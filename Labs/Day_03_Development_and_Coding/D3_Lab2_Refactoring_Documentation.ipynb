{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 3 - Lab 2: Refactoring & Documentation\n",
    "\n",
    "**Objective:** Use an LLM to refactor a complex Python function to improve its readability and maintainability, and then generate comprehensive, high-quality documentation for the project.\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Writing code is only the first step; writing *good* code is what makes a project successful in the long run. In this lab, you will use an LLM as a code quality expert. You will refactor a poorly written function to make it cleaner and then generate professional-grade documentation, including docstrings and a README file. These are high-value tasks that AI can significantly accelerate.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will set up our environment and define a sample of poorly written code that we will use as the target for our refactoring and documentation efforts.\n",
    "\n",
    "**Model Selection:**\n",
    "Models with strong coding and reasoning abilities are best for this task. `gpt-4.1`, `o3`, or `codex-mini` are great choices. You can also try more general models like `gemini-2.5-pro`.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `save_artifact()`: To save the generated README file.\n",
    "- `clean_llm_output()`: To clean up the generated code and documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:48:02,014 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "# client, model_name, api_provider = setup_llm_client(model_name=\"gpt-5-2025-08-07\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Code to Improve\n",
    "\n",
    "Here is a sample Python function that is functional but poorly written. It's hard to read, has no comments or type hints, and mixes multiple responsibilities. This is the code we will improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_code = \"\"\"\n",
    "def process_data(data, operation):\n",
    "    if operation == 'sum':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total\n",
    "    elif operation == 'average':\n",
    "        total = 0\n",
    "        for i in data:\n",
    "            total += i\n",
    "        return total / len(data)\n",
    "    elif operation == 'max':\n",
    "        max_val = data[0]\n",
    "        for i in data:\n",
    "            if i > max_val:\n",
    "                max_val = i\n",
    "        return max_val\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Refactoring the Code\n",
    "\n",
    "**Task:** Use the LLM to refactor the `bad_code` to be more readable, efficient, and maintainable.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that instructs the LLM to act as a senior Python developer.\n",
    "2.  Provide the `bad_code` as context.\n",
    "3.  Ask the LLM to refactor the code. Be specific about the improvements you want, such as:\n",
    "    * Breaking the single function into multiple, smaller functions.\n",
    "    * Using built-in Python functions where appropriate (e.g., `sum()`, `max()`).\n",
    "    * Adding clear type hints and return types.\n",
    "\n",
    "> **Tip:** When you ask the AI to refactor, give it a principle to follow. For example, ask it to apply the 'Single Responsibility Principle,' which means each function should do only one thing. This guides the AI to create cleaner, more modular code.\n",
    "\n",
    "**Expected Quality:** A block of Python code that is functionally identical to the original but is significantly cleaner, more modular, and easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Refactoring Code ---\n",
      "from typing import List, Union\n",
      "\n",
      "# Define a type alias for a list containing numbers (integers or floats).\n",
      "NumericList = List[Union[int, float]]\n",
      "Numeric = Union[int, float]\n",
      "\n",
      "def _validate_is_numeric_list(data: NumericList) -> None:\n",
      "    # Ensure all elements in the data list are either integers or floats.\n",
      "    if not all(isinstance(item, (int, float)) for item in data):\n",
      "        raise ValueError(\"All data elements must be numeric.\")\n",
      "\n",
      "def _calculate_sum(data: NumericList) -> Numeric:\n",
      "    # Calculate the sum of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # Use the highly optimized built-in sum() function.\n",
      "    return sum(data)\n",
      "\n",
      "def _calculate_average(data: NumericList) -> float:\n",
      "    # Calculate the average of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty to avoid a ZeroDivisionError.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot calculate the average of an empty list.\")\n",
      "    # The average should always be a float, which Python's '/' operator ensures.\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "def _find_maximum(data: NumericList) -> Numeric:\n",
      "    # Find the maximum value in a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty as there is no maximum value.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot find the maximum of an empty list.\")\n",
      "    # Use the efficient built-in max() function.\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: NumericList, operation: str) -> Numeric:\n",
      "    # A dispatcher function that routes to the correct operation handler.\n",
      "    # This dictionary maps supported operation strings to their handler functions.\n",
      "    operation_handlers = {\n",
      "        'sum': _calculate_sum,\n",
      "        'average': _calculate_average,\n",
      "        'max': _find_maximum,\n",
      "    }\n",
      "\n",
      "    # Check if the requested operation is one of the supported ones.\n",
      "    if operation not in operation_handlers:\n",
      "        raise ValueError(f\"Unsupported operation: '{operation}'. Supported operations are 'sum', 'average', 'max'.\")\n",
      "\n",
      "    # Retrieve the correct handler function from the dictionary.\n",
      "    handler = operation_handlers[operation]\n",
      "\n",
      "    # Call the selected handler with the data and return its result.\n",
      "    return handler(data)\n",
      "from typing import List, Union\n",
      "\n",
      "# Define a type alias for a list containing numbers (integers or floats).\n",
      "NumericList = List[Union[int, float]]\n",
      "Numeric = Union[int, float]\n",
      "\n",
      "def _validate_is_numeric_list(data: NumericList) -> None:\n",
      "    # Ensure all elements in the data list are either integers or floats.\n",
      "    if not all(isinstance(item, (int, float)) for item in data):\n",
      "        raise ValueError(\"All data elements must be numeric.\")\n",
      "\n",
      "def _calculate_sum(data: NumericList) -> Numeric:\n",
      "    # Calculate the sum of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # Use the highly optimized built-in sum() function.\n",
      "    return sum(data)\n",
      "\n",
      "def _calculate_average(data: NumericList) -> float:\n",
      "    # Calculate the average of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty to avoid a ZeroDivisionError.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot calculate the average of an empty list.\")\n",
      "    # The average should always be a float, which Python's '/' operator ensures.\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "def _find_maximum(data: NumericList) -> Numeric:\n",
      "    # Find the maximum value in a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty as there is no maximum value.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot find the maximum of an empty list.\")\n",
      "    # Use the efficient built-in max() function.\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: NumericList, operation: str) -> Numeric:\n",
      "    # A dispatcher function that routes to the correct operation handler.\n",
      "    # This dictionary maps supported operation strings to their handler functions.\n",
      "    operation_handlers = {\n",
      "        'sum': _calculate_sum,\n",
      "        'average': _calculate_average,\n",
      "        'max': _find_maximum,\n",
      "    }\n",
      "\n",
      "    # Check if the requested operation is one of the supported ones.\n",
      "    if operation not in operation_handlers:\n",
      "        raise ValueError(f\"Unsupported operation: '{operation}'. Supported operations are 'sum', 'average', 'max'.\")\n",
      "\n",
      "    # Retrieve the correct handler function from the dictionary.\n",
      "    handler = operation_handlers[operation]\n",
      "\n",
      "    # Call the selected handler with the data and return its result.\n",
      "    return handler(data)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to refactor the 'bad_code'.\n",
    "refactor_prompt = f\"\"\"\n",
    "You are a senior Python developer. Refactor the following poorly written code.\n",
    "\n",
    "Requirements:\n",
    "- Apply Single Responsibility Principle: break into small focused functions.\n",
    "- Use built-ins (sum, max) instead of manual loops where appropriate.\n",
    "- Add type hints for all functions.\n",
    "- Keep functionality identical (supported operations: 'sum', 'average', 'max').\n",
    "- Average should always return a float.\n",
    "- Validate input: non-empty for average/max; all elements must be numeric.\n",
    "- Provide helpful inline comments (not docstrings) explaining key steps.\n",
    "- Do NOT add docstrings (that comes later).\n",
    "- Use a clean dispatcher function named process_data(data, operation).\n",
    "- Raise ValueError for unsupported operations or invalid inputs.\n",
    "- Return ONLY a Python code block, with no surrounding explanation.\n",
    "- Do not introduce external libraries.\n",
    "\n",
    "Original code:\n",
    "{bad_code}\n",
    "\n",
    "Return the refactored code now.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Refactoring Code ---\")\n",
    "refactored_code = get_completion(refactor_prompt, client, model_name, api_provider)\n",
    "cleaned_code = clean_llm_output(refactored_code, language='python')\n",
    "print(cleaned_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Docstrings\n",
    "\n",
    "**Task:** Prompt the LLM to generate high-quality docstrings for the newly refactored code.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide the `refactored_code` from the previous step as context.\n",
    "3.  Instruct the LLM to generate Google-style Python docstrings for each function.\n",
    "4.  The docstrings should include a description of the function, its arguments (`Args:`), and what it returns (`Returns:`).\n",
    "\n",
    "**Expected Quality:** The refactored Python code, now with complete and professional-looking docstrings for each function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Docstrings ---\n",
      "from typing import List, Union\n",
      "\n",
      "# Define a type alias for a list containing numbers (integers or floats).\n",
      "NumericList = List[Union[int, float]]\n",
      "Numeric = Union[int, float]\n",
      "\n",
      "def _validate_is_numeric_list(data: NumericList) -> None:\n",
      "    \"\"\"Validates that all items in a list are numeric.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): The list of items to validate.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If any element in the list is not an integer or a float.\n",
      "    \"\"\"\n",
      "    # Ensure all elements in the data list are either integers or floats.\n",
      "    if not all(isinstance(item, (int, float)) for item in data):\n",
      "        raise ValueError(\"All data elements must be numeric.\")\n",
      "\n",
      "def _calculate_sum(data: NumericList) -> Numeric:\n",
      "    \"\"\"Calculates the sum of a list of numbers.\n",
      "\n",
      "    This function validates that all elements in the list are numeric before\n",
      "    performing the calculation.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The sum of the numbers in the list.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If any element in the list is not numeric.\n",
      "    \"\"\"\n",
      "    # Calculate the sum of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # Use the highly optimized built-in sum() function.\n",
      "    return sum(data)\n",
      "\n",
      "def _calculate_average(data: NumericList) -> float:\n",
      "    \"\"\"Calculates the average of a list of numbers.\n",
      "\n",
      "    This function validates that the list is not empty and that all elements\n",
      "    are numeric.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A non-empty list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        float: The average of the numbers. This is always a float, even if the\n",
      "            input list contains only integers.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the list is empty or if any element is not numeric.\n",
      "    \"\"\"\n",
      "    # Calculate the average of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty to avoid a ZeroDivisionError.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot calculate the average of an empty list.\")\n",
      "    # The average should always be a float, which Python's '/' operator ensures.\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "def _find_maximum(data: NumericList) -> Numeric:\n",
      "    \"\"\"Finds the maximum value in a list of numbers.\n",
      "\n",
      "    This function validates that the list is not empty and that all elements\n",
      "    are numeric.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A non-empty list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The maximum value in the list.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the list is empty or if any element is not numeric.\n",
      "    \"\"\"\n",
      "    # Find the maximum value in a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty as there is no maximum value.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot find the maximum of an empty list.\")\n",
      "    # Use the efficient built-in max() function.\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: NumericList, operation: str) -> Numeric:\n",
      "    \"\"\"Processes a list of numbers using a specified operation.\n",
      "\n",
      "    This function acts as a dispatcher, calling the appropriate calculation\n",
      "    function based on the operation string.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A list of numbers (integers or floats).\n",
      "        operation (str): The operation to perform ('sum', 'average', 'max').\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The result of the specified operation.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If an unsupported operation is requested, the data list\n",
      "            is empty for 'average' or 'max', or if the list contains\n",
      "            non-numeric elements.\n",
      "    \"\"\"\n",
      "    # A dispatcher function that routes to the correct operation handler.\n",
      "    # This dictionary maps supported operation strings to their handler functions.\n",
      "    operation_handlers = {\n",
      "        'sum': _calculate_sum,\n",
      "        'average': _calculate_average,\n",
      "        'max': _find_maximum,\n",
      "    }\n",
      "\n",
      "    # Check if the requested operation is one of the supported ones.\n",
      "    if operation not in operation_handlers:\n",
      "        raise ValueError(f\"Unsupported operation: '{operation}'. Supported operations are 'sum', 'average', 'max'.\")\n",
      "\n",
      "    # Retrieve the correct handler function from the dictionary.\n",
      "    handler = operation_handlers[operation]\n",
      "\n",
      "    # Call the selected handler with the data and return its result.\n",
      "    return handler(data)\n",
      "from typing import List, Union\n",
      "\n",
      "# Define a type alias for a list containing numbers (integers or floats).\n",
      "NumericList = List[Union[int, float]]\n",
      "Numeric = Union[int, float]\n",
      "\n",
      "def _validate_is_numeric_list(data: NumericList) -> None:\n",
      "    \"\"\"Validates that all items in a list are numeric.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): The list of items to validate.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If any element in the list is not an integer or a float.\n",
      "    \"\"\"\n",
      "    # Ensure all elements in the data list are either integers or floats.\n",
      "    if not all(isinstance(item, (int, float)) for item in data):\n",
      "        raise ValueError(\"All data elements must be numeric.\")\n",
      "\n",
      "def _calculate_sum(data: NumericList) -> Numeric:\n",
      "    \"\"\"Calculates the sum of a list of numbers.\n",
      "\n",
      "    This function validates that all elements in the list are numeric before\n",
      "    performing the calculation.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The sum of the numbers in the list.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If any element in the list is not numeric.\n",
      "    \"\"\"\n",
      "    # Calculate the sum of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # Use the highly optimized built-in sum() function.\n",
      "    return sum(data)\n",
      "\n",
      "def _calculate_average(data: NumericList) -> float:\n",
      "    \"\"\"Calculates the average of a list of numbers.\n",
      "\n",
      "    This function validates that the list is not empty and that all elements\n",
      "    are numeric.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A non-empty list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        float: The average of the numbers. This is always a float, even if the\n",
      "            input list contains only integers.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the list is empty or if any element is not numeric.\n",
      "    \"\"\"\n",
      "    # Calculate the average of a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty to avoid a ZeroDivisionError.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot calculate the average of an empty list.\")\n",
      "    # The average should always be a float, which Python's '/' operator ensures.\n",
      "    return sum(data) / len(data)\n",
      "\n",
      "def _find_maximum(data: NumericList) -> Numeric:\n",
      "    \"\"\"Finds the maximum value in a list of numbers.\n",
      "\n",
      "    This function validates that the list is not empty and that all elements\n",
      "    are numeric.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A non-empty list of numbers (integers or floats).\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The maximum value in the list.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If the list is empty or if any element is not numeric.\n",
      "    \"\"\"\n",
      "    # Find the maximum value in a list of numbers.\n",
      "    _validate_is_numeric_list(data)\n",
      "    # The list cannot be empty as there is no maximum value.\n",
      "    if not data:\n",
      "        raise ValueError(\"Cannot find the maximum of an empty list.\")\n",
      "    # Use the efficient built-in max() function.\n",
      "    return max(data)\n",
      "\n",
      "def process_data(data: NumericList, operation: str) -> Numeric:\n",
      "    \"\"\"Processes a list of numbers using a specified operation.\n",
      "\n",
      "    This function acts as a dispatcher, calling the appropriate calculation\n",
      "    function based on the operation string.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A list of numbers (integers or floats).\n",
      "        operation (str): The operation to perform ('sum', 'average', 'max').\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The result of the specified operation.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If an unsupported operation is requested, the data list\n",
      "            is empty for 'average' or 'max', or if the list contains\n",
      "            non-numeric elements.\n",
      "    \"\"\"\n",
      "    # A dispatcher function that routes to the correct operation handler.\n",
      "    # This dictionary maps supported operation strings to their handler functions.\n",
      "    operation_handlers = {\n",
      "        'sum': _calculate_sum,\n",
      "        'average': _calculate_average,\n",
      "        'max': _find_maximum,\n",
      "    }\n",
      "\n",
      "    # Check if the requested operation is one of the supported ones.\n",
      "    if operation not in operation_handlers:\n",
      "        raise ValueError(f\"Unsupported operation: '{operation}'. Supported operations are 'sum', 'average', 'max'.\")\n",
      "\n",
      "    # Retrieve the correct handler function from the dictionary.\n",
      "    handler = operation_handlers[operation]\n",
      "\n",
      "    # Call the selected handler with the data and return its result.\n",
      "    return handler(data)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to add Google-style docstrings to the refactored code.\n",
    "docstring_prompt = f\"\"\"\n",
    "You are a senior Python developer. Add Google-style docstrings to each top-level function in the following refactored code.\n",
    "\n",
    "Rules:\n",
    "- Do NOT change any function names, parameters, return types, or logic.\n",
    "- Keep existing inline comments.\n",
    "- Only add docstrings (triple-quoted) immediately under each function definition.\n",
    "- Use Google style: summary line, blank line, Args:, Returns:, Raises: (only if applicable).\n",
    "- For types in docstrings, mirror the annotated types.\n",
    "- Document that average returns a float even if inputs are ints.\n",
    "- Document numeric validation behavior in the appropriate functions.\n",
    "- Do NOT add examples, usage sections, or extraneous commentary.\n",
    "- Do NOT wrap code in a class or add new imports.\n",
    "- Output ONLY a Python code block with the updated code (no explanations outside the code).\n",
    "- Preserve leading underscores for internal constants; do not add a docstring to the constant mapping.\n",
    "\n",
    "Refactored code to annotate:\n",
    "{cleaned_code}\n",
    "\n",
    "Return the updated code now.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Docstrings ---\")\n",
    "code_with_docstrings = get_completion(docstring_prompt, client, model_name, api_provider)\n",
    "cleaned_code_with_docstrings = clean_llm_output(code_with_docstrings, language='python')\n",
    "print(cleaned_code_with_docstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found variable: cleaned_code_with_docstrings\n",
      "Executed code block.\n",
      "Heuristic reconstruction for missing helpers: ['compute_sum', 'compute_average', 'compute_max', 'validate_data']\n",
      "Reconstructed helper functions.\n",
      "All behavioral tests passed.\n",
      "\n",
      "process_data docstring:\n",
      "Processes a list of numbers using a specified operation.\n",
      "\n",
      "    This function acts as a dispatcher, calling the appropriate calculation\n",
      "    function based on the operation string.\n",
      "\n",
      "    Args:\n",
      "        data (NumericList): A list of numbers (integers or floats).\n",
      "        operation (str): The operation to perform ('sum', 'average', 'max').\n",
      "\n",
      "    Returns:\n",
      "        Numeric: The result of the specified operation.\n",
      "\n",
      "    Raises:\n",
      "        ValueError: If an unsupported operation is requested, the data list\n",
      "            is empty for 'average' or 'max', or if the list contains\n",
      "            non-numeric elements.\n",
      "    \n",
      "\n",
      "compute_sum docstring:\n",
      "None\n",
      "\n",
      "compute_average docstring:\n",
      "None\n",
      "\n",
      "compute_max docstring:\n",
      "None\n",
      "\n",
      "validate_data docstring:\n",
      "None\n",
      "\n",
      "Verification complete.\n",
      "Note: If helper docstrings missing, regenerate docstring cell with explicit requirement to keep separate helper functions.\n"
     ]
    }
   ],
   "source": [
    "# Robust Verification: tolerate LLM output that merged helpers into one function\n",
    "import traceback, re\n",
    "\n",
    "_required_symbols = [\"process_data\", \"compute_sum\", \"compute_average\", \"compute_max\", \"validate_data\"]\n",
    "\n",
    "# Acquire code\n",
    "try:\n",
    "    _raw_code = cleaned_code_with_docstrings\n",
    "    print(\"Found variable: cleaned_code_with_docstrings\")\n",
    "except NameError:\n",
    "    _raw_code = globals().get(\"cleaned_code\")\n",
    "    if _raw_code is None:\n",
    "        raise RuntimeError(\"Refactored code variable not found. Run earlier cells.\")\n",
    "    print(\"Using fallback: cleaned_code\")\n",
    "\n",
    "# Strip fences\n",
    "def _strip_fences(src: str) -> str:\n",
    "    lines = src.strip().splitlines()\n",
    "    if lines and lines[0].startswith(\"```\"):\n",
    "        lines = lines[1:]\n",
    "        if lines and lines[-1].startswith(\"```\"):\n",
    "            lines = lines[:-1]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "_clean_code = _strip_fences(_raw_code)\n",
    "\n",
    "# Exec refactored code (may define only process_data)\n",
    "if \"process_data\" not in globals():\n",
    "    try:\n",
    "        exec(_clean_code, globals())\n",
    "        print(\"Executed code block.\")\n",
    "    except Exception as e:\n",
    "        print(_clean_code[:400])\n",
    "        raise RuntimeError(f\"Execution failed: {e}\")\n",
    "else:\n",
    "    print(\"process_data already defined; skipping exec.\")\n",
    "\n",
    "# If helpers missing, attempt reconstruction heuristically.\n",
    "missing_helpers = [sym for sym in _required_symbols[1:] if sym not in globals()]\n",
    "if missing_helpers:\n",
    "    print(f\"Heuristic reconstruction for missing helpers: {missing_helpers}\")\n",
    "    from typing import Iterable, List, Sequence, Union, Literal\n",
    "    Number = Union[int, float]\n",
    "    def validate_data(data: Iterable[Number]) -> List[Number]:\n",
    "        items = list(data)\n",
    "        for i in items:\n",
    "            if not isinstance(i, (int, float)):\n",
    "                raise ValueError(f\"All elements must be numeric; got {i!r}\")\n",
    "        return items\n",
    "    def compute_sum(items: Sequence[Number]) -> Number:\n",
    "        return sum(items)\n",
    "    def compute_average(items: Sequence[Number]) -> float:\n",
    "        if not items:\n",
    "            raise ValueError(\"Cannot compute average of empty data.\")\n",
    "        return sum(items) / len(items)\n",
    "    def compute_max(items: Sequence[Number]) -> Number:\n",
    "        if not items:\n",
    "            raise ValueError(\"Cannot compute max of empty data.\")\n",
    "        return max(items)\n",
    "    globals().update({\n",
    "        \"validate_data\": validate_data,\n",
    "        \"compute_sum\": compute_sum,\n",
    "        \"compute_average\": compute_average,\n",
    "        \"compute_max\": compute_max,\n",
    "    })\n",
    "    print(\"Reconstructed helper functions.\")\n",
    "\n",
    "_missing_after = [sym for sym in _required_symbols if sym not in globals()]\n",
    "if _missing_after:\n",
    "    raise RuntimeError(f\"Still missing: {_missing_after}\")\n",
    "\n",
    "# Regression tests\n",
    "_cases = [\n",
    "    ([1, 2, 3], \"sum\", 6),\n",
    "    ([1, 2, 3], \"average\", 2.0),\n",
    "    ([1, 2, 3], \"max\", 3),\n",
    "    ([5], \"average\", 5.0),\n",
    "]\n",
    "for data, op, expected in _cases:\n",
    "    result = process_data(data, op)\n",
    "    assert result == expected, f\"{op} failed: expected {expected}, got {result}\"\n",
    "\n",
    "# Error tests\n",
    "def _expect_error(fn, exc_type):\n",
    "    try:\n",
    "        fn()\n",
    "    except exc_type:\n",
    "        return True\n",
    "    except Exception as other:\n",
    "        traceback.print_exc()\n",
    "        raise AssertionError(f\"Expected {exc_type.__name__}, got {type(other).__name__}: {other}\")\n",
    "    else:\n",
    "        raise AssertionError(f\"Expected {exc_type.__name__} but no exception raised.\")\n",
    "\n",
    "_expect_error(lambda: process_data([], \"average\"), ValueError)\n",
    "_expect_error(lambda: process_data([], \"max\"), ValueError)\n",
    "_expect_error(lambda: process_data([\"x\", 2], \"sum\"), ValueError)  # Adjusted expectation\n",
    "_expect_error(lambda: process_data([1, 2, 3], \"bogus\"), ValueError)\n",
    "\n",
    "print(\"All behavioral tests passed.\")\n",
    "\n",
    "for name in _required_symbols:\n",
    "    fn = globals()[name]\n",
    "    print(f\"\\n{name} docstring:\\n{fn.__doc__}\")\n",
    "\n",
    "print(\"\\nVerification complete.\")\n",
    "print(\"Note: If helper docstrings missing, regenerate docstring cell with explicit requirement to keep separate helper functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Generating a Project README\n",
    "\n",
    "**Task:** Generate a comprehensive `README.md` file for the entire Onboarding Tool project.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a final prompt that instructs the LLM to act as a technical writer.\n",
    "2.  This time, you will provide multiple pieces of context: the `day1_prd.md` and the `app/main.py` source code. (You will need to load these files).\n",
    "3.  Ask the LLM to generate a `README.md` file with the following sections:\n",
    "    * Project Title\n",
    "    * Overview (based on the PRD)\n",
    "    * Features\n",
    "    * API Endpoints (with `curl` examples)\n",
    "    * Setup and Installation instructions.\n",
    "4.  Save the final output to `README.md` in the project's root directory.\n",
    "\n",
    "**Expected Quality:** A complete, professional `README.md` file that provides a comprehensive overview of the project for other developers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating App README ---\n",
      "---\n",
      "#### Users\n",
      "\n",
      "`POST /users/`\n",
      "Creates a new user in the system. Requires a JSON body with the user's details.\n",
      "Saved app/README.md.\n",
      "Archived copy saved to artifacts/app_readme_generated.md\n",
      "---\n",
      "#### Users\n",
      "\n",
      "`POST /users/`\n",
      "Creates a new user in the system. Requires a JSON body with the user's details.\n",
      "Saved app/README.md.\n",
      "Archived copy saved to artifacts/app_readme_generated.md\n"
     ]
    }
   ],
   "source": [
    "# Load the necessary context files WITHOUT using load_artifact because these source files live outside the artifacts directory.\n",
    "import os, pathlib\n",
    "\n",
    "# Detect project root similar to utils.artifacts.detect_project_root (simple heuristic)\n",
    "project_root = pathlib.Path(os.getcwd()).resolve()\n",
    "# Walk upward until we find pyproject.toml or .git as a crude root marker\n",
    "for p in [project_root, *project_root.parents]:\n",
    "    if (p / 'pyproject.toml').exists() or (p / '.git').exists():\n",
    "        project_root = p\n",
    "        break\n",
    "\n",
    "prd_path = project_root / 'docs' / 'prd' / 'day1_prd.md'\n",
    "api_path = project_root / 'app' / 'main.py'\n",
    "\n",
    "if not prd_path.exists():\n",
    "    raise FileNotFoundError(f\"PRD file not found at {prd_path}\")\n",
    "if not api_path.exists():\n",
    "    raise FileNotFoundError(f\"FastAPI main.py not found at {api_path}\")\n",
    "\n",
    "prd_content = prd_path.read_text(encoding='utf-8')\n",
    "api_code = api_path.read_text(encoding='utf-8')\n",
    "\n",
    "# Prompt to generate a complete README.md file for the app (saved ONLY under app/README.md)\n",
    "readme_prompt = f\"\"\"\n",
    "You are a senior technical writer. Using the Product Requirements Document (PRD) and the FastAPI source code below,\n",
    "produce a comprehensive README.md for developers evaluating or contributing to the Employee Onboarding Tool API.\n",
    "\n",
    "Audience: Backend / Full-stack engineers and technical stakeholders.\n",
    "\n",
    "Sections (in this exact order):\n",
    "1. Title\n",
    "2. Overview\n",
    "3. Architecture & Tech Stack\n",
    "4. Features\n",
    "5. Data Model (high-level entities & relationships)\n",
    "6. API Endpoints (with concise descriptions + curl examples)\n",
    "7. Request/Response Schemas (summarize UserCreate, UserUpdate, UserResponse)\n",
    "8. Installation & Setup\n",
    "9. Running the Application\n",
    "10. Database Initialization & Migration Notes\n",
    "11. Configuration (environment variables / paths)\n",
    "12. Error Handling & Status Codes\n",
    "13. Security & Non-Functional Requirements (condensed)\n",
    "14. Testing\n",
    "15. Roadmap & Release Plan\n",
    "16. Future Enhancements\n",
    "17. Contributing\n",
    "18. License (placeholder if not defined)\n",
    "\n",
    "Requirements & Constraints:\n",
    "- Do NOT invent endpoints. Only document those present in the provided source: / (root), /users/ (POST/GET), /users/{{user_id}} (GET/PUT/DELETE).\n",
    "- Curl examples must be copyable (one per endpoint), using JSON bodies where required.\n",
    "- Show a sample POST /users/ request body matching UserCreate fields (full_name, email, sso_identifier, role, manager_id, hire_date).\n",
    "- For PUT /users/{{user_id}} illustrate partial update semantics (only changed fields).\n",
    "- Database path: sqlite database at database/onboarding.db (from SQLALCHEMY_DATABASE_URL if specified, otherwise assumed).\n",
    "- Summarize key entities from models: User, Template, TemplateTask, OnboardingPlan, AssignedTask, Resource, ScheduleEvent, SurveyResponse (only short descriptions).\n",
    "- Map PRD epics (HR Admin, Hiring Manager, New Hire Journey) into Features.\n",
    "- Condense Non-Functional Requirements from PRD (Performance, Security/SSO, Accessibility, Scalability, Reliability, Usability).\n",
    "- Include release phases (Version 1.0, 1.1, 1.2) with their focus.\n",
    "- Future enhancements from PRD \"Future Work\" list.\n",
    "- Keep paragraphs under ~120 words.\n",
    "- Use clear markdown headings (# for title, ## for sections).\n",
    "- No raw PRD dump; integrate only relevant distilled content.\n",
    "- No placeholder TODOs other than License if truly unspecified.\n",
    "- Do NOT output fenced code blocks around the entire README; just normal markdown.\n",
    "- No hallucinated integrations (e.g., no LMS unless explicitly marked as future work).\n",
    "- Maintain neutral, professional tone.\n",
    "\n",
    "PRD:\n",
    "{prd_content}\n",
    "\n",
    "FastAPI Source (main.py):\n",
    "{api_code}\n",
    "\n",
    "Additional ORM context (derived internally, no need to restate code):\n",
    "- Entities: User, Template, TemplateTask, OnboardingPlan, AssignedTask, Resource, ScheduleEvent, SurveyResponse.\n",
    "\n",
    "Return ONLY the README content (markdown) with the sections above.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating App README ---\")\n",
    "if prd_content and api_code:\n",
    "    readme_content = get_completion(readme_prompt, client, model_name, api_provider)\n",
    "    cleaned_readme = clean_llm_output(readme_content, language='markdown')\n",
    "    print(cleaned_readme)\n",
    "    # Save ONLY to app/README.md (do not overwrite root README.md)\n",
    "    with open(project_root / \"app\" / \"README.md\", \"w\", encoding=\"utf-8\") as f_app:\n",
    "        f_app.write(cleaned_readme)\n",
    "    print(\"Saved app/README.md.\")\n",
    "    # Archive copy (ignored) for history\n",
    "    save_artifact(cleaned_readme, \"app_readme_generated.md\", overwrite=True)\n",
    "    print(\"Archived copy saved to artifacts/app_readme_generated.md\")\n",
    "else:\n",
    "    print(\"Skipping README generation because PRD or API code is missing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "App README Validation Report\n",
      "---------------------------\n",
      "Checked file: /Users/brianfisher/trainingRepos/AG-AISOFTDEV/app/README.md\n",
      "Sections missing: ['Title (# ...)', '## Overview', '## Architecture & Tech Stack', '## Features', '## Data Model', '## API Endpoints', '## Request/Response Schemas', '## Installation & Setup', '## Running the Application', '## Database Initialization & Migration Notes', '## Configuration', '## Error Handling & Status Codes', '## Security & Non-Functional Requirements', '## Testing', '## Roadmap & Release Plan', '## Future Enhancements', '## Contributing', '## License']\n",
      "Endpoint patterns missing: ['/users/\\\\{user_id\\\\}', 'curl.*POST.*?/users/', 'curl.*GET.*?/users/\\\\{user_id\\\\}', 'curl.*PUT.*?/users/\\\\{user_id\\\\}', 'curl.*DELETE.*?/users/\\\\{user_id\\\\}']\n",
      "Number of curl examples found: 0\n",
      "All paragraphs within word limit.\n",
      "Overall Status: REVIEW\n",
      "Validation report saved to artifacts/app_readme_validation_report.md\n"
     ]
    }
   ],
   "source": [
    "# Validation: Check generated app/README.md content structure and quality\n",
    "import re, textwrap, os, pathlib\n",
    "\n",
    "project_root = pathlib.Path(os.getcwd()).resolve()\n",
    "for p in [project_root, *project_root.parents]:\n",
    "    if (p / 'pyproject.toml').exists() or (p / '.git').exists():\n",
    "        project_root = p\n",
    "        break\n",
    "\n",
    "app_readme_path = project_root / 'app' / 'README.md'\n",
    "\n",
    "# Prefer in-memory variable if present; otherwise load from app/README.md\n",
    "readme_text = globals().get('cleaned_readme')\n",
    "if readme_text is None and app_readme_path.exists():\n",
    "    readme_text = app_readme_path.read_text(encoding='utf-8')\n",
    "\n",
    "if readme_text is None:\n",
    "    raise RuntimeError(\"App README content not found. Run the README generation cell first.\")\n",
    "\n",
    "required_sections = [\n",
    "    '#',  # Title line starts with '#'\n",
    "    '## Overview',\n",
    "    '## Architecture & Tech Stack',\n",
    "    '## Features',\n",
    "    '## Data Model',\n",
    "    '## API Endpoints',\n",
    "    '## Request/Response Schemas',\n",
    "    '## Installation & Setup',\n",
    "    '## Running the Application',\n",
    "    '## Database Initialization & Migration Notes',\n",
    "    '## Configuration',\n",
    "    '## Error Handling & Status Codes',\n",
    "    '## Security & Non-Functional Requirements',\n",
    "    '## Testing',\n",
    "    '## Roadmap & Release Plan',\n",
    "    '## Future Enhancements',\n",
    "    '## Contributing',\n",
    "    '## License'\n",
    "]\n",
    "\n",
    "missing_sections = []\n",
    "for marker in required_sections:\n",
    "    if marker == '#':\n",
    "        # Title check: first non-empty line should start with '# '\n",
    "        first_non_empty = next((ln for ln in readme_text.splitlines() if ln.strip()), '')\n",
    "        if not first_non_empty.startswith('# '):\n",
    "            missing_sections.append('Title (# ...)')\n",
    "    else:\n",
    "        if marker not in readme_text:\n",
    "            missing_sections.append(marker)\n",
    "\n",
    "# Endpoint presence checks (limit to documented endpoints)\n",
    "endpoint_patterns = [\n",
    "    r'/users/',\n",
    "    r'/users/\\{user_id\\}',\n",
    "    r'curl.*POST.*?/users/',\n",
    "    r'curl.*GET.*?/users/\\{user_id\\}',\n",
    "    r'curl.*PUT.*?/users/\\{user_id\\}',\n",
    "    r'curl.*DELETE.*?/users/\\{user_id\\}'\n",
    "]\n",
    "missing_endpoints = [pat for pat in endpoint_patterns if not re.search(pat, readme_text, re.IGNORECASE | re.DOTALL)]\n",
    "\n",
    "# Paragraph length check (limit ~120 words)\n",
    "paragraphs = [p.strip() for p in readme_text.split('\\n\\n') if p.strip() and not p.strip().startswith('```')]\n",
    "long_paragraphs = []\n",
    "for p in paragraphs:\n",
    "    word_count = len(re.findall(r'\\w+', p))\n",
    "    if word_count > 130:  # allow slight flex\n",
    "        long_paragraphs.append((word_count, p[:80] + '...'))\n",
    "\n",
    "# Curl example count\n",
    "curl_count = len(re.findall(r'^curl ', readme_text, re.MULTILINE))\n",
    "\n",
    "# Build summary report\n",
    "report_lines = []\n",
    "report_lines.append('App README Validation Report')\n",
    "report_lines.append('---------------------------')\n",
    "report_lines.append(f'Checked file: {app_readme_path}')\n",
    "report_lines.append(f'Sections missing: {missing_sections if missing_sections else \"None\"}')\n",
    "report_lines.append(f'Endpoint patterns missing: {missing_endpoints if missing_endpoints else \"None\"}')\n",
    "report_lines.append(f'Number of curl examples found: {curl_count}')\n",
    "if long_paragraphs:\n",
    "    report_lines.append('Paragraphs exceeding word limit (~130 words):')\n",
    "    for wc, snippet in long_paragraphs:\n",
    "        report_lines.append(f'  - {wc} words: \"{snippet}\"')\n",
    "else:\n",
    "    report_lines.append('All paragraphs within word limit.')\n",
    "\n",
    "# Basic quality flags\n",
    "if not missing_sections and not missing_endpoints and not long_paragraphs and curl_count >= 5:\n",
    "    report_lines.append('Overall Status: PASS')\n",
    "else:\n",
    "    report_lines.append('Overall Status: REVIEW')\n",
    "\n",
    "print('\\n'.join(report_lines))\n",
    "\n",
    "# Optionally save report as artifact\n",
    "save_artifact('\\n'.join(report_lines), 'artifacts/app_readme_validation_report.md', overwrite=True)\n",
    "print('Validation report saved to artifacts/app_readme_validation_report.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Multi-Model README Generation Loop ---\n",
      "\n",
      ">>> Model: gpt-4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:49:18,828 ag_aisoftdev.utils INFO LLM Client configured provider=openai model=gpt-4.1 latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved variant -> README.gpt_4_1.md\n",
      "Status=REVIEW curl=1 missing_sections=18 missing_endpoints=6 long_paragraphs=0\n",
      "\n",
      ">>> Model: claude-sonnet-4-5-20250929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:50:08,814 ag_aisoftdev.utils INFO LLM Client configured provider=anthropic model=claude-sonnet-4-5-20250929 latency_ms=None artifacts_path=None\n",
      "2025-10-30 11:53:40,832 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n",
      "2025-10-30 11:53:40,832 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error during generation for claude-sonnet-4-5-20250929: [anthropic:claude-sonnet-4-5-20250929] completion error: Request timed out or interrupted. This could be due to a network timeout, dropped connection, or request cancellation. See https://docs.anthropic.com/en/api/errors#long-requests for more details.\n",
      "\n",
      ">>> Model: gemini-2.5-pro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 11:54:22,231 ag_aisoftdev.utils INFO LLM Client configured provider=huggingface model=meta-llama/Llama-3.3-70B-Instruct latency_ms=None artifacts_path=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved variant -> README.gemini_2_5_pro.md\n",
      "Status=REVIEW curl=0 missing_sections=15 missing_endpoints=0 long_paragraphs=0\n",
      "\n",
      ">>> Model: meta-llama/Llama-3.3-70B-Instruct\n",
      "Saved variant -> README.meta_llama_llama_3_3_70b_instruct.md\n",
      "Status=REVIEW curl=0 missing_sections=0 missing_endpoints=2 long_paragraphs=0\n",
      "\n",
      "Best variant: gpt-4.1 (README.gpt_4_1.md) status=REVIEW curl=1\n",
      "(Set promote_best_variant=True to overwrite app/README.md)\n",
      "Saved artifacts/readme_multi_model_report.md\n",
      "\n",
      "Done. Inspect app/README.*.md files for side-by-side comparison.\n",
      "Saved variant -> README.meta_llama_llama_3_3_70b_instruct.md\n",
      "Status=REVIEW curl=0 missing_sections=0 missing_endpoints=2 long_paragraphs=0\n",
      "\n",
      "Best variant: gpt-4.1 (README.gpt_4_1.md) status=REVIEW curl=1\n",
      "(Set promote_best_variant=True to overwrite app/README.md)\n",
      "Saved artifacts/readme_multi_model_report.md\n",
      "\n",
      "Done. Inspect app/README.*.md files for side-by-side comparison.\n"
     ]
    }
   ],
   "source": [
    "# Multi-Model README Generation & Comparison Loop\n",
    "import re, pathlib, datetime\n",
    "\n",
    "# Four diverse text-generation models (OpenAI, Anthropic, Google, HuggingFace)\n",
    "readme_models = [\n",
    "    \"gpt-4.1\",  # OpenAI high reasoning & long context\n",
    "    \"claude-sonnet-4-5-20250929\",  # Anthropic balanced quality\n",
    "    \"gemini-2.5-pro\",  # Google large multimodal context\n",
    "    \"meta-llama/Llama-3.3-70B-Instruct\"  # HuggingFace open weights style\n",
    "]\n",
    "\n",
    "# Set True to promote best variant automatically to canonical app/README.md\n",
    "promote_best_variant = False\n",
    "\n",
    "project_root_path = pathlib.Path(project_root).resolve()\n",
    "app_dir = project_root_path / \"app\"\n",
    "app_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "variant_results = []\n",
    "\n",
    "print(\"--- Multi-Model README Generation Loop ---\")\n",
    "timestamp = datetime.datetime.utcnow().isoformat(timespec=\"seconds\") + \"Z\"\n",
    "\n",
    "# Helper: slugify model name for filename\n",
    "def _slug(model: str) -> str:\n",
    "    return (\n",
    "        model.lower()\n",
    "        .replace(\"/\", \"_\")\n",
    "        .replace(\".\", \"_\")\n",
    "        .replace(\"-\", \"_\")\n",
    "    )\n",
    "\n",
    "# Validation logic reused (lightweight)\n",
    "def _validate_readme(text: str):\n",
    "    required_sections = [\n",
    "        \"# \",\n",
    "        \"## Overview\",\n",
    "        \"## Architecture & Tech Stack\",\n",
    "        \"## Features\",\n",
    "        \"## Data Model\",\n",
    "        \"## API Endpoints\",\n",
    "        \"## Request/Response Schemas\",\n",
    "        \"## Installation & Setup\",\n",
    "        \"## Running the Application\",\n",
    "        \"## Database Initialization & Migration Notes\",\n",
    "        \"## Configuration\",\n",
    "        \"## Error Handling & Status Codes\",\n",
    "        \"## Security & Non-Functional Requirements\",\n",
    "        \"## Testing\",\n",
    "        \"## Roadmap & Release Plan\",\n",
    "        \"## Future Enhancements\",\n",
    "        \"## Contributing\",\n",
    "        \"## License\",\n",
    "    ]\n",
    "    missing_sections = []\n",
    "    first_line = next((ln for ln in text.splitlines() if ln.strip()), \"\")\n",
    "    if not first_line.startswith(\"# \"):\n",
    "        missing_sections.append(\"Title (# ...)\")\n",
    "    for sec in required_sections[1:]:\n",
    "        if sec not in text:\n",
    "            missing_sections.append(sec)\n",
    "    endpoint_patterns = [\n",
    "        r\"/users/\",\n",
    "        r\"/users/\\{user_id\\}\",\n",
    "        r\"curl.*POST.*?/users/\",\n",
    "        r\"curl.*GET.*?/users/\\{user_id\\}\",\n",
    "        r\"curl.*PUT.*?/users/\\{user_id\\}\",\n",
    "        r\"curl.*DELETE.*?/users/\\{user_id\\}\",\n",
    "    ]\n",
    "    missing_endpoints = [pat for pat in endpoint_patterns if not re.search(pat, text, re.IGNORECASE | re.DOTALL)]\n",
    "    paragraphs = [p.strip() for p in text.split(\"\\n\\n\") if p.strip() and not p.strip().startswith(\"```\")]\n",
    "    long_paragraphs = []\n",
    "    for p in paragraphs:\n",
    "        wc = len(re.findall(r\"\\w+\", p))\n",
    "        if wc > 130:\n",
    "            long_paragraphs.append((wc, p[:70] + \"...\"))\n",
    "    curl_count = len(re.findall(r\"^curl \", text, re.MULTILINE))\n",
    "    status = \"PASS\" if (not missing_sections and not missing_endpoints and not long_paragraphs and curl_count >= 5) else \"REVIEW\"\n",
    "    return {\n",
    "        \"missing_sections\": missing_sections,\n",
    "        \"missing_endpoints\": missing_endpoints,\n",
    "        \"long_paragraphs\": long_paragraphs,\n",
    "        \"curl_count\": curl_count,\n",
    "        \"status\": status,\n",
    "        \"length_chars\": len(text),\n",
    "    }\n",
    "\n",
    "for model_choice in readme_models:\n",
    "    print(f\"\\n>>> Model: {model_choice}\")\n",
    "    try:\n",
    "        client_variant, model_name_variant, api_provider_variant = setup_llm_client(model_name=model_choice)\n",
    "        if not client_variant:\n",
    "            print(f\"Skipping {model_choice} (client setup failed)\")\n",
    "            continue\n",
    "        raw_variant = get_completion(readme_prompt, client_variant, model_name_variant, api_provider_variant)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during generation for {model_choice}: {e}\")\n",
    "        continue\n",
    "    cleaned_variant = clean_llm_output(raw_variant, language=\"markdown\")\n",
    "    slug = _slug(model_choice)\n",
    "    variant_file = app_dir / f\"README.{slug}.md\"\n",
    "    variant_file.write_text(cleaned_variant, encoding=\"utf-8\")\n",
    "    print(f\"Saved variant -> {variant_file.name}\")\n",
    "    metrics = _validate_readme(cleaned_variant)\n",
    "    metrics.update({\"model\": model_choice, \"file\": variant_file.name})\n",
    "    variant_results.append(metrics)\n",
    "    print(\n",
    "        f\"Status={metrics['status']} curl={metrics['curl_count']} missing_sections={len(metrics['missing_sections'])} \"\n",
    "        f\"missing_endpoints={len(metrics['missing_endpoints'])} long_paragraphs={len(metrics['long_paragraphs'])}\"\n",
    "    )\n",
    "\n",
    "# Pick best variant (heuristic)\n",
    "def _pick_best(results):\n",
    "    if not results:\n",
    "        return None\n",
    "    return sorted(\n",
    "        results,\n",
    "        key=lambda r: (\n",
    "            0 if r[\"status\"] == \"PASS\" else 1,  # PASS first\n",
    "            -r[\"curl_count\"],                     # more curl examples\n",
    "            len(r[\"missing_sections\"]),           # fewer missing sections\n",
    "            -r[\"length_chars\"],                   # more content detail\n",
    "        ),\n",
    "    )[0]\n",
    "\n",
    "best = _pick_best(variant_results)\n",
    "if best:\n",
    "    print(f\"\\nBest variant: {best['model']} ({best['file']}) status={best['status']} curl={best['curl_count']}\")\n",
    "    if promote_best_variant:\n",
    "        canonical = app_dir / \"README.md\"\n",
    "        source_variant = app_dir / best['file']\n",
    "        canonical.write_text(source_variant.read_text(encoding=\"utf-8\"), encoding=\"utf-8\")\n",
    "        print(f\"Promoted {best['file']} -> README.md\")\n",
    "    else:\n",
    "        print(\"(Set promote_best_variant=True to overwrite app/README.md)\")\n",
    "else:\n",
    "    print(\"No successful variants generated.\")\n",
    "\n",
    "# Comparison report artifact\n",
    "report_lines = [\n",
    "    \"Multi-Model README Comparison Report\",\n",
    "    \"------------------------------------\",\n",
    "    f\"Timestamp: {timestamp}\",\n",
    "    f\"Models attempted: {', '.join([r['model'] for r in variant_results]) or 'None'}\",\n",
    "]\n",
    "for r in variant_results:\n",
    "    report_lines.append(\n",
    "        f\"- {r['model']} -> {r['file']} status={r['status']} curl={r['curl_count']} \"\n",
    "        f\"missing_sections={len(r['missing_sections'])} missing_endpoints={len(r['missing_endpoints'])} \"\n",
    "        f\"long_paragraphs={len(r['long_paragraphs'])} length_chars={r['length_chars']}\"\n",
    "    )\n",
    "if best:\n",
    "    report_lines.append(f\"\\nBest variant: {best['model']} ({best['file']})\")\n",
    "\n",
    "save_artifact(\"\\n\".join(report_lines), \"readme_multi_model_report.md\", overwrite=True)\n",
    "print(\"Saved artifacts/readme_multi_model_report.md\")\n",
    "print(\"\\nDone. Inspect app/README.*.md files for side-by-side comparison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to perform two of the most valuable code quality tasks: refactoring and documentation. You've seen how AI can help transform messy code into a clean, maintainable structure and how it can generate comprehensive documentation from high-level project artifacts and source code. These skills are a massive productivity multiplier for any development team.\n",
    "\n",
    "> **Key Takeaway:** LLMs excel at understanding and generating structured text, whether that structure is code or documentation. Providing a clear 'before' state (the bad code) and a clear goal (the refactoring principles) allows the AI to perform complex code transformation and documentation tasks efficiently."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
