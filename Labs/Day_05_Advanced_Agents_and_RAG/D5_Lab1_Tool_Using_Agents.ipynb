{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 5 - Lab 1: Tool-Using Agents\n",
    "\n",
    "**Objective:** Build agents that can use external tools to accomplish tasks they cannot perform on their own, using both LangChain and custom Python functions.\n",
    "\n",
    "**Estimated Time:** 135 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 5! We are now shifting from using AI to build a traditional application to building applications that *are* AI. An 'agent' is more than just a prompt; it's a system that can reason, plan, and use tools to achieve a goal. In this lab, you will build your first simple agents using the flexible LangChain framework.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will set up our environment, which for today includes installing the `langchain`, `langchain-community`, and `tavily-python` libraries. Tavily is a search engine API optimized for AI agents, which we will use as our first tool.\n",
    "\n",
    "**Model Selection:**\n",
    "For agentic tasks that require reasoning and tool use, highly capable models are recommended. `gpt-4.1`, `o3`, `gemini-2.5-pro`, or open-source models like `deepseek-ai/DeepSeek-R1` are excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM (though we'll mostly use LangChain's abstractions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# This helper will install packages if they are not found\n",
    "import importlib\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found, installing...\")\n",
    "        # Note: %pip is for notebooks. In a script, use subprocess.\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "install_if_missing('langchain')\n",
    "install_if_missing('langchain_community')\n",
    "install_if_missing('langchain_openai')\n",
    "install_if_missing('tavily')\n",
    "\n",
    "from utils import setup_llm_client\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Building a LangChain Agent with One Tool\n",
    "\n",
    "**Task:** Build a simple LangChain agent that can use the Tavily Search API to answer questions about current events.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Import `TavilySearchResults` from `langchain_community.tools.tavily_search`.\n",
    "2.  Import `create_tool_calling_agent` and `AgentExecutor` from `langchain.agents`.\n",
    "3.  Import `ChatPromptTemplate` from `langchain_core.prompts`.\n",
    "4.  Instantiate the `TavilySearchResults` tool.\n",
    "5.  Create a prompt template. It must include a placeholder for `agent_scratchpad`.\n",
    "6.  Create the agent by passing the LLM, the list of tools, and the prompt to `create_tool_calling_agent`.\n",
    "7.  Create an `AgentExecutor` to run the agent.\n",
    "8.  Invoke the agent with a question that requires a web search, like \"What was the score of the last Super Bowl?\"\n",
    "\n",
    "**Expected Quality:** The agent should successfully use the Tavily tool to search the web, find the correct information, and provide an accurate answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Perform all necessary imports\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# We need to use a LangChain LLM wrapper\n",
    "llm = ChatOpenAI(model=model_name)\n",
    "\n",
    "# TODO: 1. Instantiate the Tavily search tool\n",
    "search_tool = None # Your code here\n",
    "tools = [search_tool]\n",
    "\n",
    "# TODO: 2. Create the prompt template\n",
    "# Make sure to include placeholders for 'input' and 'agent_scratchpad'\n",
    "prompt = None # Your prompt template here\n",
    "\n",
    "# TODO: 3. Create the agent\n",
    "agent = None # Your agent creation code here\n",
    "\n",
    "# TODO: 4. Create the AgentExecutor\n",
    "agent_executor = None # Your executor creation code here\n",
    "\n",
    "# TODO: 5. Invoke the agent with a question\n",
    "question = \"What was the score of the last Super Bowl?\"\n",
    "result = None # Your invocation code here\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Building a Multi-Tool Agent\n",
    "\n",
    "**Task:** Create a more advanced LangChain agent that has access to *multiple* tools and must reason about which one to use for a given task.\n",
    "\n",
    "> **What is the `agent_scratchpad`?** This is the agent's internal monologue. It's where the agent keeps track of its thought process: which tool it's thinking of using, what the tool's output was, and what it plans to do next. It is an essential part of the prompt for the agent's reasoning process.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Keep the `TavilySearchResults` tool from the previous challenge.\n",
    "2.  Define a new, custom tool for a calculator. You can do this by creating a simple Python function (e.g., `def multiply(a: int, b: int) -> int:`) and then decorating it with the `@tool` decorator from `langchain_core.tools`.\n",
    "3.  Create a new list of tools that includes both the search tool and your new calculator tool.\n",
    "4.  Create a new agent and `AgentExecutor` using this expanded list of tools.\n",
    "5.  Invoke the agent twice with different questions:\n",
    "    * A question that requires the calculator tool (e.g., \"What is 25 * 48?\").\n",
    "    * A question that requires the search tool (e.g., \"Who is the current CEO of Apple?\").\n",
    "6.  Observe how the agent correctly chooses which tool to use for each question.\n",
    "\n",
    "**Expected Quality:** A single agent that can dynamically decide which tool to use based on the user's query, demonstrating the core reasoning capability of an agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "# TODO: 1. Define your custom calculator tool\n",
    "# Use the @tool decorator\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies two integers together.\"\"\"\n",
    "    # Your implementation here\n",
    "    return 0\n",
    "\n",
    "# TODO: 2. Create the new list of tools\n",
    "multi_tool_list = [] # Your list here\n",
    "\n",
    "# TODO: 3. Create the new multi-tool agent and executor\n",
    "# The prompt and creation process are the same as before, just with the new tool list.\n",
    "multi_tool_agent = None # Your agent creation code here\n",
    "multi_tool_executor = None # Your executor creation code here\n",
    "\n",
    "# TODO: 4. Invoke the agent with a math question\n",
    "math_question = \"What is 25 * 48?\"\n",
    "math_result = None # Your invocation code here\n",
    "print(f\"Query: {math_question}\\nResult: {math_result}\\n\")\n",
    "\n",
    "# TODO: 5. Invoke the agent with a search question\n",
    "search_question = \"Who is the current CEO of Apple?\"\n",
    "search_result = None # Your invocation code here\n",
    "print(f\"Query: {search_question}\\nResult: {search_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Improving Tool Selection with Better Docstrings\n",
    "\n",
    "**Task:** Improve the agent's ability to choose the correct tool by writing more descriptive docstrings.\n",
    "\n",
    "> **Tip:** The agent doesn't understand your Python code; it only understands the tool's name and its docstring! A clear, descriptive docstring like 'Multiplies two integers together' is critical for helping the agent know when to use the tool.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Copy your `multiply` tool from the previous challenge.\n",
    "2.  Modify its docstring to be much more descriptive. For example: \"Use this tool for mathematical calculations involving multiplication. It takes two integers and returns their product.\"\n",
    "3.  Re-create your agent and executor with this updated tool.\n",
    "4.  Invoke the agent again with the math question and observe if its reasoning process (visible in the `verbose=True` output) is more direct.\n",
    "\n",
    "**Expected Quality:** A demonstration of how prompt engineering the docstring of a tool can significantly improve an agent's performance and reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1. Redefine your custom tool with a more descriptive docstring.\n",
    "@tool\n",
    "def better_multiply(a: int, b: int) -> int:\n",
    "    \"\"\" # Your new, more descriptive docstring here \"\"\"\n",
    "    return a * b\n",
    "\n",
    "# TODO: 2. Re-create the tool list, agent, and executor with the improved tool.\n",
    "improved_tool_list = [] # Your list here\n",
    "improved_agent = None # Your agent here\n",
    "improved_executor = None # Your executor here\n",
    "\n",
    "# TODO: 3. Invoke the agent again.\n",
    "math_question = \"What is 25 * 48?\"\n",
    "improved_math_result = None # Your invocation code here\n",
    "print(f\"Query: {math_question}\\nResult: {improved_math_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have successfully built your first AI agents. You've learned how to give agents tools to extend their capabilities and, most importantly, how to build an agent that can reason about which tool to use for a specific task. This is the foundational skill for all advanced agentic workflows we will explore in the coming days.\n",
    "\n",
    "> **Key Takeaway:** An agent's ability to reason and act depends on its understanding of its tools. The most critical part of creating a custom tool is writing a clear, descriptive docstring that tells the agent exactly what the tool does and when to use it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
