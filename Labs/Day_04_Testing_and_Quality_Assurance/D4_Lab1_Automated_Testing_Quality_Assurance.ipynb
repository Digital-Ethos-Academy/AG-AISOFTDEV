{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4 - Lab 1: Automated Testing & Quality Assurance\n",
    "\n",
    "**Objective:** Generate a comprehensive `pytest` test suite for the database-connected FastAPI application, including tests for happy paths, edge cases, and tests that use advanced fixtures for database isolation.\n",
    "\n",
    "**Estimated Time:** 135 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Welcome to Day 4! An application without tests is an application that is broken by design. Today, we focus on quality assurance. You will act as a QA Engineer, using an AI co-pilot to build a robust test suite for the API you created yesterday. This is a critical step to ensure our application is reliable and ready for production.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will load the source code for our main application from `app/main.py`. Providing the full code as context is essential for the LLM to generate accurate and relevant tests.\n",
    "\n",
    "**Model Selection:**\n",
    "For generating tests, models with strong code understanding and logical reasoning are best. `gpt-4.1`, `o3`, `codex-mini`, and `gemini-2.5-pro` are all excellent choices for this task.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read our application's source code.\n",
    "- `save_artifact()`: To save the generated test files.\n",
    "- `clean_llm_output()`: To clean up the generated Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 10:49:06,305 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact, clean_llm_output\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "\n",
    "# Load the application code from Day 3 to provide context for test generation\n",
    "app_code = load_artifact(\"app/main.py\", base_dir=project_root)\n",
    "if not app_code:\n",
    "    print(\"Warning: Could not load app/main.py. Lab may not function correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Generating \"Happy Path\" Tests\n",
    "\n",
    "**Task:** Generate basic `pytest` tests for the ideal or \"happy path\" scenarios of your CRUD endpoints.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that asks the LLM to act as a QA Engineer.\n",
    "2.  Provide the `app_code` as context.\n",
    "3.  Instruct the LLM to generate a `pytest` test function for the `POST /users/` endpoint, asserting that a user is created successfully (e.g., checking for a `201 Created` or `200 OK` status code and verifying the response body).\n",
    "4.  Generate another test for the `GET /users/` endpoint.\n",
    "5.  Save the generated tests into a file named `tests/test_main_simple.py`.\n",
    "\n",
    "**Expected Quality:** A Python script containing valid `pytest` functions that test the basic, successful operation of your API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Happy Path Tests ---\n",
      "import datetime\n",
      "import uuid\n",
      "\n",
      "from fastapi.testclient import TestClient\n",
      "\n",
      "# Assuming the FastAPI app instance is in `app.main`\n",
      "# This might need to be adjusted based on the actual project structure.\n",
      "from app.main import app\n",
      "\n",
      "client = TestClient(app)\n",
      "\n",
      "\n",
      "def test_create_user_happy_path():\n",
      "    \"\"\"\n",
      "    Tests the successful creation of a new user via the POST /users/ endpoint.\n",
      "    \"\"\"\n",
      "    unique_email = f\"testuser_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_data = {\n",
      "        \"full_name\": \"Jane Doe\",\n",
      "        \"email\": unique_email,\n",
      "        \"sso_identifier\": f\"sso_{uuid.uuid4().hex[:12]}\",\n",
      "        \"role\": \"employee\",\n",
      "        \"manager_id\": None,\n",
      "        \"hire_date\": datetime.date.today().isoformat()\n",
      "    }\n",
      "\n",
      "    response = client.post(\"/users/\", json=user_data)\n",
      "\n",
      "    assert response.status_code == 201\n",
      "\n",
      "    data = response.json()\n",
      "\n",
      "    # Assert shape and types of the response\n",
      "    assert \"user_id\" in data\n",
      "    assert isinstance(data[\"user_id\"], int)\n",
      "    assert \"full_name\" in data\n",
      "    assert isinstance(data[\"full_name\"], str)\n",
      "    assert \"email\" in data\n",
      "    assert isinstance(data[\"email\"], str)\n",
      "    assert \"role\" in data\n",
      "    assert isinstance(data[\"role\"], str)\n",
      "    assert \"hire_date\" in data\n",
      "    assert isinstance(data[\"hire_date\"], str)\n",
      "    assert \"created_at\" in data\n",
      "    assert \"updated_at\" in data\n",
      "\n",
      "    # Assert values from the request are reflected in the response\n",
      "    assert data[\"full_name\"] == user_data[\"full_name\"]\n",
      "    assert data[\"email\"] == user_data[\"email\"]\n",
      "    assert data[\"role\"] in [\"employee\", \"manager\", \"admin\"] # Based on typical roles\n",
      "    assert data[\"hire_date\"] == user_data[\"hire_date\"]\n",
      "\n",
      "\n",
      "def test_get_users_happy_path():\n",
      "    \"\"\"\n",
      "    Tests retrieving a list of all users via the GET /users/ endpoint.\n",
      "    Ensures the test is independent by creating a user first.\n",
      "    \"\"\"\n",
      "    # Step 1: Create a user to ensure the list is not empty\n",
      "    unique_email = f\"list_test_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_data = {\n",
      "        \"full_name\": \"List Test User\",\n",
      "        \"email\": unique_email,\n",
      "        \"role\": \"manager\",\n",
      "        \"hire_date\": \"2023-10-26\"\n",
      "    }\n",
      "    create_response = client.post(\"/users/\", json=user_data)\n",
      "    assert create_response.status_code == 201\n",
      "    created_user_id = create_response.json()[\"user_id\"]\n",
      "\n",
      "    # Step 2: Make the request to get all users\n",
      "    response = client.get(\"/users/\")\n",
      "\n",
      "    assert response.status_code == 200\n",
      "\n",
      "    data = response.json()\n",
      "    assert isinstance(data, list)\n",
      "    assert len(data) > 0\n",
      "\n",
      "    # Find the user we just created in the list\n",
      "    found_user = None\n",
      "    for user in data:\n",
      "        if user[\"user_id\"] == created_user_id:\n",
      "            found_user = user\n",
      "            break\n",
      "\n",
      "    assert found_user is not None\n",
      "    assert found_user[\"email\"] == unique_email\n",
      "    assert found_user[\"full_name\"] == \"List Test User\"\n",
      "    assert \"user_id\" in found_user\n",
      "    assert isinstance(found_user[\"user_id\"], int)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate happy path tests for your API.\n",
    "happy_path_tests_prompt = f\"\"\"\n",
    "You are a senior QA engineer specializing in FastAPI API test authoring. You will generate **only** Python pytest code for happy path tests of the provided application.\n",
    "\n",
    "CONTEXT (FastAPI app code):\n",
    "```\n",
    "{app_code}\n",
    "```\n",
    "\n",
    "TARGET ENDPOINTS TO TEST:\n",
    "1. POST /users/  -> Should create a new user. Expect HTTP 201, response JSON includes: user_id (int), full_name (str), email (str), role (str), hire_date (ISO 8601 or date), created_at, updated_at.\n",
    "2. GET /users/   -> Should return a list (possibly empty or containing previously created users). Expect HTTP 200, list of user objects with the same shape.\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Use pytest.\n",
    "- Use from fastapi.testclient import TestClient\n",
    "- Instantiate TestClient against the FastAPI app imported from app.main (e.g. `from app.main import app`).\n",
    "- Each test must be independent; do NOT rely on ordering. If needed, create a user within the same test before asserting GET /users/.\n",
    "- Use unique emails per test (e.g., f\"user_{{uuid.uuid4().hex[:8]}}@example.com\") to avoid clashes.\n",
    "- Assert specific status codes.\n",
    "- Assert essential response fields and types.\n",
    "- Do NOT include any extraneous comments beyond what is helpful.\n",
    "- Do NOT print anything.\n",
    "- No backticks, no markdown; return pure Python code only.\n",
    "- Avoid sleeping, network calls, or accessing external files.\n",
    "- Keep tests concise but clear; 1 test for POST success, 1 test for GET listing.\n",
    "- If the POST response role field is string, assert it's one of expected role values or non-empty (based on provided code; adapt accordingly).\n",
    "- If the application sets timestamps, you can assert presence (key in response) rather than exact value.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return a single Python file content containing:\n",
    "- All imports at top.\n",
    "- Two test functions: test_create_user_happy_path, test_get_users_happy_path.\n",
    "\n",
    "Do NOT include anything else but the Python code.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Happy Path Tests ---\")\n",
    "if app_code:\n",
    "    generated_happy_path_tests = get_completion(happy_path_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_tests = clean_llm_output(generated_happy_path_tests, language='python')\n",
    "    print(cleaned_tests)\n",
    "    save_artifact(cleaned_tests, \"tests/test_main_simple.py\", base_dir=project_root)\n",
    "else:\n",
    "    print(\"Skipping test generation because app code is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Edge Case Tests\n",
    "\n",
    "**Task:** Prompt the LLM to generate tests for common edge cases, such as providing invalid data or requesting a non-existent resource.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a new prompt.\n",
    "2.  Provide the `app_code` as context.\n",
    "3.  Instruct the LLM to write two new test functions:\n",
    "    * A test for the `POST /users/` endpoint that tries to create a user with an email that already exists, asserting that the API returns a `400 Bad Request` error.\n",
    "    * A test for the `GET /users/{user_id}` endpoint that requests a non-existent user ID, asserting that the API returns a `404 Not Found` error.\n",
    "\n",
    "**Expected Quality:** Two new `pytest` functions that verify the application handles common error scenarios correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Edge Case Tests ---\n",
      "import pytest\n",
      "import uuid\n",
      "import datetime\n",
      "from fastapi.testclient import TestClient\n",
      "\n",
      "from app.main import app\n",
      "\n",
      "client = TestClient(app)\n",
      "\n",
      "\n",
      "def test_create_user_duplicate_email_rejected():\n",
      "    unique_email = f\"user_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_payload = {\n",
      "        \"full_name\": \"Duplicate User\",\n",
      "        \"email\": unique_email,\n",
      "        \"sso_identifier\": uuid.uuid4().hex,\n",
      "        \"role\": \"employee\",\n",
      "        \"manager_id\": None,\n",
      "        \"hire_date\": datetime.date.today().isoformat(),\n",
      "    }\n",
      "\n",
      "    # First request: Create the user successfully\n",
      "    response1 = client.post(\"/users/\", json=user_payload)\n",
      "    assert response1.status_code == 201\n",
      "    data1 = response1.json()\n",
      "    assert isinstance(data1[\"user_id\"], int)\n",
      "    assert data1[\"email\"] == unique_email\n",
      "    assert data1[\"full_name\"] == \"Duplicate User\"\n",
      "    assert data1[\"role\"] == \"employee\"\n",
      "\n",
      "    # Second request: Attempt to create the same user again\n",
      "    response2 = client.post(\"/users/\", json=user_payload)\n",
      "    assert response2.status_code == 400\n",
      "    assert response2.json() == {\"detail\": \"An account with this email already exists.\"}\n",
      "\n",
      "\n",
      "def test_get_user_not_found_returns_404():\n",
      "    # Step 1: Create a valid user to get a real ID\n",
      "    unique_email = f\"user_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_payload = {\n",
      "        \"full_name\": \"Existing User\",\n",
      "        \"email\": unique_email,\n",
      "        \"sso_identifier\": uuid.uuid4().hex,\n",
      "        \"role\": \"manager\",\n",
      "        \"hire_date\": datetime.date.today().isoformat(),\n",
      "    }\n",
      "    create_response = client.post(\"/users/\", json=user_payload)\n",
      "    assert create_response.status_code == 201\n",
      "    created_user = create_response.json()\n",
      "    assert isinstance(created_user[\"user_id\"], int)\n",
      "    assert created_user[\"email\"] == unique_email\n",
      "    assert created_user[\"full_name\"] == \"Existing User\"\n",
      "    assert created_user[\"role\"] == \"manager\"\n",
      "\n",
      "    # Step 2: Compute a non-existent ID\n",
      "    created_user_id = created_user[\"user_id\"]\n",
      "    missing_id = created_user_id + 99999\n",
      "\n",
      "    # Step 3: Request the user with the non-existent ID\n",
      "    get_response = client.get(f\"/users/{missing_id}\")\n",
      "    assert get_response.status_code == 404\n",
      "    assert get_response.json()[\"detail\"] == f\"User with ID {missing_id} not found\"\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate edge case tests.\n",
    "edge_case_tests_prompt = f\"\"\"\n",
    "You are a senior QA engineer specializing in FastAPI negative & edge case testing. Generate ONLY Python pytest code (no markdown, no commentary) that adds edge case tests for the provided application.\n",
    "\n",
    "CONTEXT (FastAPI app code):\n",
    "```\n",
    "{app_code}\n",
    "```\n",
    "\n",
    "EDGE CASES TO TEST (exactly two test functions):\n",
    "1. Duplicate Email on User Creation:\n",
    "   - Flow:\n",
    "     * Create a user via POST /users/ (expect 201).\n",
    "     * Re-submit the exact same payload (same email) via POST /users/ (expect 400).\n",
    "   - Assert:\n",
    "     * First response status == 201.\n",
    "     * Second response status == 400.\n",
    "     * Second response JSON contains {{\"detail\": \"An account with this email already exists.\"}} (exact match).\n",
    "2. Get Non-Existent User:\n",
    "   - Flow:\n",
    "     * Create a user (to confirm normal behavior).\n",
    "     * Compute a guaranteed-missing ID = created_user_id + 99999.\n",
    "     * GET /users/{{missing_id}} (expect 404).\n",
    "   - Assert:\n",
    "     * Response status == 404.\n",
    "     * JSON[\"detail\"] == f\"User with ID {{missing_id}} not found\".\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Use: from fastapi.testclient import TestClient\n",
    "- Import: uuid, pytest\n",
    "- Import the FastAPI app as: from app.main import app\n",
    "- Do NOT rely on test execution order; each test self-contained.\n",
    "- Generate unique user emails with uuid (e.g., f\"user_{{uuid.uuid4().hex[:8]}}@example.com\").\n",
    "- Provide exactly two test functions named:\n",
    "    * test_create_user_duplicate_email_rejected\n",
    "    * test_get_user_not_found_returns_404\n",
    "- For the initial successful creation in each test, minimally assert essential fields: user_id (int), email (str), full_name (str), role (str).\n",
    "- No prints, no sleeps, no external file access, no extraneous comments.\n",
    "- Pure Python output. No backticks in final output.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return a single Python file content containing:\n",
    "- All necessary imports at top.\n",
    "- The two test functions only.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Edge Case Tests ---\")\n",
    "if app_code:\n",
    "    generated_edge_case_tests = get_completion(edge_case_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_edge_case_tests = clean_llm_output(generated_edge_case_tests, language='python')\n",
    "    print(cleaned_edge_case_tests)\n",
    "    save_artifact(cleaned_edge_case_tests, \"tests/test_main_edge_cases.py\", base_dir=project_root)\n",
    "else:\n",
    "    print(\"Skipping test generation because app code is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Testing with an Isolated Database Fixture\n",
    "\n",
    "**Task:** Generate a `pytest` fixture that creates a fresh, isolated, in-memory database for each test session. Then, refactor your tests to use this fixture. This is a critical pattern for professional-grade testing.\n",
    "\n",
    "> **Hint:** Why use an isolated database? Running tests against your actual development database can lead to data corruption and flaky, unreliable tests. A pytest fixture that creates a fresh, in-memory database for each test ensures that your tests are independent, repeatable, and have no side effects.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a prompt that asks the LLM to generate a `pytest` fixture.\n",
    "2.  This fixture should configure a temporary, in-memory SQLite database using SQLAlchemy.\n",
    "3.  It needs to create all the database tables before the test runs and tear them down afterward.\n",
    "4.  Crucially, it must override the `get_db` dependency in your FastAPI app to use this temporary database during tests.\n",
    "5.  Save the generated fixture code to a special file named `tests/conftest.py`.\n",
    "6.  Finally, create a new test file, `tests/test_main_with_fixture.py`, and ask the LLM to rewrite the happy-path tests from Challenge 1 to use the new database fixture.\n",
    "\n",
    "**Expected Quality:** Two new files, `tests/conftest.py` and `tests/test_main_with_fixture.py`, containing a professional `pytest` fixture for database isolation and tests that are correctly refactored to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating Pytest DB Fixture ---\n",
      "import pytest\n",
      "from typing import Generator\n",
      "\n",
      "from fastapi.testclient import TestClient\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker, Session\n",
      "\n",
      "# Import the main FastAPI app, the dependency, and the SQLAlchemy Base\n",
      "# This assumes a project structure where 'app' is a package at the root.\n",
      "from app.main import app\n",
      "from app.database import get_db, Base\n",
      "\n",
      "# --- TEST DATABASE SETUP ---\n",
      "\n",
      "# Define the in-memory SQLite database URL for testing\n",
      "SQLALCHEMY_DATABASE_URL = \"sqlite:///:memory:\"\n",
      "\n",
      "# Create a SQLAlchemy engine for the test database\n",
      "# connect_args is needed for SQLite to allow multi-threaded access\n",
      "engine = create_engine(\n",
      "    SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False}\n",
      ")\n",
      "\n",
      "# Create a sessionmaker to generate new Session objects for the test database\n",
      "TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
      "\n",
      "\n",
      "# --- PYTEST FIXTURES ---\n",
      "\n",
      "@pytest.fixture(scope=\"function\")\n",
      "def db_session() -> Generator[Session, None, None]:\n",
      "    \"\"\"\n",
      "    Pytest fixture that creates and yields an isolated SQLAlchemy session\n",
      "    for a single test function. It handles the creation and teardown\n",
      "    of all database tables.\n",
      "\n",
      "    This fixture is useful for tests that need to interact with the\n",
      "    database layer directly.\n",
      "    \"\"\"\n",
      "    # Create all tables in the test database\n",
      "    Base.metadata.create_all(bind=engine)\n",
      "\n",
      "    db = TestingSessionLocal()\n",
      "    try:\n",
      "        # Yield the session to the test function\n",
      "        yield db\n",
      "    finally:\n",
      "        # Ensure the session is closed after the test\n",
      "        db.close()\n",
      "\n",
      "    # Drop all tables to ensure a clean state for the next test\n",
      "    Base.metadata.drop_all(bind=engine)\n",
      "\n",
      "\n",
      "@pytest.fixture(scope=\"function\")\n",
      "def client() -> Generator[TestClient, None, None]:\n",
      "    \"\"\"\n",
      "    Pytest fixture that provides a TestClient instance for API testing.\n",
      "    It manages the test database lifecycle and overrides the `get_db`\n",
      "    dependency to ensure complete isolation.\n",
      "    \"\"\"\n",
      "    def override_get_db() -> Generator[Session, None, None]:\n",
      "        \"\"\"\n",
      "        Dependency override for `get_db` that provides a session from the\n",
      "        test database. This is called for each API request.\n",
      "        \"\"\"\n",
      "        db = TestingSessionLocal()\n",
      "        try:\n",
      "            yield db\n",
      "        finally:\n",
      "            db.close()\n",
      "\n",
      "    # Apply the dependency override to the FastAPI app\n",
      "    app.dependency_overrides[get_db] = override_get_db\n",
      "\n",
      "    # Setup: Create all tables before the test runs\n",
      "    Base.metadata.create_all(bind=engine)\n",
      "\n",
      "    # Yield the TestClient to the test function\n",
      "    yield TestClient(app)\n",
      "\n",
      "    # Teardown: Drop all tables and clear the dependency override\n",
      "    Base.metadata.drop_all(bind=engine)\n",
      "    app.dependency_overrides.clear()\n",
      "\n",
      "--- Generating Refactored Tests ---\n",
      "import pytest\n",
      "from typing import Generator\n",
      "\n",
      "from fastapi.testclient import TestClient\n",
      "from sqlalchemy import create_engine\n",
      "from sqlalchemy.orm import sessionmaker, Session\n",
      "\n",
      "# Import the main FastAPI app, the dependency, and the SQLAlchemy Base\n",
      "# This assumes a project structure where 'app' is a package at the root.\n",
      "from app.main import app\n",
      "from app.database import get_db, Base\n",
      "\n",
      "# --- TEST DATABASE SETUP ---\n",
      "\n",
      "# Define the in-memory SQLite database URL for testing\n",
      "SQLALCHEMY_DATABASE_URL = \"sqlite:///:memory:\"\n",
      "\n",
      "# Create a SQLAlchemy engine for the test database\n",
      "# connect_args is needed for SQLite to allow multi-threaded access\n",
      "engine = create_engine(\n",
      "    SQLALCHEMY_DATABASE_URL, connect_args={\"check_same_thread\": False}\n",
      ")\n",
      "\n",
      "# Create a sessionmaker to generate new Session objects for the test database\n",
      "TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
      "\n",
      "\n",
      "# --- PYTEST FIXTURES ---\n",
      "\n",
      "@pytest.fixture(scope=\"function\")\n",
      "def db_session() -> Generator[Session, None, None]:\n",
      "    \"\"\"\n",
      "    Pytest fixture that creates and yields an isolated SQLAlchemy session\n",
      "    for a single test function. It handles the creation and teardown\n",
      "    of all database tables.\n",
      "\n",
      "    This fixture is useful for tests that need to interact with the\n",
      "    database layer directly.\n",
      "    \"\"\"\n",
      "    # Create all tables in the test database\n",
      "    Base.metadata.create_all(bind=engine)\n",
      "\n",
      "    db = TestingSessionLocal()\n",
      "    try:\n",
      "        # Yield the session to the test function\n",
      "        yield db\n",
      "    finally:\n",
      "        # Ensure the session is closed after the test\n",
      "        db.close()\n",
      "\n",
      "    # Drop all tables to ensure a clean state for the next test\n",
      "    Base.metadata.drop_all(bind=engine)\n",
      "\n",
      "\n",
      "@pytest.fixture(scope=\"function\")\n",
      "def client() -> Generator[TestClient, None, None]:\n",
      "    \"\"\"\n",
      "    Pytest fixture that provides a TestClient instance for API testing.\n",
      "    It manages the test database lifecycle and overrides the `get_db`\n",
      "    dependency to ensure complete isolation.\n",
      "    \"\"\"\n",
      "    def override_get_db() -> Generator[Session, None, None]:\n",
      "        \"\"\"\n",
      "        Dependency override for `get_db` that provides a session from the\n",
      "        test database. This is called for each API request.\n",
      "        \"\"\"\n",
      "        db = TestingSessionLocal()\n",
      "        try:\n",
      "            yield db\n",
      "        finally:\n",
      "            db.close()\n",
      "\n",
      "    # Apply the dependency override to the FastAPI app\n",
      "    app.dependency_overrides[get_db] = override_get_db\n",
      "\n",
      "    # Setup: Create all tables before the test runs\n",
      "    Base.metadata.create_all(bind=engine)\n",
      "\n",
      "    # Yield the TestClient to the test function\n",
      "    yield TestClient(app)\n",
      "\n",
      "    # Teardown: Drop all tables and clear the dependency override\n",
      "    Base.metadata.drop_all(bind=engine)\n",
      "    app.dependency_overrides.clear()\n",
      "\n",
      "--- Generating Refactored Tests ---\n",
      "import datetime\n",
      "import uuid\n",
      "\n",
      "import pytest\n",
      "from fastapi.testclient import TestClient\n",
      "\n",
      "\n",
      "def test_create_user_happy_path_isolated(client: TestClient):\n",
      "    \"\"\"\n",
      "    Tests successful user creation using a fixture-managed client and isolated DB.\n",
      "    \"\"\"\n",
      "    unique_email = f\"testuser_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_data = {\n",
      "        \"full_name\": \"Jane Doe\",\n",
      "        \"email\": unique_email,\n",
      "        \"sso_identifier\": f\"sso_{uuid.uuid4().hex[:12]}\",\n",
      "        \"role\": \"manager\",  # Valid role\n",
      "        \"manager_id\": None,\n",
      "        \"hire_date\": datetime.date.today().isoformat()\n",
      "    }\n",
      "\n",
      "    response = client.post(\"/users/\", json=user_data)\n",
      "\n",
      "    assert response.status_code == 201, response.text\n",
      "\n",
      "    data = response.json()\n",
      "\n",
      "    # Assert shape and types of the response\n",
      "    assert \"user_id\" in data\n",
      "    assert isinstance(data[\"user_id\"], int)\n",
      "    assert \"full_name\" in data\n",
      "    assert isinstance(data[\"full_name\"], str)\n",
      "    assert \"email\" in data\n",
      "    assert isinstance(data[\"email\"], str)\n",
      "    assert \"role\" in data\n",
      "    assert isinstance(data[\"role\"], str)\n",
      "    assert \"hire_date\" in data\n",
      "    assert isinstance(data[\"hire_date\"], str)\n",
      "    assert \"created_at\" in data\n",
      "    assert \"updated_at\" in data\n",
      "\n",
      "    # Assert values from the request are reflected in the response\n",
      "    assert data[\"full_name\"] == user_data[\"full_name\"]\n",
      "    assert data[\"email\"] == user_data[\"email\"]\n",
      "    assert data[\"role\"] == user_data[\"role\"]\n",
      "    assert data[\"hire_date\"] == user_data[\"hire_date\"]\n",
      "\n",
      "\n",
      "def test_get_users_happy_path_isolated(client: TestClient):\n",
      "    \"\"\"\n",
      "    Tests retrieving a list of users, ensuring test isolation by creating a\n",
      "    user within the test.\n",
      "    \"\"\"\n",
      "    # Step 1: Create a user to ensure the list is not empty\n",
      "    unique_email = f\"list_test_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_data = {\n",
      "        \"full_name\": \"List Test User\",\n",
      "        \"email\": unique_email,\n",
      "        \"role\": \"hr_admin\",\n",
      "        \"hire_date\": \"2023-11-01\"\n",
      "    }\n",
      "    create_response = client.post(\"/users/\", json=user_data)\n",
      "    assert create_response.status_code == 201\n",
      "    created_user = create_response.json()\n",
      "    created_user_id = created_user[\"user_id\"]\n",
      "\n",
      "    # Step 2: Request the list of all users\n",
      "    response = client.get(\"/users/\")\n",
      "\n",
      "    assert response.status_code == 200\n",
      "\n",
      "    data = response.json()\n",
      "    assert isinstance(data, list)\n",
      "    assert len(data) >= 1\n",
      "\n",
      "    # Find the user we just created in the list\n",
      "    found_user = next((user for user in data if user[\"user_id\"] == created_user_id), None)\n",
      "\n",
      "    assert found_user is not None\n",
      "    assert found_user[\"email\"] == unique_email\n",
      "    assert found_user[\"full_name\"] == \"List Test User\"\n",
      "    assert \"user_id\" in found_user\n",
      "    assert \"role\" in found_user\n",
      "    assert \"created_at\" in found_user\n",
      "import datetime\n",
      "import uuid\n",
      "\n",
      "import pytest\n",
      "from fastapi.testclient import TestClient\n",
      "\n",
      "\n",
      "def test_create_user_happy_path_isolated(client: TestClient):\n",
      "    \"\"\"\n",
      "    Tests successful user creation using a fixture-managed client and isolated DB.\n",
      "    \"\"\"\n",
      "    unique_email = f\"testuser_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_data = {\n",
      "        \"full_name\": \"Jane Doe\",\n",
      "        \"email\": unique_email,\n",
      "        \"sso_identifier\": f\"sso_{uuid.uuid4().hex[:12]}\",\n",
      "        \"role\": \"manager\",  # Valid role\n",
      "        \"manager_id\": None,\n",
      "        \"hire_date\": datetime.date.today().isoformat()\n",
      "    }\n",
      "\n",
      "    response = client.post(\"/users/\", json=user_data)\n",
      "\n",
      "    assert response.status_code == 201, response.text\n",
      "\n",
      "    data = response.json()\n",
      "\n",
      "    # Assert shape and types of the response\n",
      "    assert \"user_id\" in data\n",
      "    assert isinstance(data[\"user_id\"], int)\n",
      "    assert \"full_name\" in data\n",
      "    assert isinstance(data[\"full_name\"], str)\n",
      "    assert \"email\" in data\n",
      "    assert isinstance(data[\"email\"], str)\n",
      "    assert \"role\" in data\n",
      "    assert isinstance(data[\"role\"], str)\n",
      "    assert \"hire_date\" in data\n",
      "    assert isinstance(data[\"hire_date\"], str)\n",
      "    assert \"created_at\" in data\n",
      "    assert \"updated_at\" in data\n",
      "\n",
      "    # Assert values from the request are reflected in the response\n",
      "    assert data[\"full_name\"] == user_data[\"full_name\"]\n",
      "    assert data[\"email\"] == user_data[\"email\"]\n",
      "    assert data[\"role\"] == user_data[\"role\"]\n",
      "    assert data[\"hire_date\"] == user_data[\"hire_date\"]\n",
      "\n",
      "\n",
      "def test_get_users_happy_path_isolated(client: TestClient):\n",
      "    \"\"\"\n",
      "    Tests retrieving a list of users, ensuring test isolation by creating a\n",
      "    user within the test.\n",
      "    \"\"\"\n",
      "    # Step 1: Create a user to ensure the list is not empty\n",
      "    unique_email = f\"list_test_{uuid.uuid4().hex[:8]}@example.com\"\n",
      "    user_data = {\n",
      "        \"full_name\": \"List Test User\",\n",
      "        \"email\": unique_email,\n",
      "        \"role\": \"hr_admin\",\n",
      "        \"hire_date\": \"2023-11-01\"\n",
      "    }\n",
      "    create_response = client.post(\"/users/\", json=user_data)\n",
      "    assert create_response.status_code == 201\n",
      "    created_user = create_response.json()\n",
      "    created_user_id = created_user[\"user_id\"]\n",
      "\n",
      "    # Step 2: Request the list of all users\n",
      "    response = client.get(\"/users/\")\n",
      "\n",
      "    assert response.status_code == 200\n",
      "\n",
      "    data = response.json()\n",
      "    assert isinstance(data, list)\n",
      "    assert len(data) >= 1\n",
      "\n",
      "    # Find the user we just created in the list\n",
      "    found_user = next((user for user in data if user[\"user_id\"] == created_user_id), None)\n",
      "\n",
      "    assert found_user is not None\n",
      "    assert found_user[\"email\"] == unique_email\n",
      "    assert found_user[\"full_name\"] == \"List Test User\"\n",
      "    assert \"user_id\" in found_user\n",
      "    assert \"role\" in found_user\n",
      "    assert \"created_at\" in found_user\n"
     ]
    }
   ],
   "source": [
    "# TODO: Write a prompt to generate the pytest fixture for an isolated test database.\n",
    "# Provides: in-memory SQLite engine, SessionLocal, override get_db, client & db_session fixtures.\n",
    "db_fixture_prompt = f\"\"\"\n",
    "You are a senior Python QA engineer. Generate ONLY Python code (no markdown) for a pytest fixture module enabling isolated, in-memory database tests for the provided FastAPI app.\n",
    "\n",
    "CONTEXT (FastAPI app code):\n",
    "```\n",
    "{app_code}\n",
    "```\n",
    "\n",
    "GOAL:\n",
    "Create a file tests/conftest.py containing:\n",
    "1. Imports (pytest, uuid, datetime, sqlalchemy components, fastapi.testclient.TestClient).\n",
    "2. Create an in-memory SQLite SQLAlchemy engine: create_engine(\"sqlite:///:memory:\", connect_args={{\"check_same_thread\": False}}).\n",
    "3. Import Base metadata & get_db dependency pieces from the app (derive from app.database / app.main code). If Base not directly exposed, reconstruct via importing the models or using declarative base from existing code.\n",
    "4. Create a SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine).\n",
    "5. A fixture `db_session` (scope=\"function\") that: creates all tables (Base.metadata.create_all(engine)), yields a SQLAlchemy session, then rolls back any pending transaction and drops all tables after test for full isolation (Base.metadata.drop_all(engine)). Ensure the session is closed in a finally block.\n",
    "6. Override the FastAPI dependency get_db to use sessions from SessionLocal inside the test context. Implement a `override_get_db` generator that yields db and closes it.\n",
    "7. Apply app.dependency_overrides[get_db] = override_get_db BEFORE yielding the TestClient fixture.\n",
    "8. Fixture `client` (scope=\"function\") returning TestClient(app) using the overridden dependency; ensures cleanup of dependency_overrides after test.\n",
    "9. Optional helper: `create_user(factory)` function for tests to re-use, but keep minimal.\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Two fixtures: db_session, client.\n",
    "- Use typing Optional where helpful.\n",
    "- Avoid any external file I/O.\n",
    "- No prints, no sleeps.\n",
    "- Pure Python code. No backticks in the final output.\n",
    "- Ensure dropping tables does not raise if already gone (normal call sequence).\n",
    "- Keep comments concise and purposeful.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return ONLY the Python code for tests/conftest.py.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating Pytest DB Fixture ---\")\n",
    "if app_code:\n",
    "    generated_db_fixture = get_completion(db_fixture_prompt, client, model_name, api_provider)\n",
    "    cleaned_fixture = clean_llm_output(generated_db_fixture, language='python')\n",
    "    print(cleaned_fixture)\n",
    "    save_artifact(cleaned_fixture, \"tests/conftest.py\")\n",
    "else:\n",
    "    print(\"Skipping fixture generation because app context is missing.\")\n",
    "\n",
    "# TODO: Write a prompt to refactor the happy path tests to use the new fixture.\n",
    "refactor_tests_prompt = f\"\"\"\n",
    "You are a senior QA engineer. Refactor happy path tests for the provided FastAPI app to use the fixtures from tests/conftest.py (client fixture, and implicit db isolation) rather than instantiating TestClient directly.\n",
    "\n",
    "CONTEXT (FastAPI app code):\n",
    "```\n",
    "{app_code}\n",
    "```\n",
    "\n",
    "EXISTING HAPPY PATH TESTS (logic reference ONLY, do NOT copy imports):\n",
    "```\n",
    "{cleaned_tests}\n",
    "```\n",
    "\n",
    "GOAL:\n",
    "Produce a new file tests/test_main_with_fixture.py containing:\n",
    "- Imports: uuid, pytest, datetime (if needed for hire_date), typing (Optional), and rely on the client fixture.\n",
    "- No direct TestClient(app) instantiation; use the injected `client` fixture parameter.\n",
    "- Two test functions: test_create_user_happy_path_isolated, test_get_users_happy_path_isolated.\n",
    "\n",
    "TEST REQUIREMENTS:\n",
    "1. test_create_user_happy_path_isolated:\n",
    "   - Generate unique email using uuid.\n",
    "   - POST /users/ payload with valid role (choose from new_hire, manager, hr_admin).\n",
    "   - Assert 201 status.\n",
    "   - Assert required fields exist and basic type checks (user_id int, email str, role str, full_name str, hire_date string/date, created_at, updated_at present).\n",
    "2. test_get_users_happy_path_isolated:\n",
    "   - Optionally create one user first (to ensure non-empty list) using same POST logic (unique email).\n",
    "   - GET /users/ -> status 200.\n",
    "   - Assert response is list; if user created, confirm at least one element with expected keys.\n",
    "\n",
    "GENERAL REQUIREMENTS:\n",
    "- Use edge marker pattern if desired? (Skip; keep simple.)\n",
    "- No prints, sleeps, external I/O.\n",
    "- Pure Python only (no markdown, no backticks).\n",
    "- Independent tests (each gets fresh DB due to fixtures).\n",
    "- Keep comments minimal.\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Return ONLY Python code for tests/test_main_with_fixture.py.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Generating Refactored Tests ---\")\n",
    "if app_code:\n",
    "    refactored_tests = get_completion(refactor_tests_prompt, client, model_name, api_provider)\n",
    "    cleaned_refactored_tests = clean_llm_output(refactored_tests, language='python')\n",
    "    print(cleaned_refactored_tests)\n",
    "    save_artifact(cleaned_refactored_tests, \"tests/test_main_with_fixture.py\", base_dir=project_root)\n",
    "else:\n",
    "    print(\"Skipping test refactoring because app context is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Fantastic work! You have built a comprehensive test suite for your API, moving from simple happy path tests to advanced, isolated database testing. You've learned how to use AI to brainstorm edge cases and generate complex fixtures. Having a strong test suite like this gives you the confidence to make changes to your application without fear of breaking existing functionality.\n",
    "\n",
    "> **Key Takeaway:** Using AI to generate tests is a massive force multiplier for quality assurance. It excels at creating boilerplate test code, brainstorming edge cases, and generating complex setup fixtures, allowing developers to build more reliable software faster."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
