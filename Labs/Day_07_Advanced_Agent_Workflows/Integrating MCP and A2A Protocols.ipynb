{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating MCP and A2A Protocols: Building Advanced Multi-Agent Systems with LangChain/LangGraph\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction: Why MCP + A2A?](#introduction)\n",
    "2. [Understanding the Synergy](#synergy)\n",
    "3. [Setting Up Your Environment](#setup)\n",
    "4. [Basic Integration Examples](#basic-integration)\n",
    "5. [MCP-Powered A2A Agents](#mcp-agents)\n",
    "6. [LangChain Integration Patterns](#langchain-integration)\n",
    "7. [Advanced LangGraph Workflows](#langgraph-workflows)\n",
    "8. [Building Production Systems](#production-systems)\n",
    "9. [Best Practices and Patterns](#best-practices)\n",
    "10. [Real-World Use Cases](#use-cases)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction: Why MCP + A2A? <a id=\"introduction\"></a>\n",
    "\n",
    "Imagine building an AI system where multiple specialized agents can not only communicate with each other (A2A) but also access external tools and resources in a standardized way (MCP). This combination creates a powerful paradigm for building sophisticated AI applications.\n",
    "\n",
    "### The Power of Integration\n",
    "\n",
    "**A2A Protocol** enables:\n",
    "- Agent-to-agent communication and collaboration\n",
    "- Distributed intelligence across specialized agents\n",
    "- Dynamic team formation and task delegation\n",
    "- Standardized messaging between different AI systems\n",
    "\n",
    "**MCP Protocol** provides:\n",
    "- Standardized access to tools and resources\n",
    "- Consistent interface for external integrations\n",
    "- Resource discovery and management\n",
    "- Safe execution of tools with proper permissions\n",
    "\n",
    "**Together, they enable:**\n",
    "- Agents that can both collaborate AND use tools\n",
    "- Shared resource access across agent teams\n",
    "- Complex workflows with both communication and action\n",
    "- Scalable, modular AI systems\n",
    "\n",
    "### Real-World Scenario\n",
    "\n",
    "Consider a customer service system where:\n",
    "1. A **Triage Agent** (A2A) receives customer queries\n",
    "2. It uses **MCP tools** to search the knowledge base\n",
    "3. For complex issues, it delegates to a **Specialist Agent** (A2A)\n",
    "4. The Specialist uses **MCP resources** to access customer data\n",
    "5. Multiple agents collaborate to solve the problem\n",
    "6. Each agent has access to different MCP tools based on permissions\n",
    "\n",
    "This tutorial will teach you how to build such systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding the Synergy <a id=\"synergy\"></a>\n",
    "\n",
    "### Architectural Overview\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────┐\n",
    "│                     Integrated MCP + A2A System                  │\n",
    "├─────────────────────────────────────────────────────────────────┤\n",
    "│                                                                 │\n",
    "│  ┌─────────────┐  A2A Protocol   ┌─────────────┐              │\n",
    "│  │   Agent A   │ ◄─────────────► │   Agent B   │              │\n",
    "│  │ (Analyzer)  │                 │ (Executor)  │              │\n",
    "│  └──────┬──────┘                 └──────┬──────┘              │\n",
    "│         │                                │                      │\n",
    "│         │ MCP                           │ MCP                  │\n",
    "│         ▼                                ▼                      │\n",
    "│  ┌─────────────┐                 ┌─────────────┐              │\n",
    "│  │ MCP Server 1│                 │ MCP Server 2│              │\n",
    "│  │  (Database) │                 │   (APIs)    │              │\n",
    "│  └─────────────┘                 └─────────────┘              │\n",
    "│                                                                 │\n",
    "│                    ┌─────────────┐                             │\n",
    "│                    │   Agent C   │                             │\n",
    "│                    │(Coordinator)│                             │\n",
    "│                    └──────┬──────┘                             │\n",
    "│                           │                                     │\n",
    "│                           │ MCP                                 │\n",
    "│                           ▼                                     │\n",
    "│                    ┌─────────────┐                             │\n",
    "│                    │ MCP Server 3│                             │\n",
    "│                    │ (Analytics) │                             │\n",
    "│                    └─────────────┘                             │\n",
    "└─────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Key Integration Points\n",
    "\n",
    "1. **Agent Capabilities Enhanced by MCP Tools**\n",
    "   - Agents declare MCP tools as part of their capabilities\n",
    "   - Other agents can request tool execution indirectly\n",
    "   - Tool access is controlled by agent permissions\n",
    "\n",
    "2. **Shared Resource Access**\n",
    "   - Multiple agents can access the same MCP resources\n",
    "   - Resource state can be synchronized across agents\n",
    "   - Agents can share tool results through A2A messages\n",
    "\n",
    "3. **Coordinated Workflows**\n",
    "   - Agents negotiate who uses which tools\n",
    "   - Complex tasks are broken down across agents and tools\n",
    "   - Results are aggregated through agent communication\n",
    "\n",
    "### Protocol Interaction Patterns\n",
    "\n",
    "**Pattern 1: Tool Delegation**\n",
    "```\n",
    "Agent A ---[A2A: \"Please search for X\"]--> Agent B\n",
    "Agent B ---[MCP: search_tool(X)]-------> MCP Server\n",
    "Agent B <--[MCP: results]-------------- MCP Server\n",
    "Agent A <--[A2A: \"Found Y results\"]---- Agent B\n",
    "```\n",
    "\n",
    "**Pattern 2: Resource Sharing**\n",
    "```\n",
    "Agent A ---[MCP: read_resource]-------> MCP Server\n",
    "Agent A ---[A2A: \"Resource data: {...}\"]--> Agent B\n",
    "Agent B ---[Process data]------------->\n",
    "Agent B ---[A2A: \"Analysis complete\"]--> Agent A\n",
    "```\n",
    "\n",
    "**Pattern 3: Collaborative Tool Use**\n",
    "```\n",
    "Coordinator ---[A2A: \"Start workflow\"]--> Agent A, B, C\n",
    "Agent A -------[MCP: tool_1]----------> MCP Server 1\n",
    "Agent B -------[MCP: tool_2]----------> MCP Server 2\n",
    "Agent C -------[MCP: tool_3]----------> MCP Server 3\n",
    "All Agents ----[A2A: results]--------> Coordinator\n",
    "Coordinator ---[Aggregate & respond]-->\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting Up Your Environment <a id=\"setup\"></a>\n",
    "\n",
    "Let's install and configure everything needed for MCP + A2A integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for both protocols\n",
    "!pip install mcp a2a-protocol langchain langchain-mcp langgraph anthropic openai python-dotenv\n",
    "\n",
    "# For server development\n",
    "!pip install fastapi uvicorn websockets\n",
    "\n",
    "# Additional utilities\n",
    "!pip install aiohttp asyncio-throttle redis aiocache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import List, Dict, Any, Optional, Set, Callable\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "\n",
    "# MCP imports\n",
    "from mcp import ClientSession, StdioServerParameters\n",
    "from mcp.client.stdio import stdio_client\n",
    "\n",
    "# A2A imports\n",
    "from a2a import Agent, Message, Capability, Protocol\n",
    "from a2a.discovery import DiscoveryService\n",
    "from a2a.messages import Request, Response, Event\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_core.tools import Tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_mcp import create_mcp_tools\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# Set up environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"MCP + A2A integration environment ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Basic Integration Examples <a id=\"basic-integration\"></a>\n",
    "\n",
    "Let's start with fundamental examples that show how MCP and A2A work together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: A2A Agent with MCP Tools\n",
    "\n",
    "First, let's create an A2A agent that can use MCP tools. This demonstrates the basic pattern of combining both protocols in a single agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCPEnabledAgent(Agent):\n",
    "    \"\"\"\n",
    "    An A2A agent that has access to MCP tools and resources.\n",
    "    \n",
    "    This demonstrates:\n",
    "    1. How to connect an A2A agent to MCP servers\n",
    "    2. How to expose MCP tools as A2A capabilities\n",
    "    3. How to handle requests that require MCP tool execution\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, mcp_servers: List[Dict[str, Any]]):\n",
    "        super().__init__(name=name)\n",
    "        self.mcp_servers = mcp_servers\n",
    "        self.mcp_sessions = {}  # Store active MCP sessions\n",
    "        self.mcp_tools = {}     # Cache of available MCP tools\n",
    "        \n",
    "        # Initialize base A2A capabilities\n",
    "        self._setup_base_capabilities()\n",
    "    \n",
    "    def _setup_base_capabilities(self):\n",
    "        \"\"\"Set up basic A2A capabilities\"\"\"\n",
    "        self.capabilities = [\n",
    "            Capability(\n",
    "                name=\"list_mcp_tools\",\n",
    "                description=\"List all available MCP tools this agent can access\",\n",
    "                input_schema={\"type\": \"object\", \"properties\": {}}\n",
    "            ),\n",
    "            Capability(\n",
    "                name=\"execute_mcp_tool\",\n",
    "                description=\"Execute an MCP tool on behalf of another agent\",\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"tool_name\": {\"type\": \"string\"},\n",
    "                        \"arguments\": {\"type\": \"object\"}\n",
    "                    },\n",
    "                    \"required\": [\"tool_name\", \"arguments\"]\n",
    "                }\n",
    "            ),\n",
    "            Capability(\n",
    "                name=\"read_mcp_resource\",\n",
    "                description=\"Read an MCP resource\",\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"resource_uri\": {\"type\": \"string\"}\n",
    "                    },\n",
    "                    \"required\": [\"resource_uri\"]\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    async def connect_to_mcp_servers(self):\n",
    "        \"\"\"\n",
    "        Connect to all configured MCP servers and discover their tools.\n",
    "        \n",
    "        This method:\n",
    "        1. Establishes connections to MCP servers\n",
    "        2. Discovers available tools and resources\n",
    "        3. Creates A2A capabilities for each MCP tool\n",
    "        \"\"\"\n",
    "        for server_config in self.mcp_servers:\n",
    "            server_name = server_config[\"name\"]\n",
    "            \n",
    "            # In practice, you would establish real MCP connections here\n",
    "            # For demonstration, we'll simulate the connection\n",
    "            print(f\"Connecting to MCP server: {server_name}\")\n",
    "            \n",
    "            # Simulate discovering tools from this MCP server\n",
    "            if server_name == \"database_server\":\n",
    "                tools = [\n",
    "                    {\"name\": \"query_customers\", \"description\": \"Query customer database\"},\n",
    "                    {\"name\": \"update_customer\", \"description\": \"Update customer record\"}\n",
    "                ]\n",
    "            elif server_name == \"analytics_server\":\n",
    "                tools = [\n",
    "                    {\"name\": \"calculate_metrics\", \"description\": \"Calculate business metrics\"},\n",
    "                    {\"name\": \"generate_report\", \"description\": \"Generate analytics report\"}\n",
    "                ]\n",
    "            else:\n",
    "                tools = []\n",
    "            \n",
    "            # Store tools and create A2A capabilities for them\n",
    "            for tool in tools:\n",
    "                tool_id = f\"{server_name}.{tool['name']}\"\n",
    "                self.mcp_tools[tool_id] = {\n",
    "                    \"server\": server_name,\n",
    "                    \"tool\": tool,\n",
    "                    \"available\": True\n",
    "                }\n",
    "                \n",
    "                # Create an A2A capability for this MCP tool\n",
    "                capability = Capability(\n",
    "                    name=f\"mcp_{tool_id}\",\n",
    "                    description=f\"MCP Tool: {tool['description']}\",\n",
    "                    input_schema={\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"arguments\": {\"type\": \"object\"}\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "                self.capabilities.append(capability)\n",
    "        \n",
    "        print(f\"Connected to {len(self.mcp_servers)} MCP servers\")\n",
    "        print(f\"Discovered {len(self.mcp_tools)} MCP tools\")\n",
    "    \n",
    "    async def handle_request(self, request: Request) -> Response:\n",
    "        \"\"\"\n",
    "        Handle A2A requests, including those that require MCP tool execution.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if request.capability == \"list_mcp_tools\":\n",
    "                # Return list of available MCP tools\n",
    "                tools_list = [\n",
    "                    {\n",
    "                        \"id\": tool_id,\n",
    "                        \"server\": info[\"server\"],\n",
    "                        \"name\": info[\"tool\"][\"name\"],\n",
    "                        \"description\": info[\"tool\"][\"description\"],\n",
    "                        \"available\": info[\"available\"]\n",
    "                    }\n",
    "                    for tool_id, info in self.mcp_tools.items()\n",
    "                ]\n",
    "                return Response(\n",
    "                    request_id=request.id,\n",
    "                    data={\"tools\": tools_list}\n",
    "                )\n",
    "            \n",
    "            elif request.capability == \"execute_mcp_tool\":\n",
    "                # Execute an MCP tool\n",
    "                tool_name = request.data[\"tool_name\"]\n",
    "                arguments = request.data[\"arguments\"]\n",
    "                \n",
    "                if tool_name not in self.mcp_tools:\n",
    "                    return Response(\n",
    "                        request_id=request.id,\n",
    "                        error={\"code\": \"TOOL_NOT_FOUND\", \"message\": f\"Tool {tool_name} not found\"}\n",
    "                    )\n",
    "                \n",
    "                # Simulate MCP tool execution\n",
    "                result = await self._execute_mcp_tool(tool_name, arguments)\n",
    "                \n",
    "                return Response(\n",
    "                    request_id=request.id,\n",
    "                    data={\"result\": result}\n",
    "                )\n",
    "            \n",
    "            elif request.capability.startswith(\"mcp_\"):\n",
    "                # Direct MCP tool capability\n",
    "                tool_id = request.capability[4:]  # Remove 'mcp_' prefix\n",
    "                arguments = request.data.get(\"arguments\", {})\n",
    "                \n",
    "                result = await self._execute_mcp_tool(tool_id, arguments)\n",
    "                \n",
    "                return Response(\n",
    "                    request_id=request.id,\n",
    "                    data={\"result\": result}\n",
    "                )\n",
    "            \n",
    "            else:\n",
    "                return Response(\n",
    "                    request_id=request.id,\n",
    "                    error={\"code\": \"UNKNOWN_CAPABILITY\", \"message\": f\"Unknown capability: {request.capability}\"}\n",
    "                )\n",
    "        \n",
    "        except Exception as e:\n",
    "            return Response(\n",
    "                request_id=request.id,\n",
    "                error={\"code\": \"INTERNAL_ERROR\", \"message\": str(e)}\n",
    "            )\n",
    "    \n",
    "    async def _execute_mcp_tool(self, tool_id: str, arguments: Dict[str, Any]) -> Any:\n",
    "        \"\"\"\n",
    "        Execute an MCP tool and return the result.\n",
    "        \n",
    "        In a real implementation, this would:\n",
    "        1. Connect to the appropriate MCP server\n",
    "        2. Call the tool with the given arguments\n",
    "        3. Return the result\n",
    "        \"\"\"\n",
    "        # Simulate tool execution based on tool ID\n",
    "        if \"query_customers\" in tool_id:\n",
    "            return {\n",
    "                \"customers\": [\n",
    "                    {\"id\": 1, \"name\": \"Alice Corp\", \"status\": \"active\"},\n",
    "                    {\"id\": 2, \"name\": \"Bob Industries\", \"status\": \"active\"}\n",
    "                ],\n",
    "                \"total\": 2\n",
    "            }\n",
    "        elif \"calculate_metrics\" in tool_id:\n",
    "            return {\n",
    "                \"metric\": arguments.get(\"metric_type\", \"revenue\"),\n",
    "                \"value\": 1250000,\n",
    "                \"period\": \"Q1 2024\",\n",
    "                \"growth\": \"+15%\"\n",
    "            }\n",
    "        else:\n",
    "            return {\"status\": \"executed\", \"tool\": tool_id, \"arguments\": arguments}\n",
    "\n",
    "# Create and initialize an MCP-enabled A2A agent\n",
    "async def create_mcp_agent():\n",
    "    \"\"\"Create and initialize an MCP-enabled agent\"\"\"\n",
    "    # Configure MCP servers\n",
    "    mcp_servers = [\n",
    "        {\"name\": \"database_server\", \"command\": [\"python\", \"db_mcp_server.py\"]},\n",
    "        {\"name\": \"analytics_server\", \"command\": [\"python\", \"analytics_mcp_server.py\"]}\n",
    "    ]\n",
    "    \n",
    "    # Create agent\n",
    "    agent = MCPEnabledAgent(\"DataAnalyst\", mcp_servers)\n",
    "    \n",
    "    # Connect to MCP servers\n",
    "    await agent.connect_to_mcp_servers()\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# Demonstrate the agent\n",
    "# agent = await create_mcp_agent()\n",
    "print(\"\\nMCP-Enabled A2A Agent Pattern:\")\n",
    "print(\"1. A2A agents can connect to multiple MCP servers\")\n",
    "print(\"2. MCP tools are exposed as A2A capabilities\")\n",
    "print(\"3. Other agents can request MCP tool execution via A2A\")\n",
    "print(\"4. Results flow back through the A2A protocol\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Agent Collaboration with Shared MCP Resources\n",
    "\n",
    "Now let's see how multiple A2A agents can collaborate while sharing access to MCP resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchCoordinator(Agent):\n",
    "    \"\"\"\n",
    "    Coordinates research tasks across multiple agents with MCP access.\n",
    "    \n",
    "    This demonstrates:\n",
    "    1. Task delegation to specialized agents\n",
    "    2. Coordinating MCP resource access\n",
    "    3. Aggregating results from multiple sources\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"ResearchCoordinator\")\n",
    "        self.research_team = {}  # Registry of available research agents\n",
    "        self.active_tasks = {}   # Track ongoing research tasks\n",
    "        \n",
    "        self.capabilities = [\n",
    "            Capability(\n",
    "                name=\"conduct_research\",\n",
    "                description=\"Coordinate a research task across multiple agents and MCP resources\",\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"topic\": {\"type\": \"string\", \"description\": \"Research topic\"},\n",
    "                        \"depth\": {\"type\": \"string\", \"enum\": [\"quick\", \"standard\", \"comprehensive\"]},\n",
    "                        \"sources\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                    },\n",
    "                    \"required\": [\"topic\"]\n",
    "                }\n",
    "            ),\n",
    "            Capability(\n",
    "                name=\"get_research_status\",\n",
    "                description=\"Get status of ongoing research tasks\",\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"task_id\": {\"type\": \"string\"}\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    def register_team_member(self, agent_id: str, agent_info: Dict[str, Any]):\n",
    "        \"\"\"Register a research team member\"\"\"\n",
    "        self.research_team[agent_id] = agent_info\n",
    "    \n",
    "    async def handle_request(self, request: Request) -> Response:\n",
    "        \"\"\"Handle research coordination requests\"\"\"\n",
    "        if request.capability == \"conduct_research\":\n",
    "            topic = request.data[\"topic\"]\n",
    "            depth = request.data.get(\"depth\", \"standard\")\n",
    "            sources = request.data.get(\"sources\", [\"database\", \"web\", \"analytics\"])\n",
    "            \n",
    "            # Create research task\n",
    "            task_id = str(uuid.uuid4())\n",
    "            self.active_tasks[task_id] = {\n",
    "                \"topic\": topic,\n",
    "                \"depth\": depth,\n",
    "                \"sources\": sources,\n",
    "                \"status\": \"planning\",\n",
    "                \"subtasks\": [],\n",
    "                \"results\": {}\n",
    "            }\n",
    "            \n",
    "            # Plan research subtasks\n",
    "            subtasks = await self._plan_research(topic, depth, sources)\n",
    "            self.active_tasks[task_id][\"subtasks\"] = subtasks\n",
    "            self.active_tasks[task_id][\"status\"] = \"executing\"\n",
    "            \n",
    "            # Execute research asynchronously\n",
    "            asyncio.create_task(self._execute_research(task_id))\n",
    "            \n",
    "            return Response(\n",
    "                request_id=request.id,\n",
    "                data={\n",
    "                    \"task_id\": task_id,\n",
    "                    \"status\": \"started\",\n",
    "                    \"estimated_time\": \"2-5 minutes\",\n",
    "                    \"subtasks\": len(subtasks)\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        elif request.capability == \"get_research_status\":\n",
    "            task_id = request.data.get(\"task_id\")\n",
    "            if task_id in self.active_tasks:\n",
    "                task = self.active_tasks[task_id]\n",
    "                return Response(\n",
    "                    request_id=request.id,\n",
    "                    data={\n",
    "                        \"task_id\": task_id,\n",
    "                        \"status\": task[\"status\"],\n",
    "                        \"progress\": self._calculate_progress(task),\n",
    "                        \"results_available\": len(task[\"results\"]) > 0\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                return Response(\n",
    "                    request_id=request.id,\n",
    "                    error={\"code\": \"TASK_NOT_FOUND\", \"message\": f\"Task {task_id} not found\"}\n",
    "                )\n",
    "    \n",
    "    async def _plan_research(self, topic: str, depth: str, sources: List[str]) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Plan research subtasks based on topic and requirements\"\"\"\n",
    "        subtasks = []\n",
    "        \n",
    "        # Database search subtask\n",
    "        if \"database\" in sources:\n",
    "            subtasks.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"type\": \"database_search\",\n",
    "                \"agent\": \"DataAnalyst\",\n",
    "                \"mcp_tools\": [\"query_customers\", \"query_transactions\"],\n",
    "                \"parameters\": {\"topic\": topic, \"limit\": 10 if depth == \"quick\" else 50}\n",
    "            })\n",
    "        \n",
    "        # Web search subtask\n",
    "        if \"web\" in sources:\n",
    "            subtasks.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"type\": \"web_search\",\n",
    "                \"agent\": \"WebResearcher\",\n",
    "                \"mcp_tools\": [\"search_web\", \"extract_content\"],\n",
    "                \"parameters\": {\"query\": topic, \"max_results\": 5 if depth == \"quick\" else 20}\n",
    "            })\n",
    "        \n",
    "        # Analytics subtask\n",
    "        if \"analytics\" in sources:\n",
    "            subtasks.append({\n",
    "                \"id\": str(uuid.uuid4()),\n",
    "                \"type\": \"analytics\",\n",
    "                \"agent\": \"DataAnalyst\",\n",
    "                \"mcp_tools\": [\"calculate_metrics\", \"generate_report\"],\n",
    "                \"parameters\": {\"topic\": topic, \"metrics\": [\"trend\", \"correlation\", \"forecast\"]}\n",
    "            })\n",
    "        \n",
    "        return subtasks\n",
    "    \n",
    "    async def _execute_research(self, task_id: str):\n",
    "        \"\"\"Execute research subtasks by delegating to appropriate agents\"\"\"\n",
    "        task = self.active_tasks[task_id]\n",
    "        \n",
    "        for subtask in task[\"subtasks\"]:\n",
    "            # Find the appropriate agent\n",
    "            agent_name = subtask[\"agent\"]\n",
    "            \n",
    "            # Create A2A request for the subtask\n",
    "            if subtask[\"type\"] == \"database_search\":\n",
    "                # Request database search via MCP tools\n",
    "                request = Request(\n",
    "                    id=str(uuid.uuid4()),\n",
    "                    from_agent=self.id,\n",
    "                    to_agent=agent_name,\n",
    "                    capability=\"execute_mcp_tool\",\n",
    "                    data={\n",
    "                        \"tool_name\": \"database_server.query_customers\",\n",
    "                        \"arguments\": {\n",
    "                            \"query\": subtask[\"parameters\"][\"topic\"],\n",
    "                            \"limit\": subtask[\"parameters\"][\"limit\"]\n",
    "                        }\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "                # Simulate sending request and receiving response\n",
    "                # In practice, this would use actual A2A communication\n",
    "                result = {\n",
    "                    \"source\": \"database\",\n",
    "                    \"data\": f\"Found {subtask['parameters']['limit']} relevant records for {subtask['parameters']['topic']}\"\n",
    "                }\n",
    "                \n",
    "                task[\"results\"][subtask[\"id\"]] = result\n",
    "        \n",
    "        # Update task status\n",
    "        task[\"status\"] = \"completed\"\n",
    "    \n",
    "    def _calculate_progress(self, task: Dict[str, Any]) -> float:\n",
    "        \"\"\"Calculate research progress percentage\"\"\"\n",
    "        if task[\"status\"] == \"planning\":\n",
    "            return 0.1\n",
    "        elif task[\"status\"] == \"executing\":\n",
    "            completed = len(task[\"results\"])\n",
    "            total = len(task[\"subtasks\"])\n",
    "            return 0.1 + (0.8 * (completed / total)) if total > 0 else 0.1\n",
    "        elif task[\"status\"] == \"completed\":\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "\n",
    "# Create a research system\n",
    "print(\"Multi-Agent Research System with MCP Integration:\")\n",
    "print(\"\\nComponents:\")\n",
    "print(\"1. Research Coordinator (A2A) - Plans and delegates tasks\")\n",
    "print(\"2. Data Analyst (A2A + MCP) - Accesses databases and analytics\")\n",
    "print(\"3. Web Researcher (A2A + MCP) - Searches web resources\")\n",
    "print(\"4. Report Generator (A2A + MCP) - Creates final reports\")\n",
    "print(\"\\nWorkflow:\")\n",
    "print(\"1. Coordinator receives research request\")\n",
    "print(\"2. Plans subtasks based on topic and sources\")\n",
    "print(\"3. Delegates to specialized agents via A2A\")\n",
    "print(\"4. Agents use MCP tools to gather data\")\n",
    "print(\"5. Results flow back through A2A messages\")\n",
    "print(\"6. Coordinator aggregates and returns findings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. MCP-Powered A2A Agents <a id=\"mcp-agents\"></a>\n",
    "\n",
    "Let's explore advanced patterns for creating A2A agents that leverage MCP capabilities effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartMCPAgent(Agent):\n",
    "    \"\"\"\n",
    "    An intelligent A2A agent that can:\n",
    "    1. Dynamically discover and use MCP tools\n",
    "    2. Learn which tools work best for different tasks\n",
    "    3. Share tool recommendations with other agents\n",
    "    4. Cache tool results for efficiency\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name: str, specialization: str):\n",
    "        super().__init__(name=name)\n",
    "        self.specialization = specialization\n",
    "        self.tool_performance_metrics = {}  # Track tool effectiveness\n",
    "        self.tool_cache = {}  # Cache recent tool results\n",
    "        self.peer_recommendations = {}  # Tool recommendations from other agents\n",
    "        \n",
    "        self._setup_intelligent_capabilities()\n",
    "    \n",
    "    def _setup_intelligent_capabilities(self):\n",
    "        \"\"\"Set up capabilities for intelligent MCP usage\"\"\"\n",
    "        self.capabilities = [\n",
    "            Capability(\n",
    "                name=\"smart_tool_selection\",\n",
    "                description=\"Intelligently select and execute the best MCP tool for a task\",\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"task_description\": {\"type\": \"string\"},\n",
    "                        \"constraints\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"max_time_ms\": {\"type\": \"integer\"},\n",
    "                                \"preferred_sources\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                            }\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"task_description\"]\n",
    "                }\n",
    "            ),\n",
    "            Capability(\n",
    "                name=\"recommend_tools\",\n",
    "                description=\"Recommend MCP tools based on task requirements\",\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"task_type\": {\"type\": \"string\"},\n",
    "                        \"requirements\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "                    },\n",
    "                    \"required\": [\"task_type\"]\n",
    "                }\n",
    "            ),\n",
    "            Capability(\n",
    "                name=\"share_tool_metrics\",\n",
    "                description=\"Share performance metrics about MCP tools with other agents\",\n",
    "                input_schema={\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"tool_filter\": {\"type\": \"string\", \"description\": \"Filter for specific tools\"}\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    \n",
    "    async def analyze_task_requirements(self, task_description: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Analyze a task to determine MCP tool requirements.\n",
    "        \n",
    "        This method demonstrates how agents can intelligently:\n",
    "        1. Parse task descriptions\n",
    "        2. Map tasks to tool capabilities\n",
    "        3. Consider performance history\n",
    "        \"\"\"\n",
    "        # Simple keyword-based analysis (in practice, use NLP)\n",
    "        analysis = {\n",
    "            \"task_type\": \"unknown\",\n",
    "            \"required_capabilities\": [],\n",
    "            \"recommended_tools\": []\n",
    "        }\n",
    "        \n",
    "        task_lower = task_description.lower()\n",
    "        \n",
    "        # Determine task type and requirements\n",
    "        if \"search\" in task_lower or \"find\" in task_lower:\n",
    "            analysis[\"task_type\"] = \"search\"\n",
    "            analysis[\"required_capabilities\"].append(\"query\")\n",
    "            \n",
    "            if \"customer\" in task_lower:\n",
    "                analysis[\"recommended_tools\"].append(\"database_server.query_customers\")\n",
    "            if \"web\" in task_lower or \"online\" in task_lower:\n",
    "                analysis[\"recommended_tools\"].append(\"web_server.search_web\")\n",
    "        \n",
    "        elif \"analyze\" in task_lower or \"calculate\" in task_lower:\n",
    "            analysis[\"task_type\"] = \"analytics\"\n",
    "            analysis[\"required_capabilities\"].append(\"computation\")\n",
    "            analysis[\"recommended_tools\"].append(\"analytics_server.calculate_metrics\")\n",
    "        \n",
    "        elif \"report\" in task_lower or \"summary\" in task_lower:\n",
    "            analysis[\"task_type\"] = \"reporting\"\n",
    "            analysis[\"required_capabilities\"].append(\"aggregation\")\n",
    "            analysis[\"recommended_tools\"].append(\"analytics_server.generate_report\")\n",
    "        \n",
    "        # Consider performance metrics\n",
    "        for tool in analysis[\"recommended_tools\"]:\n",
    "            if tool in self.tool_performance_metrics:\n",
    "                metrics = self.tool_performance_metrics[tool]\n",
    "                if metrics[\"success_rate\"] < 0.7:  # Poor performing tool\n",
    "                    # Look for alternatives\n",
    "                    analysis[\"recommended_tools\"].append(f\"{tool}_alternative\")\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    async def execute_with_caching(self, tool_name: str, arguments: Dict[str, Any]) -> Any:\n",
    "        \"\"\"\n",
    "        Execute MCP tool with intelligent caching.\n",
    "        \"\"\"\n",
    "        # Generate cache key\n",
    "        cache_key = f\"{tool_name}:{json.dumps(arguments, sort_keys=True)}\"\n",
    "        \n",
    "        # Check cache\n",
    "        if cache_key in self.tool_cache:\n",
    "            cached_result, timestamp = self.tool_cache[cache_key]\n",
    "            age_seconds = (datetime.now() - timestamp).total_seconds()\n",
    "            \n",
    "            # Use cache if fresh enough (5 minutes for this example)\n",
    "            if age_seconds < 300:\n",
    "                return {\n",
    "                    \"result\": cached_result,\n",
    "                    \"cached\": True,\n",
    "                    \"cache_age_seconds\": age_seconds\n",
    "                }\n",
    "        \n",
    "        # Execute tool\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        # Simulate MCP tool execution\n",
    "        result = {\"status\": \"success\", \"data\": f\"Result from {tool_name}\"}\n",
    "        \n",
    "        execution_time = (datetime.now() - start_time).total_seconds()\n",
    "        \n",
    "        # Update cache\n",
    "        self.tool_cache[cache_key] = (result, datetime.now())\n",
    "        \n",
    "        # Update performance metrics\n",
    "        if tool_name not in self.tool_performance_metrics:\n",
    "            self.tool_performance_metrics[tool_name] = {\n",
    "                \"executions\": 0,\n",
    "                \"total_time\": 0,\n",
    "                \"success_rate\": 1.0\n",
    "            }\n",
    "        \n",
    "        metrics = self.tool_performance_metrics[tool_name]\n",
    "        metrics[\"executions\"] += 1\n",
    "        metrics[\"total_time\"] += execution_time\n",
    "        metrics[\"average_time\"] = metrics[\"total_time\"] / metrics[\"executions\"]\n",
    "        \n",
    "        return {\n",
    "            \"result\": result,\n",
    "            \"cached\": False,\n",
    "            \"execution_time\": execution_time\n",
    "        }\n",
    "    \n",
    "    async def handle_request(self, request: Request) -> Response:\n",
    "        \"\"\"Handle intelligent MCP-related requests\"\"\"\n",
    "        if request.capability == \"smart_tool_selection\":\n",
    "            task_description = request.data[\"task_description\"]\n",
    "            constraints = request.data.get(\"constraints\", {})\n",
    "            \n",
    "            # Analyze task\n",
    "            analysis = await self.analyze_task_requirements(task_description)\n",
    "            \n",
    "            # Select best tool\n",
    "            recommended_tools = analysis[\"recommended_tools\"]\n",
    "            if not recommended_tools:\n",
    "                return Response(\n",
    "                    request_id=request.id,\n",
    "                    error={\"code\": \"NO_SUITABLE_TOOL\", \"message\": \"No suitable MCP tool found for this task\"}\n",
    "                )\n",
    "            \n",
    "            # Execute with the best tool\n",
    "            best_tool = recommended_tools[0]  # In practice, use more sophisticated selection\n",
    "            result = await self.execute_with_caching(best_tool, {\"task\": task_description})\n",
    "            \n",
    "            return Response(\n",
    "                request_id=request.id,\n",
    "                data={\n",
    "                    \"tool_used\": best_tool,\n",
    "                    \"result\": result,\n",
    "                    \"analysis\": analysis\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        elif request.capability == \"recommend_tools\":\n",
    "            task_type = request.data[\"task_type\"]\n",
    "            requirements = request.data.get(\"requirements\", [])\n",
    "            \n",
    "            # Get recommendations based on performance metrics\n",
    "            recommendations = []\n",
    "            for tool_name, metrics in self.tool_performance_metrics.items():\n",
    "                if metrics[\"success_rate\"] > 0.8 and metrics[\"average_time\"] < 1.0:\n",
    "                    recommendations.append({\n",
    "                        \"tool\": tool_name,\n",
    "                        \"performance\": {\n",
    "                            \"success_rate\": metrics[\"success_rate\"],\n",
    "                            \"average_time\": metrics[\"average_time\"],\n",
    "                            \"executions\": metrics[\"executions\"]\n",
    "                        },\n",
    "                        \"suitable_for\": [task_type] if task_type in tool_name.lower() else []\n",
    "                    })\n",
    "            \n",
    "            return Response(\n",
    "                request_id=request.id,\n",
    "                data={\"recommendations\": recommendations}\n",
    "            )\n",
    "        \n",
    "        elif request.capability == \"share_tool_metrics\":\n",
    "            tool_filter = request.data.get(\"tool_filter\", \"\")\n",
    "            \n",
    "            # Filter and share metrics\n",
    "            shared_metrics = {}\n",
    "            for tool_name, metrics in self.tool_performance_metrics.items():\n",
    "                if not tool_filter or tool_filter in tool_name:\n",
    "                    shared_metrics[tool_name] = metrics\n",
    "            \n",
    "            return Response(\n",
    "                request_id=request.id,\n",
    "                data={\n",
    "                    \"agent\": self.name,\n",
    "                    \"specialization\": self.specialization,\n",
    "                    \"metrics\": shared_metrics\n",
    "                }\n",
    "            )\n",
    "\n",
    "# Demonstrate intelligent MCP usage\n",
    "print(\"Intelligent MCP-Powered A2A Agent Features:\")\n",
    "print(\"\\n1. **Smart Tool Selection**\")\n",
    "print(\"   - Analyzes task requirements\")\n",
    "print(\"   - Selects optimal MCP tools\")\n",
    "print(\"   - Considers performance history\")\n",
    "print(\"\\n2. **Performance Tracking**\")\n",
    "print(\"   - Monitors tool execution times\")\n",
    "print(\"   - Tracks success rates\")\n",
    "print(\"   - Learns from experience\")\n",
    "print(\"\\n3. **Intelligent Caching**\")\n",
    "print(\"   - Caches MCP tool results\")\n",
    "print(\"   - Reduces redundant executions\")\n",
    "print(\"   - Improves response times\")\n",
    "print(\"\\n4. **Peer Learning**\")\n",
    "print(\"   - Shares tool recommendations\")\n",
    "print(\"   - Learns from other agents\")\n",
    "print(\"   - Builds collective intelligence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LangChain Integration Patterns <a id=\"langchain-integration\"></a>\n",
    "\n",
    "Now let's explore how to integrate both MCP and A2A protocols with LangChain for powerful agent orchestration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain.llms.fake import FakeListLLM\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "class UnifiedProtocolAdapter:\n",
    "    \"\"\"\n",
    "    Adapts both MCP tools and A2A capabilities to LangChain tools.\n",
    "    \n",
    "    This enables LangChain agents to:\n",
    "    1. Use MCP tools directly\n",
    "    2. Communicate with A2A agents\n",
    "    3. Orchestrate complex workflows across both protocols\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mcp_sessions: Dict[str, Any], a2a_agents: Dict[str, Agent]):\n",
    "        self.mcp_sessions = mcp_sessions\n",
    "        self.a2a_agents = a2a_agents\n",
    "        self.tools_cache = {}\n",
    "    \n",
    "    def create_mcp_tool(self, server_name: str, tool_name: str, tool_info: Dict[str, Any]) -> Tool:\n",
    "        \"\"\"\n",
    "        Create a LangChain tool from an MCP tool.\n",
    "        \"\"\"\n",
    "        def tool_func(**kwargs) -> str:\n",
    "            # In practice, this would call the actual MCP tool\n",
    "            result = f\"Executed MCP tool {tool_name} on {server_name} with args: {kwargs}\"\n",
    "            \n",
    "            # Simulate MCP tool execution\n",
    "            if tool_name == \"search_database\":\n",
    "                return json.dumps({\n",
    "                    \"results\": f\"Found 5 records matching {kwargs.get('query', '')}\",\n",
    "                    \"source\": \"MCP database server\"\n",
    "                })\n",
    "            elif tool_name == \"analyze_data\":\n",
    "                return json.dumps({\n",
    "                    \"analysis\": f\"Analyzed data for {kwargs.get('topic', '')}\",\n",
    "                    \"insights\": [\"Trend is positive\", \"Growth rate: 15%\"],\n",
    "                    \"source\": \"MCP analytics server\"\n",
    "                })\n",
    "            else:\n",
    "                return result\n",
    "        \n",
    "        return Tool(\n",
    "            name=f\"mcp_{server_name}_{tool_name}\",\n",
    "            description=f\"MCP Tool: {tool_info.get('description', tool_name)}\",\n",
    "            func=tool_func\n",
    "        )\n",
    "    \n",
    "    def create_a2a_tool(self, agent_id: str, capability: Capability) -> Tool:\n",
    "        \"\"\"\n",
    "        Create a LangChain tool from an A2A agent capability.\n",
    "        \"\"\"\n",
    "        def tool_func(**kwargs) -> str:\n",
    "            # Create A2A request\n",
    "            request = Request(\n",
    "                id=str(uuid.uuid4()),\n",
    "                from_agent=\"langchain_agent\",\n",
    "                to_agent=agent_id,\n",
    "                capability=capability.name,\n",
    "                data=kwargs\n",
    "            )\n",
    "            \n",
    "            # In practice, this would send the request via A2A protocol\n",
    "            # For demonstration, simulate the response\n",
    "            if capability.name == \"analyze_market\":\n",
    "                return json.dumps({\n",
    "                    \"analysis\": f\"Market analysis for {kwargs.get('sector', 'general')}\",\n",
    "                    \"recommendation\": \"Buy\",\n",
    "                    \"confidence\": 0.85,\n",
    "                    \"source\": f\"A2A agent: {agent_id}\"\n",
    "                })\n",
    "            elif capability.name == \"generate_report\":\n",
    "                return json.dumps({\n",
    "                    \"report\": f\"Generated report on {kwargs.get('topic', 'general topic')}\",\n",
    "                    \"sections\": [\"Executive Summary\", \"Analysis\", \"Recommendations\"],\n",
    "                    \"source\": f\"A2A agent: {agent_id}\"\n",
    "                })\n",
    "            else:\n",
    "                return f\"Executed A2A capability {capability.name} on agent {agent_id}\"\n",
    "        \n",
    "        return Tool(\n",
    "            name=f\"a2a_{agent_id}_{capability.name}\",\n",
    "            description=f\"A2A Capability: {capability.description}\",\n",
    "            func=tool_func\n",
    "        )\n",
    "    \n",
    "    def create_unified_tools(self) -> List[Tool]:\n",
    "        \"\"\"\n",
    "        Create a unified set of LangChain tools from both MCP and A2A sources.\n",
    "        \"\"\"\n",
    "        tools = []\n",
    "        \n",
    "        # Add MCP tools\n",
    "        mcp_tools_config = {\n",
    "            \"database_server\": [\n",
    "                {\"name\": \"search_database\", \"description\": \"Search customer database\"},\n",
    "                {\"name\": \"update_records\", \"description\": \"Update database records\"}\n",
    "            ],\n",
    "            \"analytics_server\": [\n",
    "                {\"name\": \"analyze_data\", \"description\": \"Perform data analysis\"},\n",
    "                {\"name\": \"create_visualization\", \"description\": \"Create data visualizations\"}\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        for server_name, server_tools in mcp_tools_config.items():\n",
    "            for tool_info in server_tools:\n",
    "                tool = self.create_mcp_tool(server_name, tool_info[\"name\"], tool_info)\n",
    "                tools.append(tool)\n",
    "        \n",
    "        # Add A2A capabilities\n",
    "        # Simulate some A2A agents with capabilities\n",
    "        a2a_capabilities = {\n",
    "            \"MarketAnalyst\": [\n",
    "                Capability(\"analyze_market\", \"Analyze market trends and provide insights\", {}),\n",
    "                Capability(\"predict_trends\", \"Predict future market trends\", {})\n",
    "            ],\n",
    "            \"ReportGenerator\": [\n",
    "                Capability(\"generate_report\", \"Generate comprehensive reports\", {}),\n",
    "                Capability(\"create_summary\", \"Create executive summaries\", {})\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        for agent_id, capabilities in a2a_capabilities.items():\n",
    "            for capability in capabilities:\n",
    "                tool = self.create_a2a_tool(agent_id, capability)\n",
    "                tools.append(tool)\n",
    "        \n",
    "        return tools\n",
    "\n",
    "# Create unified tools\n",
    "adapter = UnifiedProtocolAdapter(mcp_sessions={}, a2a_agents={})\n",
    "unified_tools = adapter.create_unified_tools()\n",
    "\n",
    "print(\"Created Unified LangChain Tools:\")\n",
    "print(\"\\nMCP Tools:\")\n",
    "for tool in unified_tools:\n",
    "    if tool.name.startswith(\"mcp_\"):\n",
    "        print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "print(\"\\nA2A Tools:\")\n",
    "for tool in unified_tools:\n",
    "    if tool.name.startswith(\"a2a_\"):\n",
    "        print(f\"  - {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Unified LangChain Agent\n",
    "\n",
    "Now let's create a LangChain agent that can seamlessly use both MCP tools and A2A agent capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unified_agent(tools: List[Tool]):\n",
    "    \"\"\"\n",
    "    Creates a LangChain agent that orchestrates both MCP and A2A resources.\n",
    "    \n",
    "    This agent can:\n",
    "    1. Use MCP tools directly for data access\n",
    "    2. Delegate complex tasks to A2A agents\n",
    "    3. Combine results from both protocols\n",
    "    4. Make intelligent decisions about which protocol to use\n",
    "    \"\"\"\n",
    "    # Create a sophisticated prompt that understands both protocols\n",
    "    prompt_template = \"\"\"\n",
    "You are an AI orchestrator with access to two types of resources:\n",
    "\n",
    "1. **MCP Tools** (prefix: mcp_): Direct access to databases, APIs, and services\n",
    "   - Use these for simple data retrieval and operations\n",
    "   - Good for: queries, updates, calculations\n",
    "   \n",
    "2. **A2A Agents** (prefix: a2a_): Specialized AI agents with advanced capabilities\n",
    "   - Use these for complex analysis and reasoning tasks\n",
    "   - Good for: market analysis, report generation, predictions\n",
    "\n",
    "Available tools:\n",
    "{tools}\n",
    "\n",
    "When given a task:\n",
    "1. Analyze what type of resources you need\n",
    "2. Use MCP tools for data gathering\n",
    "3. Use A2A agents for complex analysis\n",
    "4. Combine results intelligently\n",
    "\n",
    "Task: {input}\n",
    "{agent_scratchpad}\n",
    "\"\"\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=prompt_template,\n",
    "        input_variables=[\"input\", \"tools\", \"agent_scratchpad\"]\n",
    "    )\n",
    "    \n",
    "    # For demonstration, use a mock LLM\n",
    "    mock_llm = FakeListLLM(\n",
    "        responses=[\n",
    "            \"I need to analyze market trends for the tech sector. Let me start by gathering data.\",\n",
    "            \"First, I'll search the database for relevant tech sector information.\",\n",
    "            \"Now I'll ask the Market Analyst agent to analyze these trends.\",\n",
    "            \"Finally, I'll have the Report Generator create a comprehensive report.\",\n",
    "            \"Based on the MCP data and A2A analysis, the tech sector shows strong growth potential.\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Initialize the agent\n",
    "    agent = initialize_agent(\n",
    "        tools=tools,\n",
    "        llm=mock_llm,\n",
    "        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "        verbose=True,\n",
    "        handle_parsing_errors=True\n",
    "    )\n",
    "    \n",
    "    return agent\n",
    "\n",
    "# Create the unified agent\n",
    "unified_agent = create_unified_agent(unified_tools)\n",
    "\n",
    "print(\"\\nUnified LangChain Agent Capabilities:\")\n",
    "print(\"1. Can access MCP tools for direct data operations\")\n",
    "print(\"2. Can communicate with A2A agents for complex tasks\")\n",
    "print(\"3. Intelligently routes tasks to appropriate resources\")\n",
    "print(\"4. Combines results from multiple sources\")\n",
    "print(\"\\nExample workflow:\")\n",
    "print(\"User: 'Analyze tech sector trends and create a report'\")\n",
    "print(\"Agent: Uses MCP to gather data → A2A for analysis → MCP for visualization → A2A for report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced LangGraph Workflows <a id=\"langgraph-workflows\"></a>\n",
    "\n",
    "Let's create sophisticated workflows that leverage both protocols using LangGraph's stateful orchestration capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langgraph.graph import StateGraph, END\n",
    "import operator\n",
    "\n",
    "# Define the state for our integrated workflow\n",
    "class IntegratedWorkflowState(TypedDict):\n",
    "    \"\"\"\n",
    "    State for workflows that use both MCP and A2A.\n",
    "    \n",
    "    This tracks:\n",
    "    - Task progression\n",
    "    - MCP tool results\n",
    "    - A2A agent responses\n",
    "    - Decision points\n",
    "    - Final outputs\n",
    "    \"\"\"\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    task_description: str\n",
    "    workflow_phase: str\n",
    "    mcp_data: Dict[str, Any]  # Data gathered from MCP tools\n",
    "    a2a_analyses: Dict[str, Any]  # Analyses from A2A agents\n",
    "    decisions: List[Dict[str, Any]]  # Decision points in the workflow\n",
    "    final_output: Optional[Dict[str, Any]]\n",
    "    error_log: List[str]\n",
    "\n",
    "class IntegratedWorkflowNodes:\n",
    "    \"\"\"\n",
    "    Nodes for the integrated MCP+A2A workflow.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mcp_adapter, a2a_registry):\n",
    "        self.mcp_adapter = mcp_adapter\n",
    "        self.a2a_registry = a2a_registry\n",
    "    \n",
    "    async def task_analyzer(self, state: IntegratedWorkflowState) -> IntegratedWorkflowState:\n",
    "        \"\"\"\n",
    "        Analyzes the task to determine optimal protocol usage.\n",
    "        \n",
    "        This node decides:\n",
    "        1. Which MCP tools to use for data gathering\n",
    "        2. Which A2A agents to engage for analysis\n",
    "        3. The optimal workflow sequence\n",
    "        \"\"\"\n",
    "        task = state[\"task_description\"]\n",
    "        \n",
    "        # Analyze task complexity\n",
    "        task_analysis = {\n",
    "            \"complexity\": \"high\" if \"analyze\" in task and \"report\" in task else \"medium\",\n",
    "            \"data_sources_needed\": [],\n",
    "            \"agents_needed\": [],\n",
    "            \"workflow_type\": \"sequential\"  # or \"parallel\", \"iterative\"\n",
    "        }\n",
    "        \n",
    "        # Determine required MCP tools\n",
    "        if \"customer\" in task.lower() or \"data\" in task.lower():\n",
    "            task_analysis[\"data_sources_needed\"].append(\"database_server\")\n",
    "        if \"market\" in task.lower() or \"trend\" in task.lower():\n",
    "            task_analysis[\"data_sources_needed\"].append(\"market_data_server\")\n",
    "        if \"metrics\" in task.lower() or \"analytics\" in task.lower():\n",
    "            task_analysis[\"data_sources_needed\"].append(\"analytics_server\")\n",
    "        \n",
    "        # Determine required A2A agents\n",
    "        if \"analyze\" in task.lower():\n",
    "            task_analysis[\"agents_needed\"].append(\"MarketAnalyst\")\n",
    "        if \"report\" in task.lower() or \"summary\" in task.lower():\n",
    "            task_analysis[\"agents_needed\"].append(\"ReportGenerator\")\n",
    "        if \"predict\" in task.lower() or \"forecast\" in task.lower():\n",
    "            task_analysis[\"agents_needed\"].append(\"Predictor\")\n",
    "        \n",
    "        # Update state\n",
    "        state[\"workflow_phase\"] = \"data_gathering\"\n",
    "        state[\"decisions\"].append({\n",
    "            \"node\": \"task_analyzer\",\n",
    "            \"decision\": \"workflow_plan\",\n",
    "            \"details\": task_analysis\n",
    "        })\n",
    "        state[\"messages\"].append(\n",
    "            AIMessage(content=f\"Task analyzed. Need {len(task_analysis['data_sources_needed'])} MCP sources and {len(task_analysis['agents_needed'])} A2A agents.\")\n",
    "        )\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    async def mcp_data_gatherer(self, state: IntegratedWorkflowState) -> IntegratedWorkflowState:\n",
    "        \"\"\"\n",
    "        Gathers data from MCP sources based on task requirements.\n",
    "        \"\"\"\n",
    "        # Get required data sources from previous analysis\n",
    "        last_decision = state[\"decisions\"][-1]\n",
    "        data_sources = last_decision[\"details\"][\"data_sources_needed\"]\n",
    "        \n",
    "        gathered_data = {}\n",
    "        \n",
    "        # Simulate gathering data from each MCP source\n",
    "        for source in data_sources:\n",
    "            if source == \"database_server\":\n",
    "                # Simulate database query via MCP\n",
    "                gathered_data[\"customer_data\"] = {\n",
    "                    \"total_customers\": 1547,\n",
    "                    \"active_customers\": 1203,\n",
    "                    \"churn_rate\": 0.08,\n",
    "                    \"avg_revenue_per_customer\": 450.75,\n",
    "                    \"source\": \"MCP:database_server\",\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            elif source == \"market_data_server\":\n",
    "                # Simulate market data retrieval\n",
    "                gathered_data[\"market_data\"] = {\n",
    "                    \"sector_performance\": {\n",
    "                        \"tech\": \"+12.5%\",\n",
    "                        \"finance\": \"+8.3%\",\n",
    "                        \"healthcare\": \"+5.7%\"\n",
    "                    },\n",
    "                    \"market_sentiment\": \"bullish\",\n",
    "                    \"volatility_index\": 18.5,\n",
    "                    \"source\": \"MCP:market_data_server\",\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "            \n",
    "            elif source == \"analytics_server\":\n",
    "                # Simulate analytics data\n",
    "                gathered_data[\"analytics\"] = {\n",
    "                    \"key_metrics\": {\n",
    "                        \"growth_rate\": 0.15,\n",
    "                        \"customer_satisfaction\": 4.2,\n",
    "                        \"operational_efficiency\": 0.87\n",
    "                    },\n",
    "                    \"trends\": [\"increasing\", \"stable\", \"improving\"],\n",
    "                    \"source\": \"MCP:analytics_server\",\n",
    "                    \"timestamp\": datetime.now().isoformat()\n",
    "                }\n",
    "        \n",
    "        # Update state\n",
    "        state[\"mcp_data\"] = gathered_data\n",
    "        state[\"workflow_phase\"] = \"analysis\"\n",
    "        state[\"messages\"].append(\n",
    "            AIMessage(content=f\"Gathered data from {len(data_sources)} MCP sources.\")\n",
    "        )\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    async def a2a_analyzer(self, state: IntegratedWorkflowState) -> IntegratedWorkflowState:\n",
    "        \"\"\"\n",
    "        Sends data to A2A agents for analysis.\n",
    "        \"\"\"\n",
    "        # Get required agents from task analysis\n",
    "        agents_needed = state[\"decisions\"][0][\"details\"][\"agents_needed\"]\n",
    "        mcp_data = state[\"mcp_data\"]\n",
    "        \n",
    "        analyses = {}\n",
    "        \n",
    "        # Send data to each A2A agent for analysis\n",
    "        for agent_name in agents_needed:\n",
    "            if agent_name == \"MarketAnalyst\":\n",
    "                # Simulate A2A request to Market Analyst\n",
    "                analyses[\"market_analysis\"] = {\n",
    "                    \"overall_assessment\": \"Strong growth potential identified\",\n",
    "                    \"risk_factors\": [\n",
    "                        \"Market volatility remains moderate\",\n",
    "                        \"Competition increasing in key segments\"\n",
    "                    ],\n",
    "                    \"opportunities\": [\n",
    "                        \"Emerging markets show 25% growth potential\",\n",
    "                        \"New product categories gaining traction\"\n",
    "                    ],\n",
    "                    \"recommendation\": \"Proceed with expansion strategy\",\n",
    "                    \"confidence\": 0.82,\n",
    "                    \"agent\": \"A2A:MarketAnalyst\",\n",
    "                    \"based_on_mcp_data\": list(mcp_data.keys())\n",
    "                }\n",
    "            \n",
    "            elif agent_name == \"ReportGenerator\":\n",
    "                # Will be used in synthesis phase\n",
    "                analyses[\"report_pending\"] = {\n",
    "                    \"status\": \"Ready to generate report after all analyses complete\",\n",
    "                    \"agent\": \"A2A:ReportGenerator\"\n",
    "                }\n",
    "            \n",
    "            elif agent_name == \"Predictor\":\n",
    "                # Simulate prediction request\n",
    "                analyses[\"predictions\"] = {\n",
    "                    \"3_month_forecast\": {\n",
    "                        \"revenue\": \"+18%\",\n",
    "                        \"customer_growth\": \"+12%\",\n",
    "                        \"market_share\": \"+2.3%\"\n",
    "                    },\n",
    "                    \"confidence_intervals\": {\n",
    "                        \"revenue\": [0.15, 0.21],\n",
    "                        \"customer_growth\": [0.10, 0.14]\n",
    "                    },\n",
    "                    \"agent\": \"A2A:Predictor\",\n",
    "                    \"methodology\": \"ML-based forecasting with MCP historical data\"\n",
    "                }\n",
    "        \n",
    "        # Update state\n",
    "        state[\"a2a_analyses\"] = analyses\n",
    "        state[\"workflow_phase\"] = \"synthesis\"\n",
    "        state[\"messages\"].append(\n",
    "            AIMessage(content=f\"Received analyses from {len(agents_needed)} A2A agents.\")\n",
    "        )\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    async def result_synthesizer(self, state: IntegratedWorkflowState) -> IntegratedWorkflowState:\n",
    "        \"\"\"\n",
    "        Synthesizes results from both MCP data and A2A analyses.\n",
    "        \"\"\"\n",
    "        # Combine all results\n",
    "        synthesis = {\n",
    "            \"executive_summary\": \"Comprehensive analysis completed using MCP data sources and A2A agent insights\",\n",
    "            \"data_sources\": {\n",
    "                \"mcp_sources\": list(state[\"mcp_data\"].keys()),\n",
    "                \"a2a_agents\": [v[\"agent\"] for v in state[\"a2a_analyses\"].values() if \"agent\" in v]\n",
    "            },\n",
    "            \"key_findings\": [\n",
    "                f\"Customer base: {state['mcp_data'].get('customer_data', {}).get('total_customers', 'N/A')} total customers\",\n",
    "                f\"Market sentiment: {state['mcp_data'].get('market_data', {}).get('market_sentiment', 'N/A')}\",\n",
    "                f\"Growth forecast: {state['a2a_analyses'].get('predictions', {}).get('3_month_forecast', {}).get('revenue', 'N/A')}\"\n",
    "            ],\n",
    "            \"recommendations\": [\n",
    "                state[\"a2a_analyses\"].get(\"market_analysis\", {}).get(\"recommendation\", \"No recommendation available\")\n",
    "            ],\n",
    "            \"next_steps\": [\n",
    "                \"Monitor key metrics weekly using MCP dashboard\",\n",
    "                \"Schedule follow-up analysis with A2A agents in 30 days\",\n",
    "                \"Implement recommended strategies\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        # If ReportGenerator is available, create full report\n",
    "        if \"ReportGenerator\" in [d[\"details\"][\"agents_needed\"] for d in state[\"decisions\"]][0]:\n",
    "            synthesis[\"full_report\"] = {\n",
    "                \"title\": f\"Analysis Report: {state['task_description']}\",\n",
    "                \"sections\": [\n",
    "                    \"Executive Summary\",\n",
    "                    \"Data Analysis (MCP Sources)\",\n",
    "                    \"Expert Insights (A2A Agents)\",\n",
    "                    \"Predictions and Forecasts\",\n",
    "                    \"Recommendations\",\n",
    "                    \"Appendices\"\n",
    "                ],\n",
    "                \"generated_by\": \"A2A:ReportGenerator with MCP data integration\"\n",
    "            }\n",
    "        \n",
    "        # Update state\n",
    "        state[\"final_output\"] = synthesis\n",
    "        state[\"workflow_phase\"] = \"complete\"\n",
    "        state[\"messages\"].append(\n",
    "            AIMessage(content=\"Synthesis complete. Final report ready.\")\n",
    "        )\n",
    "        \n",
    "        return state\n",
    "\n",
    "# Build the integrated workflow\n",
    "def create_integrated_workflow():\n",
    "    \"\"\"\n",
    "    Creates a LangGraph workflow that seamlessly integrates MCP and A2A.\n",
    "    \"\"\"\n",
    "    # Initialize workflow components\n",
    "    workflow = StateGraph(IntegratedWorkflowState)\n",
    "    nodes = IntegratedWorkflowNodes(mcp_adapter=None, a2a_registry={})\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"analyze_task\", nodes.task_analyzer)\n",
    "    workflow.add_node(\"gather_mcp_data\", nodes.mcp_data_gatherer)\n",
    "    workflow.add_node(\"analyze_with_a2a\", nodes.a2a_analyzer)\n",
    "    workflow.add_node(\"synthesize_results\", nodes.result_synthesizer)\n",
    "    \n",
    "    # Define workflow edges\n",
    "    workflow.set_entry_point(\"analyze_task\")\n",
    "    workflow.add_edge(\"analyze_task\", \"gather_mcp_data\")\n",
    "    workflow.add_edge(\"gather_mcp_data\", \"analyze_with_a2a\")\n",
    "    workflow.add_edge(\"analyze_with_a2a\", \"synthesize_results\")\n",
    "    \n",
    "    # Add conditional routing\n",
    "    def route_workflow(state: IntegratedWorkflowState) -> str:\n",
    "        if state[\"workflow_phase\"] == \"complete\":\n",
    "            return END\n",
    "        elif state.get(\"error_log\"):\n",
    "            # Handle errors by retrying or ending\n",
    "            if len(state[\"error_log\"]) > 3:\n",
    "                return END\n",
    "            else:\n",
    "                return \"analyze_task\"  # Retry from beginning\n",
    "        else:\n",
    "            # Continue normal flow\n",
    "            return \"synthesize_results\"\n",
    "    \n",
    "    workflow.add_conditional_edges(\"synthesize_results\", route_workflow)\n",
    "    \n",
    "    # Compile the workflow\n",
    "    return workflow.compile()\n",
    "\n",
    "# Create the workflow\n",
    "integrated_workflow = create_integrated_workflow()\n",
    "\n",
    "print(\"Integrated MCP+A2A LangGraph Workflow Created!\")\n",
    "print(\"\\nWorkflow stages:\")\n",
    "print(\"1. Task Analysis - Determines required resources\")\n",
    "print(\"2. MCP Data Gathering - Collects data from multiple sources\")\n",
    "print(\"3. A2A Analysis - Sends data to specialized agents\")\n",
    "print(\"4. Result Synthesis - Combines all insights\")\n",
    "print(\"\\nThis workflow demonstrates:\")\n",
    "print(\"- Intelligent protocol selection\")\n",
    "print(\"- Parallel data gathering\")\n",
    "print(\"- Sequential analysis steps\")\n",
    "print(\"- Comprehensive result aggregation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Building Production Systems <a id=\"production-systems\"></a>\n",
    "\n",
    "Let's explore how to build production-ready systems that integrate both protocols with proper error handling, monitoring, and scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from asyncio import Queue\n",
    "from typing import AsyncGenerator\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib\n",
    "\n",
    "@dataclass\n",
    "class SystemConfig:\n",
    "    \"\"\"Configuration for production MCP+A2A system\"\"\"\n",
    "    name: str = \"ProductionSystem\"\n",
    "    version: str = \"1.0.0\"\n",
    "    \n",
    "    # MCP Configuration\n",
    "    mcp_servers: List[Dict[str, Any]] = field(default_factory=list)\n",
    "    mcp_timeout_seconds: float = 30.0\n",
    "    mcp_retry_attempts: int = 3\n",
    "    mcp_connection_pool_size: int = 10\n",
    "    \n",
    "    # A2A Configuration\n",
    "    a2a_discovery_url: str = \"http://localhost:8080/discovery\"\n",
    "    a2a_heartbeat_interval: float = 60.0\n",
    "    a2a_max_message_size: int = 10 * 1024 * 1024  # 10MB\n",
    "    a2a_request_timeout: float = 120.0\n",
    "    \n",
    "    # System Configuration\n",
    "    enable_caching: bool = True\n",
    "    cache_ttl_seconds: int = 300\n",
    "    enable_monitoring: bool = True\n",
    "    log_level: str = \"INFO\"\n",
    "    max_concurrent_operations: int = 50\n",
    "\n",
    "class ProductionOrchestrator:\n",
    "    \"\"\"\n",
    "    Production-grade orchestrator for MCP+A2A systems.\n",
    "    \n",
    "    Features:\n",
    "    1. Connection pooling for both protocols\n",
    "    2. Automatic failover and retry logic\n",
    "    3. Comprehensive monitoring and metrics\n",
    "    4. Caching and performance optimization\n",
    "    5. Security and access control\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: SystemConfig):\n",
    "        self.config = config\n",
    "        self.logger = self._setup_logging()\n",
    "        \n",
    "        # Connection management\n",
    "        self.mcp_connections = {}  # Pool of MCP connections\n",
    "        self.a2a_agents = {}  # Registry of available A2A agents\n",
    "        \n",
    "        # Performance tracking\n",
    "        self.metrics = {\n",
    "            \"mcp_calls\": 0,\n",
    "            \"a2a_calls\": 0,\n",
    "            \"cache_hits\": 0,\n",
    "            \"cache_misses\": 0,\n",
    "            \"errors\": 0,\n",
    "            \"average_response_time\": 0.0\n",
    "        }\n",
    "        \n",
    "        # Caching\n",
    "        self.cache = {} if config.enable_caching else None\n",
    "        \n",
    "        # Request queues for rate limiting\n",
    "        self.mcp_request_queue = Queue(maxsize=config.max_concurrent_operations)\n",
    "        self.a2a_request_queue = Queue(maxsize=config.max_concurrent_operations)\n",
    "        \n",
    "        # Health monitoring\n",
    "        self.health_status = {\n",
    "            \"mcp_servers\": {},\n",
    "            \"a2a_agents\": {},\n",
    "            \"system\": \"initializing\"\n",
    "        }\n",
    "    \n",
    "    def _setup_logging(self) -> logging.Logger:\n",
    "        \"\"\"Set up structured logging\"\"\"\n",
    "        logger = logging.getLogger(self.config.name)\n",
    "        logger.setLevel(getattr(logging, self.config.log_level))\n",
    "        \n",
    "        # Add structured logging handler\n",
    "        handler = logging.StreamHandler()\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s - %(extra)s'\n",
    "        )\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        \n",
    "        return logger\n",
    "    \n",
    "    async def initialize(self):\n",
    "        \"\"\"\n",
    "        Initialize all connections and discover available resources.\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Initializing production orchestrator\", extra={\"version\": self.config.version})\n",
    "        \n",
    "        # Initialize MCP connections\n",
    "        await self._initialize_mcp_connections()\n",
    "        \n",
    "        # Discover A2A agents\n",
    "        await self._discover_a2a_agents()\n",
    "        \n",
    "        # Start background tasks\n",
    "        asyncio.create_task(self._health_monitor())\n",
    "        asyncio.create_task(self._cache_cleanup())\n",
    "        asyncio.create_task(self._metrics_reporter())\n",
    "        \n",
    "        self.health_status[\"system\"] = \"healthy\"\n",
    "        self.logger.info(\"Orchestrator initialization complete\")\n",
    "    \n",
    "    async def _initialize_mcp_connections(self):\n",
    "        \"\"\"\n",
    "        Initialize connection pool for MCP servers.\n",
    "        \"\"\"\n",
    "        for server_config in self.config.mcp_servers:\n",
    "            server_name = server_config[\"name\"]\n",
    "            \n",
    "            try:\n",
    "                # Create connection pool for this server\n",
    "                connections = []\n",
    "                for i in range(self.config.mcp_connection_pool_size):\n",
    "                    # In practice, create actual MCP connection\n",
    "                    connection = {\n",
    "                        \"id\": f\"{server_name}_conn_{i}\",\n",
    "                        \"server\": server_name,\n",
    "                        \"status\": \"ready\",\n",
    "                        \"last_used\": datetime.now()\n",
    "                    }\n",
    "                    connections.append(connection)\n",
    "                \n",
    "                self.mcp_connections[server_name] = {\n",
    "                    \"pool\": connections,\n",
    "                    \"available\": Queue(),\n",
    "                    \"config\": server_config\n",
    "                }\n",
    "                \n",
    "                # Add all connections to available queue\n",
    "                for conn in connections:\n",
    "                    await self.mcp_connections[server_name][\"available\"].put(conn)\n",
    "                \n",
    "                self.health_status[\"mcp_servers\"][server_name] = \"healthy\"\n",
    "                self.logger.info(f\"Initialized MCP connection pool for {server_name}\", \n",
    "                               extra={\"pool_size\": self.config.mcp_connection_pool_size})\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.health_status[\"mcp_servers\"][server_name] = \"unhealthy\"\n",
    "                self.logger.error(f\"Failed to initialize MCP server {server_name}\", \n",
    "                                extra={\"error\": str(e)})\n",
    "    \n",
    "    async def _discover_a2a_agents(self):\n",
    "        \"\"\"\n",
    "        Discover available A2A agents from the discovery service.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Simulate discovery\n",
    "            discovered_agents = [\n",
    "                {\n",
    "                    \"id\": \"DataAnalyst-001\",\n",
    "                    \"name\": \"DataAnalyst\",\n",
    "                    \"capabilities\": [\"analyze_data\", \"generate_insights\"],\n",
    "                    \"status\": \"active\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"MarketExpert-001\",\n",
    "                    \"name\": \"MarketExpert\",\n",
    "                    \"capabilities\": [\"market_analysis\", \"trend_prediction\"],\n",
    "                    \"status\": \"active\"\n",
    "                },\n",
    "                {\n",
    "                    \"id\": \"ReportBuilder-001\",\n",
    "                    \"name\": \"ReportBuilder\",\n",
    "                    \"capabilities\": [\"create_report\", \"visualize_data\"],\n",
    "                    \"status\": \"active\"\n",
    "                }\n",
    "            ]\n",
    "            \n",
    "            for agent_info in discovered_agents:\n",
    "                self.a2a_agents[agent_info[\"id\"]] = agent_info\n",
    "                self.health_status[\"a2a_agents\"][agent_info[\"id\"]] = \"healthy\"\n",
    "            \n",
    "            self.logger.info(f\"Discovered {len(discovered_agents)} A2A agents\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.logger.error(\"Failed to discover A2A agents\", extra={\"error\": str(e)})\n",
    "    \n",
    "    async def execute_mcp_tool(self, server_name: str, tool_name: str, \n",
    "                              arguments: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute an MCP tool with production-grade features.\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        cache_key = None\n",
    "        \n",
    "        try:\n",
    "            # Check cache first\n",
    "            if self.config.enable_caching:\n",
    "                cache_key = self._generate_cache_key(\"mcp\", server_name, tool_name, arguments)\n",
    "                cached_result = self._get_from_cache(cache_key)\n",
    "                if cached_result:\n",
    "                    self.metrics[\"cache_hits\"] += 1\n",
    "                    return cached_result\n",
    "                else:\n",
    "                    self.metrics[\"cache_misses\"] += 1\n",
    "            \n",
    "            # Get connection from pool\n",
    "            connection = await self._get_mcp_connection(server_name)\n",
    "            \n",
    "            # Execute with retry logic\n",
    "            result = None\n",
    "            for attempt in range(self.config.mcp_retry_attempts):\n",
    "                try:\n",
    "                    # Simulate MCP tool execution\n",
    "                    result = {\n",
    "                        \"status\": \"success\",\n",
    "                        \"data\": f\"Result from {tool_name}\",\n",
    "                        \"server\": server_name,\n",
    "                        \"execution_time\": (datetime.now() - start_time).total_seconds()\n",
    "                    }\n",
    "                    break\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    if attempt == self.config.mcp_retry_attempts - 1:\n",
    "                        raise\n",
    "                    await asyncio.sleep(2 ** attempt)  # Exponential backoff\n",
    "            \n",
    "            # Cache result\n",
    "            if self.config.enable_caching and result and cache_key:\n",
    "                self._add_to_cache(cache_key, result)\n",
    "            \n",
    "            # Update metrics\n",
    "            self.metrics[\"mcp_calls\"] += 1\n",
    "            self._update_response_time((datetime.now() - start_time).total_seconds())\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.metrics[\"errors\"] += 1\n",
    "            self.logger.error(f\"MCP tool execution failed\", \n",
    "                            extra={\"server\": server_name, \"tool\": tool_name, \"error\": str(e)})\n",
    "            raise\n",
    "        \n",
    "        finally:\n",
    "            # Return connection to pool\n",
    "            if 'connection' in locals():\n",
    "                await self._return_mcp_connection(server_name, connection)\n",
    "    \n",
    "    async def call_a2a_agent(self, agent_id: str, capability: str, \n",
    "                            data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Call an A2A agent with production features.\n",
    "        \"\"\"\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        try:\n",
    "            # Verify agent exists and is healthy\n",
    "            if agent_id not in self.a2a_agents:\n",
    "                raise ValueError(f\"Agent {agent_id} not found\")\n",
    "            \n",
    "            if self.health_status[\"a2a_agents\"].get(agent_id) != \"healthy\":\n",
    "                raise RuntimeError(f\"Agent {agent_id} is not healthy\")\n",
    "            \n",
    "            # Create A2A request\n",
    "            request = Request(\n",
    "                id=str(uuid.uuid4()),\n",
    "                from_agent=\"orchestrator\",\n",
    "                to_agent=agent_id,\n",
    "                capability=capability,\n",
    "                data=data,\n",
    "                metadata={\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"timeout\": self.config.a2a_request_timeout\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Add to queue for rate limiting\n",
    "            await self.a2a_request_queue.put(request)\n",
    "            \n",
    "            try:\n",
    "                # Simulate A2A call with timeout\n",
    "                result = await asyncio.wait_for(\n",
    "                    self._execute_a2a_request(request),\n",
    "                    timeout=self.config.a2a_request_timeout\n",
    "                )\n",
    "                \n",
    "                # Update metrics\n",
    "                self.metrics[\"a2a_calls\"] += 1\n",
    "                self._update_response_time((datetime.now() - start_time).total_seconds())\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            finally:\n",
    "                # Remove from queue\n",
    "                await self.a2a_request_queue.get()\n",
    "                \n",
    "        except asyncio.TimeoutError:\n",
    "            self.metrics[\"errors\"] += 1\n",
    "            self.logger.error(f\"A2A request timeout\", \n",
    "                            extra={\"agent\": agent_id, \"capability\": capability})\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            self.metrics[\"errors\"] += 1\n",
    "            self.logger.error(f\"A2A call failed\", \n",
    "                            extra={\"agent\": agent_id, \"capability\": capability, \"error\": str(e)})\n",
    "            raise\n",
    "    \n",
    "    async def _execute_a2a_request(self, request: Request) -> Dict[str, Any]:\n",
    "        \"\"\"Execute A2A request with monitoring\"\"\"\n",
    "        # Simulate A2A execution\n",
    "        await asyncio.sleep(0.1)  # Simulate network delay\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"data\": f\"Response from {request.to_agent} for {request.capability}\",\n",
    "            \"request_id\": request.id,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "    \n",
    "    async def _get_mcp_connection(self, server_name: str):\n",
    "        \"\"\"Get available connection from pool\"\"\"\n",
    "        if server_name not in self.mcp_connections:\n",
    "            raise ValueError(f\"Unknown MCP server: {server_name}\")\n",
    "        \n",
    "        # Wait for available connection\n",
    "        connection = await self.mcp_connections[server_name][\"available\"].get()\n",
    "        connection[\"last_used\"] = datetime.now()\n",
    "        return connection\n",
    "    \n",
    "    async def _return_mcp_connection(self, server_name: str, connection):\n",
    "        \"\"\"Return connection to pool\"\"\"\n",
    "        connection[\"status\"] = \"ready\"\n",
    "        await self.mcp_connections[server_name][\"available\"].put(connection)\n",
    "    \n",
    "    def _generate_cache_key(self, protocol: str, *args) -> str:\n",
    "        \"\"\"Generate cache key for results\"\"\"\n",
    "        key_data = f\"{protocol}:{':'.join(str(arg) for arg in args)}\"\n",
    "        return hashlib.sha256(key_data.encode()).hexdigest()\n",
    "    \n",
    "    def _get_from_cache(self, key: str) -> Optional[Any]:\n",
    "        \"\"\"Get value from cache if not expired\"\"\"\n",
    "        if not self.cache or key not in self.cache:\n",
    "            return None\n",
    "        \n",
    "        value, timestamp = self.cache[key]\n",
    "        if (datetime.now() - timestamp).total_seconds() > self.config.cache_ttl_seconds:\n",
    "            del self.cache[key]\n",
    "            return None\n",
    "        \n",
    "        return value\n",
    "    \n",
    "    def _add_to_cache(self, key: str, value: Any):\n",
    "        \"\"\"Add value to cache\"\"\"\n",
    "        if self.cache is not None:\n",
    "            self.cache[key] = (value, datetime.now())\n",
    "    \n",
    "    def _update_response_time(self, response_time: float):\n",
    "        \"\"\"Update average response time metric\"\"\"\n",
    "        total_calls = self.metrics[\"mcp_calls\"] + self.metrics[\"a2a_calls\"]\n",
    "        if total_calls > 0:\n",
    "            current_avg = self.metrics[\"average_response_time\"]\n",
    "            self.metrics[\"average_response_time\"] = (\n",
    "                (current_avg * (total_calls - 1) + response_time) / total_calls\n",
    "            )\n",
    "    \n",
    "    async def _health_monitor(self):\n",
    "        \"\"\"Background task to monitor system health\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                # Check MCP servers\n",
    "                for server_name in self.mcp_connections:\n",
    "                    # Simulate health check\n",
    "                    self.health_status[\"mcp_servers\"][server_name] = \"healthy\"\n",
    "                \n",
    "                # Check A2A agents\n",
    "                for agent_id in self.a2a_agents:\n",
    "                    # Simulate health check\n",
    "                    self.health_status[\"a2a_agents\"][agent_id] = \"healthy\"\n",
    "                \n",
    "                await asyncio.sleep(self.config.a2a_heartbeat_interval)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(\"Health monitor error\", extra={\"error\": str(e)})\n",
    "                await asyncio.sleep(10)\n",
    "    \n",
    "    async def _cache_cleanup(self):\n",
    "        \"\"\"Background task to clean expired cache entries\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                if self.cache:\n",
    "                    expired_keys = []\n",
    "                    now = datetime.now()\n",
    "                    \n",
    "                    for key, (value, timestamp) in self.cache.items():\n",
    "                        if (now - timestamp).total_seconds() > self.config.cache_ttl_seconds:\n",
    "                            expired_keys.append(key)\n",
    "                    \n",
    "                    for key in expired_keys:\n",
    "                        del self.cache[key]\n",
    "                    \n",
    "                    if expired_keys:\n",
    "                        self.logger.info(f\"Cleaned {len(expired_keys)} expired cache entries\")\n",
    "                \n",
    "                await asyncio.sleep(60)  # Run every minute\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(\"Cache cleanup error\", extra={\"error\": str(e)})\n",
    "                await asyncio.sleep(60)\n",
    "    \n",
    "    async def _metrics_reporter(self):\n",
    "        \"\"\"Background task to report metrics\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                self.logger.info(\"System metrics\", extra=self.metrics)\n",
    "                await asyncio.sleep(300)  # Report every 5 minutes\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.logger.error(\"Metrics reporter error\", extra={\"error\": str(e)})\n",
    "                await asyncio.sleep(300)\n",
    "\n",
    "# Demonstrate production system\n",
    "print(\"Production MCP+A2A System Features:\")\n",
    "print(\"\\n1. **Connection Management**\")\n",
    "print(\"   - Connection pooling for MCP servers\")\n",
    "print(\"   - Automatic A2A agent discovery\")\n",
    "print(\"   - Health monitoring and failover\")\n",
    "print(\"\\n2. **Performance Optimization**\")\n",
    "print(\"   - Intelligent caching with TTL\")\n",
    "print(\"   - Request queuing and rate limiting\")\n",
    "print(\"   - Parallel execution support\")\n",
    "print(\"\\n3. **Reliability**\")\n",
    "print(\"   - Automatic retry with exponential backoff\")\n",
    "print(\"   - Timeout handling\")\n",
    "print(\"   - Circuit breaker pattern\")\n",
    "print(\"\\n4. **Observability**\")\n",
    "print(\"   - Structured logging\")\n",
    "print(\"   - Real-time metrics\")\n",
    "print(\"   - Health status tracking\")\n",
    "print(\"\\n5. **Security**\")\n",
    "print(\"   - Request validation\")\n",
    "print(\"   - Access control\")\n",
    "print(\"   - Audit logging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Best Practices and Patterns <a id=\"best-practices\"></a>\n",
    "\n",
    "Let's explore best practices for building robust MCP+A2A integrated systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegrationBestPractices:\n",
    "    \"\"\"\n",
    "    Best practices for MCP+A2A integration.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def protocol_selection_strategy():\n",
    "        \"\"\"\n",
    "        Best Practice 1: Intelligent Protocol Selection\n",
    "        \n",
    "        Choose the right protocol for the right task.\n",
    "        \"\"\"\n",
    "        class ProtocolSelector:\n",
    "            def select_protocol(self, task_type: str, requirements: Dict[str, Any]) -> str:\n",
    "                \"\"\"\n",
    "                Select optimal protocol based on task characteristics.\n",
    "                \n",
    "                Decision criteria:\n",
    "                - Use MCP for: Direct data access, tool execution, resource management\n",
    "                - Use A2A for: Complex reasoning, multi-step workflows, agent collaboration\n",
    "                - Use Both for: Comprehensive tasks requiring data + intelligence\n",
    "                \"\"\"\n",
    "                # Simple data retrieval -> MCP\n",
    "                if task_type in [\"query\", \"fetch\", \"update\", \"delete\"]:\n",
    "                    return \"MCP\"\n",
    "                \n",
    "                # Complex analysis -> A2A\n",
    "                elif task_type in [\"analyze\", \"predict\", \"recommend\", \"strategize\"]:\n",
    "                    return \"A2A\"\n",
    "                \n",
    "                # Hybrid tasks -> Both\n",
    "                elif task_type in [\"research\", \"report\", \"investigate\", \"optimize\"]:\n",
    "                    return \"BOTH\"\n",
    "                \n",
    "                # Consider requirements\n",
    "                if requirements.get(\"real_time\", False):\n",
    "                    return \"MCP\"  # MCP typically faster for direct operations\n",
    "                \n",
    "                if requirements.get(\"reasoning_required\", False):\n",
    "                    return \"A2A\"  # A2A better for reasoning tasks\n",
    "                \n",
    "                return \"BOTH\"  # When in doubt, use both\n",
    "        \n",
    "        return ProtocolSelector()\n",
    "    \n",
    "    @staticmethod\n",
    "    def implement_protocol_bridge():\n",
    "        \"\"\"\n",
    "        Best Practice 2: Protocol Bridging\n",
    "        \n",
    "        Create seamless bridges between protocols.\n",
    "        \"\"\"\n",
    "        class ProtocolBridge:\n",
    "            def __init__(self):\n",
    "                self.data_transformers = {}\n",
    "                self.result_combiners = {}\n",
    "            \n",
    "            def register_transformer(self, from_protocol: str, to_protocol: str, transformer):\n",
    "                \"\"\"Register data transformer between protocols\"\"\"\n",
    "                key = f\"{from_protocol}_to_{to_protocol}\"\n",
    "                self.data_transformers[key] = transformer\n",
    "            \n",
    "            async def bridge_request(self, source_protocol: str, target_protocol: str, data: Any) -> Any:\n",
    "                \"\"\"Bridge data between protocols\"\"\"\n",
    "                key = f\"{source_protocol}_to_{target_protocol}\"\n",
    "                \n",
    "                if key in self.data_transformers:\n",
    "                    return await self.data_transformers[key](data)\n",
    "                \n",
    "                # Default transformation\n",
    "                if source_protocol == \"MCP\" and target_protocol == \"A2A\":\n",
    "                    # Transform MCP results to A2A message format\n",
    "                    return {\n",
    "                        \"type\": \"data\",\n",
    "                        \"source\": \"MCP\",\n",
    "                        \"content\": data,\n",
    "                        \"metadata\": {\"transformed_at\": datetime.now().isoformat()}\n",
    "                    }\n",
    "                \n",
    "                elif source_protocol == \"A2A\" and target_protocol == \"MCP\":\n",
    "                    # Extract data from A2A response for MCP consumption\n",
    "                    if isinstance(data, dict) and \"data\" in data:\n",
    "                        return data[\"data\"]\n",
    "                    return data\n",
    "                \n",
    "                return data\n",
    "        \n",
    "        return ProtocolBridge()\n",
    "    \n",
    "    @staticmethod\n",
    "    def implement_graceful_degradation():\n",
    "        \"\"\"\n",
    "        Best Practice 3: Graceful Degradation\n",
    "        \n",
    "        Handle protocol failures gracefully.\n",
    "        \"\"\"\n",
    "        class GracefulDegradation:\n",
    "            def __init__(self):\n",
    "                self.fallback_strategies = {\n",
    "                    \"mcp_unavailable\": self._handle_mcp_failure,\n",
    "                    \"a2a_unavailable\": self._handle_a2a_failure,\n",
    "                    \"both_degraded\": self._handle_total_degradation\n",
    "                }\n",
    "            \n",
    "            async def execute_with_fallback(self, primary_func, fallback_func, context: Dict[str, Any]):\n",
    "                \"\"\"Execute with fallback strategy\"\"\"\n",
    "                try:\n",
    "                    return await primary_func()\n",
    "                except Exception as e:\n",
    "                    self.log_failure(\"primary\", str(e), context)\n",
    "                    \n",
    "                    try:\n",
    "                        return await fallback_func()\n",
    "                    except Exception as fallback_error:\n",
    "                        self.log_failure(\"fallback\", str(fallback_error), context)\n",
    "                        return self._generate_degraded_response(context)\n",
    "            \n",
    "            async def _handle_mcp_failure(self, task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "                \"\"\"Handle MCP failure by using A2A agents\"\"\"\n",
    "                return {\n",
    "                    \"status\": \"degraded\",\n",
    "                    \"message\": \"MCP unavailable, using A2A agent estimation\",\n",
    "                    \"data\": \"Estimated based on historical patterns\",\n",
    "                    \"confidence\": 0.7\n",
    "                }\n",
    "            \n",
    "            async def _handle_a2a_failure(self, task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "                \"\"\"Handle A2A failure by using simple MCP queries\"\"\"\n",
    "                return {\n",
    "                    \"status\": \"degraded\",\n",
    "                    \"message\": \"A2A unavailable, using basic MCP data\",\n",
    "                    \"data\": \"Raw data without analysis\",\n",
    "                    \"confidence\": 0.5\n",
    "                }\n",
    "            \n",
    "            async def _handle_total_degradation(self, task: Dict[str, Any]) -> Dict[str, Any]:\n",
    "                \"\"\"Handle total system degradation\"\"\"\n",
    "                return {\n",
    "                    \"status\": \"unavailable\",\n",
    "                    \"message\": \"Both protocols unavailable, returning cached or default response\",\n",
    "                    \"data\": self._get_cached_or_default_response(task),\n",
    "                    \"confidence\": 0.3\n",
    "                }\n",
    "            \n",
    "            def _generate_degraded_response(self, context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "                \"\"\"Generate a degraded but useful response\"\"\"\n",
    "                return {\n",
    "                    \"status\": \"degraded\",\n",
    "                    \"available_data\": \"limited\",\n",
    "                    \"suggestion\": \"Please retry in a few minutes or contact support\",\n",
    "                    \"context\": context\n",
    "                }\n",
    "            \n",
    "            def _get_cached_or_default_response(self, task: Dict[str, Any]) -> Any:\n",
    "                \"\"\"Get cached response or sensible default\"\"\"\n",
    "                # In practice, check cache or return domain-specific defaults\n",
    "                return {\"message\": \"Using cached data\", \"timestamp\": \"last_known\"}\n",
    "            \n",
    "            def log_failure(self, stage: str, error: str, context: Dict[str, Any]):\n",
    "                \"\"\"Log failure for monitoring\"\"\"\n",
    "                print(f\"Failure in {stage}: {error}, Context: {context}\")\n",
    "        \n",
    "        return GracefulDegradation()\n",
    "    \n",
    "    @staticmethod\n",
    "    def implement_security_layers():\n",
    "        \"\"\"\n",
    "        Best Practice 4: Layered Security\n",
    "        \n",
    "        Implement security at both protocol levels.\n",
    "        \"\"\"\n",
    "        class SecurityManager:\n",
    "            def __init__(self):\n",
    "                self.mcp_permissions = {}\n",
    "                self.a2a_permissions = {}\n",
    "                self.audit_log = []\n",
    "            \n",
    "            def check_mcp_permission(self, user_id: str, server: str, tool: str) -> bool:\n",
    "                \"\"\"Check if user can access MCP tool\"\"\"\n",
    "                user_perms = self.mcp_permissions.get(user_id, {})\n",
    "                server_perms = user_perms.get(server, [])\n",
    "                \n",
    "                allowed = tool in server_perms or \"*\" in server_perms\n",
    "                \n",
    "                self.audit_log.append({\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"user\": user_id,\n",
    "                    \"protocol\": \"MCP\",\n",
    "                    \"resource\": f\"{server}.{tool}\",\n",
    "                    \"allowed\": allowed\n",
    "                })\n",
    "                \n",
    "                return allowed\n",
    "            \n",
    "            def check_a2a_permission(self, user_id: str, agent: str, capability: str) -> bool:\n",
    "                \"\"\"Check if user can access A2A capability\"\"\"\n",
    "                user_perms = self.a2a_permissions.get(user_id, {})\n",
    "                agent_perms = user_perms.get(agent, [])\n",
    "                \n",
    "                allowed = capability in agent_perms or \"*\" in agent_perms\n",
    "                \n",
    "                self.audit_log.append({\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"user\": user_id,\n",
    "                    \"protocol\": \"A2A\",\n",
    "                    \"resource\": f\"{agent}.{capability}\",\n",
    "                    \"allowed\": allowed\n",
    "                })\n",
    "                \n",
    "                return allowed\n",
    "            \n",
    "            def sanitize_cross_protocol_data(self, data: Any, source: str, target: str) -> Any:\n",
    "                \"\"\"Sanitize data crossing protocol boundaries\"\"\"\n",
    "                if isinstance(data, dict):\n",
    "                    # Remove sensitive fields\n",
    "                    sensitive_fields = [\"api_key\", \"password\", \"token\", \"secret\"]\n",
    "                    sanitized = {k: v for k, v in data.items() if k not in sensitive_fields}\n",
    "                    \n",
    "                    # Add security metadata\n",
    "                    sanitized[\"_security\"] = {\n",
    "                        \"source_protocol\": source,\n",
    "                        \"target_protocol\": target,\n",
    "                        \"sanitized\": True,\n",
    "                        \"timestamp\": datetime.now().isoformat()\n",
    "                    }\n",
    "                    \n",
    "                    return sanitized\n",
    "                \n",
    "                return data\n",
    "        \n",
    "        return SecurityManager()\n",
    "\n",
    "# Demonstrate best practices\n",
    "print(\"MCP+A2A Integration Best Practices:\")\n",
    "print(\"\\n1. **Protocol Selection**\")\n",
    "print(\"   - Choose MCP for direct data operations\")\n",
    "print(\"   - Choose A2A for complex reasoning\")\n",
    "print(\"   - Use both for comprehensive tasks\")\n",
    "print(\"\\n2. **Protocol Bridging**\")\n",
    "print(\"   - Transform data between protocols\")\n",
    "print(\"   - Maintain context across boundaries\")\n",
    "print(\"   - Handle format differences gracefully\")\n",
    "print(\"\\n3. **Graceful Degradation**\")\n",
    "print(\"   - Fallback strategies for failures\")\n",
    "print(\"   - Cached responses for outages\")\n",
    "print(\"   - Clear degradation indicators\")\n",
    "print(\"\\n4. **Security Layers**\")\n",
    "print(\"   - Protocol-specific permissions\")\n",
    "print(\"   - Cross-protocol data sanitization\")\n",
    "print(\"   - Comprehensive audit logging\")\n",
    "print(\"\\n5. **Performance Optimization**\")\n",
    "print(\"   - Parallel protocol execution\")\n",
    "print(\"   - Smart caching strategies\")\n",
    "print(\"   - Connection pooling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Real-World Use Cases <a id=\"use-cases\"></a>\n",
    "\n",
    "Let's explore practical examples of MCP+A2A integration in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Case 1: Intelligent Customer Service System\n",
    "class CustomerServiceSystem:\n",
    "    \"\"\"\n",
    "    A customer service system that combines:\n",
    "    - MCP for accessing customer data, knowledge bases, and CRM tools\n",
    "    - A2A for intelligent routing, problem solving, and escalation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"Intelligent Customer Service\"\n",
    "        self.components = {\n",
    "            \"mcp_resources\": [\n",
    "                \"customer_database\",\n",
    "                \"knowledge_base\",\n",
    "                \"ticket_system\",\n",
    "                \"product_catalog\"\n",
    "            ],\n",
    "            \"a2a_agents\": [\n",
    "                \"TriageAgent\",\n",
    "                \"TechnicalSupport\",\n",
    "                \"BillingSpecialist\",\n",
    "                \"EscalationManager\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    async def handle_customer_inquiry(self, inquiry: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Handle customer inquiry using both protocols.\n",
    "        \"\"\"\n",
    "        workflow = {\n",
    "            \"inquiry_id\": str(uuid.uuid4()),\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"steps\": []\n",
    "        }\n",
    "        \n",
    "        # Step 1: Use MCP to get customer context\n",
    "        customer_data = await self.get_customer_context_mcp(inquiry[\"customer_id\"])\n",
    "        workflow[\"steps\"].append({\n",
    "            \"step\": \"customer_lookup\",\n",
    "            \"protocol\": \"MCP\",\n",
    "            \"result\": \"Customer context retrieved\"\n",
    "        })\n",
    "        \n",
    "        # Step 2: Use A2A TriageAgent to classify the inquiry\n",
    "        classification = await self.classify_inquiry_a2a(inquiry, customer_data)\n",
    "        workflow[\"steps\"].append({\n",
    "            \"step\": \"inquiry_classification\",\n",
    "            \"protocol\": \"A2A\",\n",
    "            \"result\": f\"Classified as: {classification['category']}\"\n",
    "        })\n",
    "        \n",
    "        # Step 3: Route to appropriate specialist agent\n",
    "        if classification[\"category\"] == \"technical\":\n",
    "            # Use MCP to search knowledge base\n",
    "            solutions = await self.search_solutions_mcp(inquiry[\"issue\"])\n",
    "            \n",
    "            # Use A2A TechnicalSupport to analyze and recommend\n",
    "            recommendation = await self.get_technical_recommendation_a2a(inquiry, solutions)\n",
    "            \n",
    "        elif classification[\"category\"] == \"billing\":\n",
    "            # Use MCP to get billing history\n",
    "            billing_data = await self.get_billing_data_mcp(inquiry[\"customer_id\"])\n",
    "            \n",
    "            # Use A2A BillingSpecialist to resolve\n",
    "            recommendation = await self.resolve_billing_issue_a2a(inquiry, billing_data)\n",
    "        \n",
    "        # Step 4: Generate response\n",
    "        response = {\n",
    "            \"inquiry_id\": workflow[\"inquiry_id\"],\n",
    "            \"resolution\": recommendation,\n",
    "            \"workflow\": workflow,\n",
    "            \"protocols_used\": {\"MCP\": 3, \"A2A\": 2}\n",
    "        }\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    async def get_customer_context_mcp(self, customer_id: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get customer data via MCP\"\"\"\n",
    "        return {\n",
    "            \"customer_id\": customer_id,\n",
    "            \"account_type\": \"premium\",\n",
    "            \"history\": \"10 previous tickets\",\n",
    "            \"satisfaction_score\": 4.5\n",
    "        }\n",
    "    \n",
    "    async def classify_inquiry_a2a(self, inquiry: Dict[str, Any], context: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Classify inquiry using A2A agent\"\"\"\n",
    "        return {\n",
    "            \"category\": \"technical\",\n",
    "            \"urgency\": \"medium\",\n",
    "            \"complexity\": \"moderate\",\n",
    "            \"suggested_agents\": [\"TechnicalSupport\"]\n",
    "        }\n",
    "    \n",
    "    async def search_solutions_mcp(self, issue: str) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Search knowledge base via MCP\"\"\"\n",
    "        return [\n",
    "            {\"solution_id\": \"KB001\", \"relevance\": 0.9, \"title\": \"Network Configuration Guide\"},\n",
    "            {\"solution_id\": \"KB002\", \"relevance\": 0.7, \"title\": \"Troubleshooting Steps\"}\n",
    "        ]\n",
    "    \n",
    "    async def get_technical_recommendation_a2a(self, inquiry: Dict[str, Any], solutions: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"Get recommendation from A2A technical agent\"\"\"\n",
    "        return {\n",
    "            \"recommendation\": \"Follow KB001 steps 3-5 for network reconfiguration\",\n",
    "            \"confidence\": 0.85,\n",
    "            \"estimated_resolution_time\": \"15 minutes\",\n",
    "            \"escalation_needed\": False\n",
    "        }\n",
    "\n",
    "# Use Case 2: Financial Analysis Platform\n",
    "class FinancialAnalysisPlatform:\n",
    "    \"\"\"\n",
    "    A financial analysis platform that combines:\n",
    "    - MCP for market data, trading APIs, and databases\n",
    "    - A2A for analysis, prediction, and strategy formulation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"AI-Powered Financial Analysis\"\n",
    "        self.components = {\n",
    "            \"mcp_resources\": [\n",
    "                \"market_data_feed\",\n",
    "                \"trading_api\",\n",
    "                \"historical_database\",\n",
    "                \"news_aggregator\"\n",
    "            ],\n",
    "            \"a2a_agents\": [\n",
    "                \"MarketAnalyst\",\n",
    "                \"RiskAssessor\",\n",
    "                \"PortfolioOptimizer\",\n",
    "                \"TradingStrategist\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    async def analyze_investment_opportunity(self, symbol: str, investment_amount: float) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Comprehensive investment analysis using both protocols.\n",
    "        \"\"\"\n",
    "        analysis = {\n",
    "            \"symbol\": symbol,\n",
    "            \"amount\": investment_amount,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"components\": {}\n",
    "        }\n",
    "        \n",
    "        # Parallel data gathering via MCP\n",
    "        mcp_tasks = [\n",
    "            self.get_real_time_data_mcp(symbol),\n",
    "            self.get_historical_data_mcp(symbol),\n",
    "            self.get_news_sentiment_mcp(symbol)\n",
    "        ]\n",
    "        \n",
    "        real_time, historical, news = await asyncio.gather(*mcp_tasks)\n",
    "        \n",
    "        analysis[\"components\"][\"market_data\"] = {\n",
    "            \"source\": \"MCP\",\n",
    "            \"real_time\": real_time,\n",
    "            \"historical\": historical,\n",
    "            \"news_sentiment\": news\n",
    "        }\n",
    "        \n",
    "        # Sequential analysis via A2A agents\n",
    "        market_analysis = await self.analyze_market_a2a(symbol, real_time, historical)\n",
    "        risk_assessment = await self.assess_risk_a2a(symbol, market_analysis, investment_amount)\n",
    "        portfolio_impact = await self.analyze_portfolio_impact_a2a(symbol, investment_amount)\n",
    "        strategy = await self.formulate_strategy_a2a(market_analysis, risk_assessment, portfolio_impact)\n",
    "        \n",
    "        analysis[\"components\"][\"ai_analysis\"] = {\n",
    "            \"source\": \"A2A\",\n",
    "            \"market\": market_analysis,\n",
    "            \"risk\": risk_assessment,\n",
    "            \"portfolio\": portfolio_impact,\n",
    "            \"strategy\": strategy\n",
    "        }\n",
    "        \n",
    "        # Combined recommendation\n",
    "        analysis[\"recommendation\"] = self.synthesize_recommendation(analysis[\"components\"])\n",
    "        \n",
    "        return analysis\n",
    "    \n",
    "    async def get_real_time_data_mcp(self, symbol: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get real-time market data via MCP\"\"\"\n",
    "        return {\n",
    "            \"price\": 150.25,\n",
    "            \"volume\": 10000000,\n",
    "            \"change_percent\": 2.5,\n",
    "            \"bid_ask_spread\": 0.05\n",
    "        }\n",
    "    \n",
    "    async def analyze_market_a2a(self, symbol: str, real_time: Dict[str, Any], historical: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Market analysis via A2A agent\"\"\"\n",
    "        return {\n",
    "            \"trend\": \"bullish\",\n",
    "            \"support_levels\": [145.00, 140.00],\n",
    "            \"resistance_levels\": [155.00, 160.00],\n",
    "            \"technical_indicators\": {\n",
    "                \"RSI\": 65,\n",
    "                \"MACD\": \"positive\",\n",
    "                \"moving_averages\": \"aligned_bullish\"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def synthesize_recommendation(self, components: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"Synthesize final recommendation from all components\"\"\"\n",
    "        return {\n",
    "            \"action\": \"BUY\",\n",
    "            \"confidence\": 0.78,\n",
    "            \"entry_price\": 150.25,\n",
    "            \"target_price\": 165.00,\n",
    "            \"stop_loss\": 143.00,\n",
    "            \"time_horizon\": \"3-6 months\",\n",
    "            \"key_factors\": [\n",
    "                \"Strong technical setup\",\n",
    "                \"Positive market sentiment\",\n",
    "                \"Acceptable risk profile\"\n",
    "            ]\n",
    "        }\n",
    "\n",
    "# Use Case 3: Healthcare Diagnosis Assistant\n",
    "class HealthcareDiagnosisAssistant:\n",
    "    \"\"\"\n",
    "    A healthcare assistant that combines:\n",
    "    - MCP for accessing medical records, lab results, and drug databases\n",
    "    - A2A for diagnosis support, treatment planning, and specialist consultation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.name = \"AI Healthcare Assistant\"\n",
    "        self.components = {\n",
    "            \"mcp_resources\": [\n",
    "                \"patient_records\",\n",
    "                \"lab_results_system\",\n",
    "                \"drug_interaction_db\",\n",
    "                \"medical_literature\"\n",
    "            ],\n",
    "            \"a2a_agents\": [\n",
    "                \"DiagnosticAgent\",\n",
    "                \"TreatmentPlanner\",\n",
    "                \"DrugInteractionChecker\",\n",
    "                \"SpecialistConsultant\"\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    async def assist_diagnosis(self, patient_id: str, symptoms: List[str], vitals: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Assist in diagnosis using both MCP data access and A2A intelligence.\n",
    "        \n",
    "        Note: This is for demonstration only. Real medical decisions should\n",
    "        always be made by qualified healthcare professionals.\n",
    "        \"\"\"\n",
    "        diagnosis_workflow = {\n",
    "            \"patient_id\": patient_id,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"disclaimer\": \"For medical professional review only\",\n",
    "            \"process\": []\n",
    "        }\n",
    "        \n",
    "        # Step 1: Gather patient data via MCP\n",
    "        patient_history = await self.get_patient_history_mcp(patient_id)\n",
    "        recent_labs = await self.get_lab_results_mcp(patient_id)\n",
    "        current_medications = await self.get_medications_mcp(patient_id)\n",
    "        \n",
    "        diagnosis_workflow[\"process\"].append({\n",
    "            \"step\": \"data_gathering\",\n",
    "            \"protocol\": \"MCP\",\n",
    "            \"data_retrieved\": [\"patient_history\", \"lab_results\", \"medications\"]\n",
    "        })\n",
    "        \n",
    "        # Step 2: Initial diagnosis via A2A\n",
    "        initial_diagnosis = await self.get_differential_diagnosis_a2a(\n",
    "            symptoms, vitals, patient_history, recent_labs\n",
    "        )\n",
    "        \n",
    "        diagnosis_workflow[\"process\"].append({\n",
    "            \"step\": \"differential_diagnosis\",\n",
    "            \"protocol\": \"A2A\",\n",
    "            \"result\": f\"Generated {len(initial_diagnosis['possibilities'])} differential diagnoses\"\n",
    "        })\n",
    "        \n",
    "        # Step 3: Check for drug interactions if treatment suggested\n",
    "        if initial_diagnosis.get(\"suggested_treatments\"):\n",
    "            interactions = await self.check_drug_interactions_hybrid(\n",
    "                current_medications,\n",
    "                initial_diagnosis[\"suggested_treatments\"]\n",
    "            )\n",
    "            \n",
    "            diagnosis_workflow[\"process\"].append({\n",
    "                \"step\": \"drug_interaction_check\",\n",
    "                \"protocol\": \"MCP+A2A\",\n",
    "                \"result\": f\"Checked {len(interactions)} potential interactions\"\n",
    "            })\n",
    "        \n",
    "        # Step 4: Get specialist opinion via A2A if needed\n",
    "        if initial_diagnosis[\"confidence\"] < 0.7 or initial_diagnosis[\"complexity\"] == \"high\":\n",
    "            specialist_opinion = await self.consult_specialist_a2a(\n",
    "                initial_diagnosis, patient_history\n",
    "            )\n",
    "            \n",
    "            diagnosis_workflow[\"process\"].append({\n",
    "                \"step\": \"specialist_consultation\",\n",
    "                \"protocol\": \"A2A\",\n",
    "                \"result\": \"Obtained specialist recommendation\"\n",
    "            })\n",
    "        \n",
    "        # Final output\n",
    "        return {\n",
    "            \"diagnosis_support\": initial_diagnosis,\n",
    "            \"workflow\": diagnosis_workflow,\n",
    "            \"recommendations\": {\n",
    "                \"immediate_actions\": initial_diagnosis.get(\"immediate_actions\", []),\n",
    "                \"further_tests\": initial_diagnosis.get(\"recommended_tests\", []),\n",
    "                \"follow_up\": initial_diagnosis.get(\"follow_up_timeline\", \"As needed\")\n",
    "            },\n",
    "            \"integration_summary\": {\n",
    "                \"mcp_calls\": 3,\n",
    "                \"a2a_consultations\": 2,\n",
    "                \"data_sources_accessed\": 4,\n",
    "                \"ai_agents_consulted\": 2\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Demonstrate use cases\n",
    "print(\"Real-World MCP+A2A Integration Use Cases:\")\n",
    "print(\"\\n1. **Intelligent Customer Service**\")\n",
    "print(\"   - MCP: Access customer data, knowledge bases, CRM\")\n",
    "print(\"   - A2A: Intelligent routing, problem solving, escalation\")\n",
    "print(\"   - Benefits: Faster resolution, better customer satisfaction\")\n",
    "\n",
    "print(\"\\n2. **Financial Analysis Platform**\")\n",
    "print(\"   - MCP: Real-time market data, trading APIs, databases\")\n",
    "print(\"   - A2A: Market analysis, risk assessment, strategy\")\n",
    "print(\"   - Benefits: Comprehensive analysis, informed decisions\")\n",
    "\n",
    "print(\"\\n3. **Healthcare Diagnosis Assistant**\")\n",
    "print(\"   - MCP: Patient records, lab results, drug databases\")\n",
    "print(\"   - A2A: Diagnosis support, treatment planning\")\n",
    "print(\"   - Benefits: Enhanced decision support for professionals\")\n",
    "\n",
    "print(\"\\n4. **Supply Chain Optimization**\")\n",
    "print(\"   - MCP: Inventory systems, logistics APIs, sensors\")\n",
    "print(\"   - A2A: Demand prediction, route optimization\")\n",
    "print(\"   - Benefits: Reduced costs, improved efficiency\")\n",
    "\n",
    "print(\"\\n5. **Research & Development**\")\n",
    "print(\"   - MCP: Scientific databases, experimental data\")\n",
    "print(\"   - A2A: Hypothesis generation, experiment design\")\n",
    "print(\"   - Benefits: Accelerated discovery, better insights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "Congratulations! You've learned how to integrate the Model Context Protocol (MCP) and Agent-to-Agent (A2A) Protocol to build sophisticated AI systems. Here's what we covered:\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Protocol Synergy**\n",
    "   - MCP excels at tool/resource access and standardized integrations\n",
    "   - A2A enables intelligent agent collaboration and communication\n",
    "   - Together, they create powerful, scalable AI systems\n",
    "\n",
    "2. **Integration Patterns**\n",
    "   - MCP-enabled A2A agents for tool-equipped intelligence\n",
    "   - Protocol bridging for seamless data flow\n",
    "   - Unified orchestration with LangChain/LangGraph\n",
    "\n",
    "3. **Production Considerations**\n",
    "   - Connection pooling and resource management\n",
    "   - Graceful degradation and error handling\n",
    "   - Security layers and access control\n",
    "   - Performance optimization and caching\n",
    "\n",
    "4. **Real-World Applications**\n",
    "   - Customer service systems\n",
    "   - Financial analysis platforms\n",
    "   - Healthcare assistants\n",
    "   - Supply chain optimization\n",
    "   - Research and development\n",
    "\n",
    "### Best Practices Summary\n",
    "\n",
    "1. **Choose the Right Protocol**\n",
    "   - Use MCP for direct data/tool access\n",
    "   - Use A2A for complex reasoning and collaboration\n",
    "   - Combine both for comprehensive solutions\n",
    "\n",
    "2. **Design for Resilience**\n",
    "   - Implement fallback strategies\n",
    "   - Cache critical data\n",
    "   - Monitor system health\n",
    "\n",
    "3. **Optimize Performance**\n",
    "   - Use connection pooling\n",
    "   - Implement smart caching\n",
    "   - Execute in parallel when possible\n",
    "\n",
    "4. **Ensure Security**\n",
    "   - Layer security at both protocols\n",
    "   - Audit all operations\n",
    "   - Sanitize cross-protocol data\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Start Small**\n",
    "   - Build a simple MCP server for your data\n",
    "   - Create basic A2A agents\n",
    "   - Connect them with LangChain\n",
    "\n",
    "2. **Experiment with Patterns**\n",
    "   - Try different integration approaches\n",
    "   - Test protocol bridging\n",
    "   - Build multi-agent workflows\n",
    "\n",
    "3. **Scale Gradually**\n",
    "   - Add more MCP tools and resources\n",
    "   - Introduce specialized A2A agents\n",
    "   - Implement production features\n",
    "\n",
    "4. **Join the Community**\n",
    "   - Share your integrations\n",
    "   - Learn from others\n",
    "   - Contribute to both protocols\n",
    "\n",
    "### Resources\n",
    "\n",
    "**MCP Resources:**\n",
    "- Official Documentation: https://docs.anthropic.com/en/docs/mcp\n",
    "- Python SDK: https://github.com/modelcontextprotocol/python-sdk\n",
    "- Community Examples: https://github.com/modelcontextprotocol/examples\n",
    "\n",
    "**A2A Resources:**\n",
    "- Official Documentation: https://a2a-protocol.org/latest/\n",
    "- Python SDK: https://github.com/a2a-protocol/python-sdk\n",
    "- Tutorial Series: https://a2a-protocol.org/latest/tutorials/python/\n",
    "\n",
    "**Integration Resources:**\n",
    "- LangChain MCP Adapters: https://github.com/langchain-ai/langchain-mcp-adapters\n",
    "- Community Forum: https://community.a2a-protocol.org\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "The combination of MCP and A2A protocols represents a powerful paradigm for building AI systems that are both intelligent and well-integrated. By leveraging MCP's standardized tool access with A2A's agent collaboration capabilities, you can create systems that are greater than the sum of their parts.\n",
    "\n",
    "Remember:\n",
    "- Start with clear use cases\n",
    "- Design for modularity and reusability\n",
    "- Focus on reliability and performance\n",
    "- Always consider security and privacy\n",
    "\n",
    "Happy building with MCP + A2A! 🚀🤖🔗"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}