{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 7 - Lab 1: Advanced Agent Workflows with MCP for New Hire Onboarding\n",
    "\n",
    "**Objective:** Master the Model Context Protocol (MCP) to build reliable, predictable agents for automating new employee onboarding workflows.\n",
    "\n",
    "**Estimated Time:** 135 minutes\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to Day 7! Today, you'll learn how the Model Context Protocol (MCP) transforms unreliable AI agents into production-ready systems. You'll build an onboarding automation agent that demonstrates why MCP is critical for enterprise AI applications.\n",
    "\n",
    "### The Problem with Unstructured Context\n",
    "\n",
    "When onboarding new employees, HR teams juggle multiple data sources:\n",
    "- Policy documents (formal requirements)\n",
    "- Slack messages (informal requests)\n",
    "- Access matrices (system permissions)\n",
    "- Training catalogs (learning requirements)\n",
    "\n",
    "Without structure, AI agents make inconsistent decisions. MCP solves this by providing:\n",
    "1. **Resources**: Structured, versioned data sources\n",
    "2. **Tools**: Validated, idempotent operations\n",
    "3. **Schema Enforcement**: Type-safe interactions\n",
    "\n",
    "By the end of this lab, you'll build an MCP-powered onboarding agent that makes deterministic, auditable decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We will install the necessary libraries for this lab, including `model-context-protocol` for creating structured prompts and `langchain-mcp-adapters` for easily integrating MCP with our LangChain agents.\n",
    "\n",
    "**Model Selection:**\n",
    "For tasks involving structured data and code, models with strong reasoning and instruction-following capabilities are best. `gpt-4.1`, `o3`, or `gemini-2.5-pro` are excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import importlib\n",
    "def install_if_missing(package):\n",
    "    try:\n",
    "        importlib.import_module(package)\n",
    "    except ImportError:\n",
    "        print(f\"{package} not found, installing...\")\n",
    "        import subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "install_if_missing('model_context_protocol')\n",
    "install_if_missing('langchain_mcp_adapters')\n",
    "\n",
    "from utils import setup_llm_client, get_completion\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Manually Formatting an MCP Prompt\n",
    "\n",
    "**Task:** Before using the SDK, manually write a prompt string that follows the MCP XML-style format.\n",
    "\n",
    "> **Tip:** Notice the XML-style tags. This structure isn't just for looks; it gives the LLM clear signals about the role of each piece of information. `<request>` is the user's goal, while `<context>` provides the data needed to achieve it.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Create a multi-line f-string for your prompt.\n",
    "2.  The prompt should include the following MCP tags:\n",
    "    * `<request>`: The user's high-level request (e.g., \"Please refactor this code.\").\n",
    "    * `<context>`: A container for contextual information.\n",
    "    * `<code>`: Inside `<context>`, place a snippet of Python code that needs refactoring.\n",
    "    * `<instructions>`: Inside `<context>`, provide specific instructions for the refactoring (e.g., \"Make this function more readable and add type hints.\").\n",
    "3.  Send this manually formatted string to the LLM and observe the output.\n",
    "\n",
    "**Expected Quality:** A successful response from the LLM, demonstrating that it can understand and act upon the structured MCP format even without the SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_to_refactor = \"def my_func(a,b):\\n  x=a+b\\n  y=x*2\\n  return y\"\n",
    "\n",
    "# TODO: Create a prompt string that manually uses MCP tags.\n",
    "manual_mcp_prompt = f\"\"\"\n",
    "# Your prompt here\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Sending Manually Formatted MCP Prompt ---\")\n",
    "response = get_completion(manual_mcp_prompt, client, model_name, api_provider)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Using the MCP SDK to Build a Prompt\n",
    "\n",
    "**Task:** Now, use the `model-context-protocol` SDK to programmatically build the same structured prompt.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Import `Request`, `Context`, `Code`, and `Instructions` from the `model_context_protocol` library.\n",
    "2.  Create an instance of the `Code` context item, passing the `code_to_refactor`.\n",
    "3.  Create an instance of the `Instructions` context item.\n",
    "4.  Create a `Context` object, passing a list containing your `Code` and `Instructions` items.\n",
    "5.  Create the final `Request` object, passing the user's request text and the `Context` object.\n",
    "6.  Use the `.render()` method on the `Request` object to get the formatted string and print it to verify it matches your manual prompt.\n",
    "\n",
    "**Expected Quality:** A Python script that programmatically generates a valid MCP-formatted string, demonstrating a more robust and maintainable way to construct complex prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_context_protocol import Request, Context, Code, Instructions\n",
    "\n",
    "# TODO: Use the MCP SDK to build the request programmatically.\n",
    "\n",
    "# 1. Create Code and Instructions items\n",
    "code_item = None # Your code here\n",
    "instructions_item = None # Your code here\n",
    "\n",
    "# 2. Create the Context object\n",
    "context_obj = None # Your code here\n",
    "\n",
    "# 3. Create the final Request object\n",
    "mcp_request = None # Your code here\n",
    "\n",
    "# 4. Render the request to a string\n",
    "rendered_prompt = mcp_request.render()\n",
    "\n",
    "print(\"--- Programmatically Rendered MCP Prompt ---\")\n",
    "print(rendered_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Building a Context-Aware Refactoring Agent\n",
    "\n",
    "**Task:** Use the `langchain-mcp-adapters` library to create a LangChain agent that automatically structures its inputs using MCP.\n",
    "\n",
    "> **What do the adapters do?** The `langchain-mcp-adapters` library acts as a bridge. It lets you define the high-level structure of your context (e.g., 'I need code and instructions') and automatically handles the work of formatting it into the proper MCP string for the LLM.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Import `McpChatPromptTemplate` from `langchain_mcp_adapters`.\n",
    "2.  Create a list of context builders. For this lab, you'll need one for `Code` and one for `Instructions`. The adapter library provides these.\n",
    "3.  Create an instance of `McpChatPromptTemplate`, passing in your list of context builders and a request template string.\n",
    "4.  Create a simple LangChain chain by piping this special prompt template to your LLM.\n",
    "5.  Invoke the chain. The input should be a dictionary containing keys that match your context builders (e.g., `code` and `instructions`) and your request template variables.\n",
    "6.  The adapter will automatically build the full MCP-formatted prompt before sending it to the LLM.\n",
    "\n",
    "**Expected Quality:** A functioning LangChain agent that seamlessly and automatically uses the Model Context Protocol, demonstrating how to build robust, production-ready agents that handle complex, multi-part context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters import McpChatPromptTemplate\n",
    "from langchain_mcp_adapters.context_builders import CodeContextBuilder, InstructionsContextBuilder\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=model_name)\n",
    "\n",
    "# TODO: 1. Create a list of context builders\n",
    "context_builders = [] # Your list here\n",
    "\n",
    "# TODO: 2. Create the McpChatPromptTemplate\n",
    "mcp_prompt_template = None # Your prompt template here\n",
    "\n",
    "# TODO: 3. Create the LangChain agent chain\n",
    "refactoring_agent = None # Your chain here\n",
    "\n",
    "# TODO: 4. Invoke the agent with a dictionary of inputs\n",
    "refactoring_input = {\n",
    "    \"user_request\": \"Please refactor this code to be more Pythonic.\",\n",
    "    \"code\": \"def f(data):\\n  r = []\\n  for i in data:\\n    if i % 2 == 0:\\n      r.append(i*i)\\n  return r\",\n",
    "    \"instructions\": \"Use a list comprehension and add type hints.\"\n",
    "}\n",
    "\n",
    "print(\"--- Invoking MCP-powered Refactoring Agent ---\")\n",
    "refactored_code = refactoring_agent.invoke(refactoring_input)\n",
    "print(refactored_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Excellent work! You have learned how to use the Model Context Protocol to create structured, reliable prompts for your AI agents. You progressed from manually writing MCP-formatted strings to using the SDK for programmatic construction, and finally to using the LangChain adapter for seamless integration. This skill is crucial for building advanced agents that need to handle diverse and complex contextual information in a predictable way.\n",
    "\n",
    "> **Key Takeaway:** Structuring prompts with a clear protocol like MCP makes agents more reliable. It separates the user's *request* from the *context* the agent needs, reducing ambiguity and allowing you to build more predictable, production-ready AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
