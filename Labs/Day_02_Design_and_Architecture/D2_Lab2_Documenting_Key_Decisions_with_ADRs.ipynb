{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Estimated Time:** 60 minutes\n",
    "\n",
    "**Introduction:**\n",
    "Great architectural decisions are based on research and trade-offs. A critical practice for healthy, long-lived projects is documenting *why* these decisions were made. In this lab, you will use an LLM to research a key technical choice for our application and then generate a formal ADR to record that decision for the future.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "We'll start by ensuring our environment is ready and adding the standard pathing solution to reliably import our `utils.py` helper.\n",
    "\n",
    "**Model Selection:**\n",
    "For research and synthesis tasks, models with large context windows and strong reasoning abilities are ideal. `gpt-4.1`, `gemini-2.5-pro`, or `meta-llama/Llama-3.3-70B-Instruct` would be excellent choices.\n",
    "\n",
    "**Helper Functions Used:**\n",
    "- `setup_llm_client()`: To configure the API client.\n",
    "- `get_completion()`: To send prompts to the LLM.\n",
    "- `load_artifact()`: To read the ADR template.\n",
    "- `save_artifact()`: To save the generated ADR template and the final ADR."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:48:42.457400Z",
     "start_time": "2025-10-28T14:48:41.288025Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-28 10:48:42,456 ag_aisoftdev.utils INFO LLM Client configured provider=google model=gemini-2.5-pro latency_ms=None artifacts_path=None\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Task:** A good ADR follows a consistent format. Your first task is to prompt an LLM to generate a clean, reusable ADR template in markdown.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt that asks the LLM to generate a markdown template for an Architectural Decision Record.\n",
    "2.  The template should include sections for: `Title`, `Status` (e.g., Proposed, Accepted, Deprecated), `Context` (the problem or forces at play), `Decision` (the chosen solution), and `Consequences` (the positive and negative results of the decision).\n",
    "3.  Save the generated template to `templates/adr_template.md`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T14:58:57.999667Z",
     "start_time": "2025-10-28T14:58:36.455898Z"
    }
   },
   "source": "# TODO: Write a prompt to generate a markdown ADR template.\nadr_template_prompt = \"\"\"\nYou are a technical documentation expert tasked with creating a reusable Architectural Decision Record (ADR) template.\n\n**Your Task:**\nGenerate a clean, professional markdown template for documenting architectural decisions. This template will be used by engineers to record important technical choices throughout a project's lifecycle.\n\n**Required Sections:**\n1. **Title**: A clear, concise title in the format \"ADR-XXX: [Decision Title]\"\n2. **Status**: The current state of the decision (e.g., Proposed, Accepted, Rejected, Deprecated, Superseded)\n3. **Date**: When the decision was made or proposed\n4. **Context**: \n   - What is the issue or problem we're addressing?\n   - What technical, business, or organizational forces are at play?\n   - What constraints or requirements must we consider?\n5. **Decision**: \n   - What solution or approach have we chosen?\n   - Be specific and clear about what will be implemented\n6. **Consequences**:\n   - **Positive**: What benefits does this decision bring?\n   - **Negative**: What drawbacks, risks, or trade-offs does this decision create?\n   - **Neutral**: What are the side effects or implications?\n\n**Format Requirements:**\n- Use markdown formatting with clear headers\n- Include placeholder text in each section to guide the author\n- Use italics for instructional text that should be replaced\n- Make it professional and easy to follow\n- Keep it concise but comprehensive\n\nGenerate the ADR template now:\n\"\"\"\n\nprint(\"--- Generating ADR Template ---\")\nadr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\nprint(adr_template_content)\n\n# Save the artifact\nif adr_template_content:\n    save_artifact(adr_template_content, \"templates/adr_template.md\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "Of course. Here is a clean, professional, and reusable markdown template for an Architectural Decision Record (ADR).\n",
      "\n",
      "---\n",
      "\n",
      "```markdown\n",
      "# ADR-XXX: [Short, descriptive title of the decision]\n",
      "\n",
      "*Replace XXX with the ADR number (e.g., 001, 002).*\n",
      "\n",
      "## Status\n",
      "\n",
      "**Status**: Proposed\n",
      "\n",
      "*Can be: Proposed, Accepted, Rejected, Deprecated, Superseded by [ADR-YYY].*\n",
      "\n",
      "## Date\n",
      "\n",
      "**Date**: YYYY-MM-DD\n",
      "\n",
      "## Context\n",
      "\n",
      "*This section describes the \"why\" of the decision. What is the problem, situation, or business need we are addressing? What are the constraints and requirements?*\n",
      "\n",
      "**Problem Statement**\n",
      "*Describe the issue, problem, or challenge we are addressing. For example, \"Our current authentication system does not support single sign-on (SSO), which is a key requirement for our new enterprise clients.\"*\n",
      "\n",
      "**Drivers & Constraints**\n",
      "*List the forces influencing this decision. These can be technical, business, or operational.*\n",
      "*   **Driver:** *e.g., Improve system performance to meet new SLA targets.*\n",
      "*   **Driver:** *e.g., Reduce monthly infrastructure costs by 15%.*\n",
      "*   **Constraint:** *e.g., The solution must be compatible with our existing Kubernetes environment.*\n",
      "*   **Constraint:** *e.g., The team has limited experience with Go, so a solution in Python or Java is preferred.*\n",
      "\n",
      "## Decision\n",
      "\n",
      "*This section describes the \"what\" of the decision. State the chosen solution clearly and specifically.*\n",
      "\n",
      "We have decided to **[describe the chosen approach or technology]**.\n",
      "\n",
      "*Be specific and unambiguous. For example:*\n",
      "*   *\"We will adopt PostgreSQL as our primary relational database for the new microservice.\"*\n",
      "*   *\"We will use the Strangler Fig pattern to incrementally replace the legacy monolith's billing module.\"*\n",
      "*   *\"All new frontend applications will be built using the React framework with TypeScript.\"*\n",
      "\n",
      "## Consequences\n",
      "\n",
      "*This section describes the outcomes and implications of the decision. It is crucial for understanding the trade-offs.*\n",
      "\n",
      "### Positive\n",
      "*What are the benefits and positive outcomes we expect from this decision?*\n",
      "*   *e.g., Improved performance by 20% under peak load.*\n",
      "*   *e.g., Faster development cycles due to a well-defined component library.*\n",
      "*   *e.g., Unlocks the ability to implement [new feature X].*\n",
      "\n",
      "### Negative\n",
      "*What are the drawbacks, risks, or trade-offs? What will be more difficult because of this decision?*\n",
      "*   *e.g., Introduces a new technology that the team needs to be trained on.*\n",
      "*   *e.g., Increases the complexity of the deployment pipeline.*\n",
      "*   *e.g., Higher licensing costs compared to the previous solution.*\n",
      "\n",
      "### Neutral\n",
      "*What are the side-effects or non-critical implications? These are not necessarily good or bad, but are worth noting for future reference.*\n",
      "*   *e.g., This decision will influence the design of future related services.*\n",
      "*   *e.g., Existing monitoring dashboards will need to be updated.*\n",
      "```\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Task:** Use the LLM to perform unbiased research on a key technical decision for our project: choosing a database for semantic search.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Write a prompt instructing the LLM to perform a technical comparison.\n",
    "2.  Ask it to compare and contrast two technical options: **\"Using PostgreSQL with the `pgvector` extension\"** versus **\"Using a specialized vector database like ChromaDB or FAISS\"**.\n",
    "3.  The prompt should ask for a balanced view for the specific use case of our new hire onboarding tool.\n",
    "4.  Store the output in a variable for the next step.\n",
    "\n",
    "> **Tip:** To get a balanced comparison, explicitly ask the LLM to 'act as an unbiased research assistant' and to list the 'pros and cons for each approach.' This prevents the model from simply recommending the more popular option and encourages a more critical analysis."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T15:04:37.336524Z",
     "start_time": "2025-10-28T15:03:53.184881Z"
    }
   },
   "source": "# TODO: Write a prompt to research database options.\ndb_research_prompt = \"\"\"\nYou are an unbiased technical research assistant tasked with comparing database solutions for semantic search functionality in a new hire onboarding application.\n\n**Project Context:**\nWe are building the Momentum Onboarding Platform, a web application that helps companies streamline their new hire onboarding process. The platform will include features like:\n- Centralized onboarding hub with company resources, documentation, and FAQs\n- Task management and tracking for new hires, managers, and HR\n- Searchable knowledge base where new hires can find answers to common questions\n- Resource library with policies, handbooks, and training materials\n\n**Technical Decision:**\nWe need to implement semantic search capabilities to allow new hires to search the onboarding hub using natural language queries (e.g., \"How do I request time off?\" or \"Who is my HR contact?\"). This requires storing and querying vector embeddings of our content.\n\n**Your Task:**\nProvide a balanced, objective comparison of two technical approaches for implementing this semantic search capability:\n\n**Option 1: PostgreSQL with pgvector extension**\n- PostgreSQL is a mature, open-source relational database\n- pgvector is an extension that adds vector similarity search capabilities\n\n**Option 2: Specialized vector databases (ChromaDB or FAISS)**\n- ChromaDB is a purpose-built vector database designed for AI applications\n- FAISS is a library for efficient similarity search maintained by Meta\n\n**Analysis Requirements:**\nFor each option, provide:\n1. **Pros**: What are the advantages and strengths of this approach?\n2. **Cons**: What are the drawbacks, limitations, or challenges?\n3. **Use Case Fit**: How well does it align with our specific needs (onboarding tool with moderate scale, relatively small team, need for reliability)?\n4. **Operational Considerations**: What are the infrastructure, maintenance, and skill requirements?\n\n**Important Guidelines:**\n- Be objective and balanced - do not favor one option simply because it's more popular\n- Consider practical factors like: operational complexity, cost, learning curve, ecosystem maturity\n- Think about the specific context: this is an enterprise onboarding tool, not a large-scale consumer application\n- We need a solution that balances capability with simplicity\n\nProvide your detailed comparison now:\n\"\"\"\n\nprint(\"--- Researching Database Options ---\")\ndb_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\nprint(db_research_output)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "Of course. Here is a balanced, objective comparison of PostgreSQL with pgvector and specialized vector databases for the Momentum Onboarding Platform's semantic search needs.\n",
      "\n",
      "***\n",
      "\n",
      "### **Executive Summary**\n",
      "\n",
      "This analysis compares two primary approaches for implementing semantic search in the Momentum Onboarding Platform.\n",
      "\n",
      "*   **Option 1 (PostgreSQL + pgvector):** Integrates vector search capabilities directly into our primary relational database. This approach prioritizes architectural simplicity, unified data management, and operational stability by leveraging a mature, well-understood technology.\n",
      "*   **Option 2 (Specialized Vector Databases):** Introduces a purpose-built database (like ChromaDB) or library (like FAISS) dedicated solely to high-performance vector search. This approach prioritizes cutting-edge performance and a developer experience tailored for AI/ML workflows, at the cost of increased architectural complexity.\n",
      "\n",
      "For the Momentum Onboarding Platform's specific context—a B2B application with moderate scale, a small development team, and a high need for reliability—**PostgreSQL with pgvector presents a more pragmatic and lower-risk starting point.**\n",
      "\n",
      "---\n",
      "\n",
      "### **Option 1: PostgreSQL with pgvector extension**\n",
      "\n",
      "This approach involves using our existing or planned PostgreSQL database and enabling vector search functionality by installing the `pgvector` open-source extension.\n",
      "\n",
      "#### **1. Pros (Advantages & Strengths)**\n",
      "\n",
      "*   **Unified Data Store & Architectural Simplicity:** This is the most significant advantage. Your user data, tasks, documents, and their corresponding vector embeddings all reside in a single database. This eliminates the complexity of running, backing up, and monitoring a separate database system.\n",
      "*   **No Data Synchronization Issues:** Since the vector embeddings can be in the same table as the source text and other metadata (e.g., document ID, author, creation date), there is no need to build and maintain a pipeline to keep two separate databases in sync. This drastically reduces potential points of failure.\n",
      "*   **Powerful Hybrid Search:** You can combine vector similarity search with standard SQL `WHERE` clauses in a single query. For example, you can search for \"time off policy\" (`vector search`) but filter for documents relevant only to the \"Engineering\" department (`SQL filter`) atomically and efficiently.\n",
      "*   **Mature & Reliable Ecosystem:** PostgreSQL is a battle-tested database with decades of development. The ecosystem for backups, monitoring, high availability, security, and performance tuning is incredibly mature and well-documented. Your team likely already has or can easily acquire these skills.\n",
      "*   **Transactional Guarantees (ACID):** All operations, including vector updates, benefit from PostgreSQL's full ACID compliance. When you update a document and its vector, the change is atomic and durable, ensuring data integrity.\n",
      "\n",
      "#### **2. Cons (Drawbacks & Limitations)**\n",
      "\n",
      "*   **Not a Specialized Tool:** PostgreSQL was not originally designed for vector search. While `pgvector` is highly effective, a purpose-built vector database may offer more advanced, fine-tuned indexing algorithms or performance optimizations at an extremely large scale (hundreds of millions to billions of vectors).\n",
      "*   **Potential Performance Ceiling:** For applications requiring ultra-low latency on massive datasets, a specialized solution might eventually outperform `pgvector`. However, this threshold is likely far beyond the projected scale of an onboarding platform's knowledge base.\n",
      "*   **Extension Management:** As an extension, `pgvector`'s updates are separate from PostgreSQL's core release cycle. This adds a minor maintenance task to track and apply updates to the extension itself.\n",
      "\n",
      "#### **3. Use Case Fit for Momentum Onboarding**\n",
      "\n",
      "**Excellent Fit.** The platform's scale (thousands to tens of thousands of documents, not billions) is well within the capabilities of `pgvector`. The primary benefits for a small team are:\n",
      "*   **Reduced Operational Burden:** Managing one database is significantly easier than managing two.\n",
      "*   **Leverages Existing Skills:** Your team doesn't need to learn the operational intricacies of a new database technology.\n",
      "*   **Data Integrity:** The ability to store content and vectors together transactionally is ideal for an enterprise application where reliability is key.\n",
      "\n",
      "#### **4. Operational Considerations**\n",
      "\n",
      "*   **Infrastructure:** Requires a standard PostgreSQL instance (version 11+). Can be self-hosted or run on any major cloud provider's managed PostgreSQL service (e.g., AWS RDS, Google Cloud SQL), many of which now support `pgvector` out of the box.\n",
      "*   **Maintenance:** Involves standard PostgreSQL administration (backups, vacuuming, monitoring). You must also ensure the `pgvector` extension is installed and kept up-to-date.\n",
      "*   **Skills:** Requires standard backend development and SQL knowledge. The learning curve for `pgvector` itself is minimal for anyone familiar with SQL.\n",
      "\n",
      "---\n",
      "\n",
      "### **Option 2: Specialized Vector Databases (ChromaDB or FAISS)**\n",
      "\n",
      "This approach involves using a separate, dedicated system for storing and querying vectors. Note that **FAISS is a library**, not a standalone database, often used as a high-performance backend. **ChromaDB is a full database** built for AI applications.\n",
      "\n",
      "#### **1. Pros (Advantages & Strengths)**\n",
      "\n",
      "*   **Optimized Performance at Scale:** These tools are engineered from the ground up for one task: fast Approximate Nearest Neighbor (ANN) search. They use highly optimized indexing strategies (like HNSW) and can deliver superior performance for extremely large datasets.\n",
      "*   **AI/ML-Native Developer Experience:** Databases like ChromaDB offer simple, Python-centric APIs designed for ML engineers. They integrate seamlessly with popular frameworks like LangChain and LlamaIndex, which can accelerate initial development.\n",
      "*   **Decoupled Scaling:** The vector search component can be scaled independently of your primary application database. If search becomes a bottleneck, you can allocate more resources to it without affecting the rest of the application.\n",
      "\n",
      "#### **2. Cons (Drawbacks & Limitations)**\n",
      "\n",
      "*   **Increased Architectural Complexity:** This is the primary drawback. You now have two databases to manage, monitor, secure, and back up. This introduces a new potential point of failure.\n",
      "*   **Data Synchronization Challenge:** You must maintain consistency between your primary database (PostgreSQL) and your vector database. If a document is updated in PostgreSQL, you must have a reliable process to update the corresponding vector in ChromaDB. This adds engineering overhead and fragility.\n",
      "*   **Limited Querying Capabilities:** Specialized vector databases have limited or no support for the rich, transactional queries of a relational database. Complex filtering based on metadata can be less efficient or impossible compared to a simple SQL `WHERE` clause.\n",
      "*   **Operational Immaturity:** Compared to PostgreSQL, the ecosystem for these newer databases is less mature. Finding experienced administrators, established best practices for production deployments, and extensive community support for operational issues can be more challenging.\n",
      "\n",
      "#### **3. Use Case Fit for Momentum Onboarding**\n",
      "\n",
      "**Potential Over-engineering.** While this approach would certainly work, the benefits it provides (extreme performance at scale) do not align with the immediate needs of the platform. The costs it introduces (architectural complexity, operational overhead) would be a significant burden for a small team. This option is better suited for applications where vector search is the core, high-throughput feature, such as a large-scale e-commerce product discovery engine.\n",
      "\n",
      "#### **4. Operational Considerations**\n",
      "\n",
      "*   **Infrastructure:** Requires a separate server or container to run the vector database. You are responsible for its deployment, networking, and security.\n",
      "*   **Maintenance:** Involves learning a new system's operational playbook for backups, monitoring, and updates. You must also build and maintain the data synchronization pipeline between PostgreSQL and the vector DB.\n",
      "*   **Skills:** Requires knowledge of the specific vector database's API and operational model. This is a more specialized skill set than general PostgreSQL administration.\n",
      "\n",
      "---\n",
      "\n",
      "### **Side-by-Side Comparison & Recommendation**\n",
      "\n",
      "| Feature | PostgreSQL + pgvector | Specialized Vector DB (e.g., ChromaDB) |\n",
      "| :--- | :--- | :--- |\n",
      "| **Architectural Simplicity** | **Excellent** (Single, unified database) | **Poor** (Requires a second database & sync logic) |\n",
      "| **Operational Overhead** | **Low** (Leverages existing infrastructure & skills) | **High** (New system to deploy, monitor, and maintain) |\n",
      "| **Data Integrity** | **Excellent** (Full ACID transactions) | **Varies** (Weaker guarantees, sync challenges) |\n",
      "| **Hybrid Search** | **Excellent** (Seamless SQL + vector queries) | **Limited** (Metadata filtering can be less powerful) |\n",
      "| **Performance at Scale** | **Good to Excellent** (Sufficient for millions of vectors) | **Excellent** (Optimized for hundreds of millions+) |\n",
      "| **Ecosystem Maturity** | **Excellent** (Decades of tooling and support) | **Emerging** (Newer technology, smaller community) |\n",
      "| **Learning Curve** | **Low** (Minimal extension on top of standard SQL) | **Moderate** (Requires learning a new system/API) |\n",
      "\n",
      "**Recommendation:**\n",
      "\n",
      "For the Momentum Onboarding Platform, **PostgreSQL with the pgvector extension is the recommended approach.**\n",
      "\n",
      "It provides a robust, reliable, and sufficiently performant solution that directly aligns with the project's constraints. The overwhelming benefit of architectural simplicity and reduced operational overhead for a small team makes it the most pragmatic choice. It allows the team to focus on building application features rather than managing complex infrastructure, while still delivering the powerful semantic search functionality required.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Task:** Provide the LLM with your research from the previous step and have it formally document the decision.\n",
    "\n",
    "**Instructions:**\n",
    "1.  Load the `adr_template.md` you created in the first challenge.\n",
    "2.  Create a new prompt instructing the LLM to act as a Staff Engineer.\n",
    "3.  Provide the `db_research_output` as context.\n",
    "4.  Instruct the LLM to populate the ADR template, formally documenting the decision to **use PostgreSQL with pgvector** and justifying the choice based on the synthesized pros and cons.\n",
    "5.  Save the final, completed ADR as `artifacts/adr_001_database_choice.md`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T17:00:03.399219Z",
     "start_time": "2025-10-28T16:59:40.854710Z"
    }
   },
   "source": "adr_template = load_artifact(\"templates/adr_template.md\")\n\n# TODO: Write a prompt to synthesize the final ADR.\nsynthesis_prompt = f\"\"\"\nYou are a Staff Engineer at Momentum, responsible for making and documenting key architectural decisions for the Onboarding Platform project.\n\n**Your Task:**\nBased on the technical research provided below, you need to create a formal Architectural Decision Record (ADR) that documents the decision to **use PostgreSQL with the pgvector extension** for implementing semantic search capabilities in our application.\n\n**Context:**\nAfter careful consideration of the trade-offs, the engineering team has decided to go with PostgreSQL + pgvector rather than a specialized vector database. Your job is to formally document this decision using the ADR template provided.\n\n**Instructions:**\n1. Populate the ADR template with the following details:\n   - **Title**: \"ADR-001: Database Choice for Semantic Search\"\n   - **Status**: \"Accepted\"\n   - **Date**: Use today's date (October 28, 2025)\n   \n2. Write the **Context** section by:\n   - Explaining the need for semantic search in the onboarding platform\n   - Describing the key forces and constraints (team size, operational complexity, need for reliability, budget)\n   - Summarizing the options that were considered\n   \n3. Write the **Decision** section by:\n   - Clearly stating the chosen solution: PostgreSQL with pgvector extension\n   - Briefly explaining what this means technically\n   - Providing 2-3 key reasons why this option was selected over the alternatives\n   \n4. Write the **Consequences** section by extracting insights from the research:\n   - **Positive**: List 3-4 concrete benefits of this decision (drawn from the research pros)\n   - **Negative**: List 2-3 honest drawbacks or limitations we accept (drawn from the research cons)\n   - **Neutral**: List 1-2 neutral implications or things to be aware of\n\n**Research Findings:**\n{db_research_output}\n\n**ADR Template to Populate:**\n{adr_template}\n\n**Output Requirements:**\n- Use professional, technical language appropriate for a formal architectural document\n- Be specific and concrete - avoid vague statements\n- Ensure the document will be valuable to future engineers who need to understand this decision\n- Remove any placeholder text or instructional comments from the template\n- Output the completed ADR in markdown format\n\nGenerate the completed ADR now:\n\"\"\"\n\nprint(\"--- Synthesizing Final ADR ---\")\nif adr_template and 'db_research_output' in locals() and db_research_output:\n    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n    print(final_adr)\n    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\")\nelse:\n    print(\"Skipping ADR synthesis because template or research is missing.\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "# ADR-001: Database Choice for Semantic Search\n",
      "\n",
      "## Status\n",
      "\n",
      "**Status**: Accepted\n",
      "\n",
      "## Date\n",
      "\n",
      "**Date**: 2025-10-28\n",
      "\n",
      "## Context\n",
      "\n",
      "### Problem Statement\n",
      "The Momentum Onboarding Platform requires a semantic search capability to allow users to find relevant information within our knowledge base (e.g., HR policies, technical documentation, setup guides) using natural language queries. A simple keyword search is insufficient as it fails to capture the user's intent. For example, a query for \"how do I get paid?\" should match documents titled \"Understanding Your Paystub\" or \"Setting Up Direct Deposit.\" This requires storing and querying high-dimensional vector embeddings generated from our documents.\n",
      "\n",
      "### Drivers & Constraints\n",
      "*   **Driver:** Implement a powerful semantic search feature to improve user experience and information discovery.\n",
      "*   **Driver:** Enable hybrid search, allowing users to filter search results by metadata (e.g., department, author, date) in addition to semantic relevance.\n",
      "*   **Constraint:** The solution must be reliable and maintain high data integrity, as it is a core feature of our B2B platform.\n",
      "*   **Constraint:** As a small engineering team, we must minimize operational complexity and avoid introducing new systems that require specialized maintenance skills.\n",
      "*   **Constraint:** The chosen solution must be cost-effective and leverage our existing infrastructure and expertise where possible.\n",
      "\n",
      "### Considered Options\n",
      "1.  **PostgreSQL with the `pgvector` extension:** Integrate vector search capabilities directly into our primary relational database.\n",
      "2.  **Specialized Vector Database (e.g., ChromaDB, FAISS):** Introduce a separate, purpose-built database dedicated to storing and querying vectors, running alongside our primary PostgreSQL database.\n",
      "\n",
      "## Decision\n",
      "\n",
      "We have decided to **use PostgreSQL with the `pgvector` extension** to implement semantic search capabilities.\n",
      "\n",
      "This means we will install the `pgvector` extension into our existing PostgreSQL database. Document embeddings will be stored in a `vector` column within the same table as the source text and associated metadata. Application queries will leverage standard SQL combined with `pgvector`'s distance functions to perform efficient similarity searches.\n",
      "\n",
      "This choice was made for the following key reasons:\n",
      "1.  **Architectural Simplicity:** It allows us to maintain a single, unified data store for both relational data and vector embeddings, drastically reducing system complexity.\n",
      "2.  **Operational Efficiency:** We avoid the significant overhead of deploying, monitoring, backing up, and securing a second database system, which is a critical advantage for our small team.\n",
      "3.  **Data Integrity and Hybrid Search:** Storing vectors with their source data in the same transaction-safe environment eliminates data synchronization issues and enables powerful, atomic hybrid queries that combine vector search with traditional SQL `WHERE` clauses.\n",
      "\n",
      "## Consequences\n",
      "\n",
      "### Positive\n",
      "*   **Reduced Operational Burden:** The team can leverage its existing PostgreSQL expertise and infrastructure for deployment, monitoring, and maintenance, avoiding the learning curve and operational cost of a new database technology.\n",
      "*   **Guaranteed Data Consistency:** By co-locating vectors and metadata, we eliminate the entire class of problems related to keeping two separate databases in sync. Updates are atomic and ACID-compliant.\n",
      "*   **Powerful, Flexible Querying:** We can immediately perform complex hybrid searches (e.g., find documents semantically similar to \"time off policy\" but only for the \"Engineering\" department and created in the last year) in a single, efficient SQL query.\n",
      "*   **Mature Ecosystem:** We benefit from PostgreSQL's battle-tested reliability, security, and extensive ecosystem of tools for backups, high availability, and performance tuning.\n",
      "\n",
      "### Negative\n",
      "*   **Potential Performance Ceiling:** At an extremely large scale (hundreds of millions of vectors), a specialized vector database might offer lower latency. We accept this trade-off, as our projected scale is well within `pgvector`'s performant range.\n",
      "*   **Not a Specialized Tool:** We will not have access to some of the cutting-edge indexing algorithms or the AI-native developer experience (e.g., Python-centric APIs) offered by purpose-built vector databases.\n",
      "*   **Extension Management:** We are responsible for managing the `pgvector` extension's update cycle, which is separate from the core PostgreSQL release schedule. This adds a minor maintenance task.\n",
      "\n",
      "### Neutral\n",
      "*   **Schema Design Implications:** Our database schema design will now incorporate the `vector` data type and indexing strategies (e.g., HNSW, IVFFlat), which will influence the design of future data models.\n",
      "*   **Monitoring Adjustments:** Existing PostgreSQL monitoring dashboards will need to be updated to track the performance of vector indexes and the resource consumption of search queries.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
