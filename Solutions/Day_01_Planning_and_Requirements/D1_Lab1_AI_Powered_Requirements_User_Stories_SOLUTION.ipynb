{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories (Solution)\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Introduction:**\n",
    "This notebook contains the complete solution for Lab 1. It demonstrates how to use an LLM to systematically break down a problem, generate structured requirements, and programmatically validate the output. Each step includes explanations of the code and the reasoning behind the prompts.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Purpose:** This initial block of code prepares our environment for the lab. It adds the project root to the system path to ensure our `utils.py` helper script can be imported, and then initializes the LLM API client.\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Libraries Explained:**\n",
    "- **`os`**, **`sys`**: Standard Python libraries for interacting with the file system and Python's path, ensuring our modules are discoverable.\n",
    "- **`json`**: A standard library for working with JSON data. We use `json.loads` to parse the LLM's text output into a Python dictionary or list, and `json.dumps` to format Python objects into a pretty-printed JSON string for saving.\n",
    "- **`utils`**: Our custom helper script. \n",
    "  - `setup_llm_client()`: Handles reading the `.env` file and initializing the API client.\n",
    "  - `get_completion()`: Simplifies the process of sending a prompt to the LLM and receiving a text response.\n",
    "  - `save_artifact()`: Ensures our project artifacts are stored consistently in the `artifacts` directory.\n",
    "  - `clean_llm_output()`: A new standardized function to remove markdown fences from LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "We define our starting point—a simple, high-level problem statement—as a Python variable. This makes it easy to reuse in multiple prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help our company's new hires get up to speed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Here are the complete solutions for each challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Explanation:**\n",
    "This first challenge is about exploration. We use simple, direct prompts to get the LLM's initial thoughts on the problem. The goal is to generate a broad set of ideas (features and personas) that will serve as the raw material for the more structured tasks to follow. We expect the output to be human-readable markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Brainstorming Features ---\n",
      "- **Interactive Onboarding Checklist**: A dynamic checklist that guides new hires through essential tasks and milestones during their first weeks or months.\n",
      "- **Welcome Videos**: Engaging video messages from the CEO, managers, and team members to introduce company culture and values.\n",
      "- **Company Handbook Access**: A digital version of the company handbook with search functionality for easy navigation.\n",
      "- **Document Upload and Management**: A secure portal for new hires to upload necessary documents such as identification, tax forms, and direct deposit information.\n",
      "- **Progress Tracking**: A dashboard that allows both new hires and managers to track onboarding progress and completion of required tasks.\n",
      "- **Training Modules**: Interactive and self-paced online training sessions covering company policies, software tools, and role-specific skills.\n",
      "- **Virtual Office Tour**: A virtual reality or video tour of the office to familiarize remote hires with the physical workspace.\n",
      "- **Mentorship Program Access**: Tools to connect new hires with mentors within the company for guidance and support.\n",
      "- **Communication Tools Integration**: Seamless integration with company communication platforms like Slack, Microsoft Teams, or email for easy connectivity.\n",
      "- **Feedback Mechanism**: A system for new hires to provide feedback on the onboarding experience for continuous improvement.\n",
      "- **Social Introductions**: Features to help new hires connect with colleagues, including a digital meet-and-greet and team introduction pages.\n",
      "- **FAQ Section**: A comprehensive FAQ section answering common questions new hires may have.\n",
      "- **Event Calendar**: A calendar featuring important company events, training sessions, and social gatherings.\n",
      "- **HR Support Chat**: An integrated chat feature that allows new hires to ask HR-related questions in real-time.\n",
      "- **Personalization Options**: Customizable profiles for new hires to fill out interests, skills, and goals to help tailor their onboarding experience.\n",
      "- **Resource Library**: Access to a library of resources, including articles, videos, and guides relevant to their roles and departments.\n",
      "- **Role-Specific Information**: Tailored content and resources based on the new hire’s specific role and team.\n",
      "\n",
      "--- Identifying User Personas ---\n",
      "To effectively address the problem statement, \"We need a tool to help our company's new hires get up to speed,\" we can identify three distinct user personas who would interact with this tool. Each persona represents a different aspect of the onboarding process and has unique roles and goals:\n",
      "\n",
      "1. **New Hire (Entry-Level Employee)**\n",
      "   - **Role:** This persona represents a newly hired employee who is joining the company, potentially for their first professional role. They may be recent graduates or individuals transitioning into a new industry.\n",
      "   - **Main Goal:** The primary goal of the new hire is to quickly learn and adapt to the company's culture, processes, and expectations. They aim to become productive members of the team by understanding their responsibilities, mastering necessary skills, and integrating with their colleagues effectively. The tool should provide them with the necessary resources, training modules, and a roadmap for their initial weeks or months at the company.\n",
      "\n",
      "2. **HR Manager (Onboarding Coordinator)**\n",
      "   - **Role:** The HR manager is responsible for designing and overseeing the onboarding process. They ensure that new hires have a smooth transition into the company and receive all necessary information and training.\n",
      "   - **Main Goal:** The HR manager's main goal is to streamline the onboarding process to enhance efficiency and ensure consistency across all new hires. They seek to provide a structured and engaging onboarding experience that covers all essential topics, reduces time-to-productivity, and improves employee retention. The tool should allow them to track progress, gather feedback, and adjust the onboarding program as necessary.\n",
      "\n",
      "3. **Team Leader (Direct Supervisor)**\n",
      "   - **Role:** The team leader is the new hire’s direct supervisor within their department. They are responsible for guiding the new hire through department-specific tasks and ensuring they understand their role within the team.\n",
      "   - **Main Goal:** The team leader aims to integrate the new hire into the team as quickly and seamlessly as possible. They focus on ensuring the new hire understands their specific job duties, aligns with team objectives, and receives any necessary mentorship or support. The tool should provide the team leader with insights into the new hire’s progress, allow for personalized task assignments, and facilitate communication and feedback.\n",
      "\n",
      "Each of these personas interacts with the onboarding tool in ways that align with their roles and objectives, ensuring a comprehensive and effective onboarding process for new hires.\n"
     ]
    }
   ],
   "source": [
    "# This prompt is direct and open-ended, encouraging the LLM to be creative.\n",
    "features_prompt = f\"\"\"\n",
    "Based on the problem statement: '{problem_statement}', brainstorm a list of potential features for a new hire onboarding tool. \n",
    "Format the output as a simple markdown list.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Brainstorming Features ---\")\n",
    "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_features)\n",
    "\n",
    "# This prompt asks for specific roles to ground the brainstorming in user-centric thinking.\n",
    "personas_prompt = f\"\"\"\n",
    "Based on the problem statement: '{problem_statement}', identify and describe three distinct user personas who would interact with this tool. \n",
    "For each persona, describe their role and main goal.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Identifying User Personas ---\")\n",
    "user_personas = get_completion(personas_prompt, client, model_name, api_provider)\n",
    "print(user_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Explanation:**\n",
    "This challenge represents a significant increase in complexity and value. We are no longer asking for simple text; we are demanding a specific, structured data format (JSON). \n",
    "\n",
    "The prompt is carefully engineered:\n",
    "1.  **Persona:** `You are a Senior Product Manager...` tells the LLM the role it should adopt.\n",
    "2.  **Context:** We provide the previous outputs (`problem_statement`, `brainstormed_features`, `user_personas`) inside `<context>` tags to give the LLM all the necessary information.\n",
    "3.  **Format:** The `OUTPUT REQUIREMENTS` section is extremely explicit. It tells the LLM to *only* output JSON, defines the exact keys for each object, and specifies the format for nested data (like the array of Gherkin strings). This strictness is key to getting reliable, machine-readable output.\n",
    "4.  **Parsing:** The `try...except` block is a crucial step. It attempts to parse the LLM's string output into a Python list of dictionaries. If it succeeds, we know the LLM followed our instructions perfectly. If it fails, we print the raw output to help debug the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating User Stories as JSON ---\n",
      "Successfully parsed LLM output as JSON.\n",
      "\n",
      "--- Sample User Story ---\n",
      "{\n",
      "  \"id\": 1,\n",
      "  \"persona\": \"New Hire (Entry-Level Employee)\",\n",
      "  \"user_story\": \"As a New Hire, I want an interactive onboarding checklist, so that I can easily track and complete essential tasks during my first weeks.\",\n",
      "  \"acceptance_criteria\": [\n",
      "    \"Given I am a new hire, When I log into the onboarding tool, Then I should see an interactive checklist with tasks to complete.\",\n",
      "    \"Given I have completed a task, When I mark it as done, Then it should update my progress on the checklist.\",\n",
      "    \"Given I have tasks due, When I view the checklist, Then I should see due dates and priority levels for each task.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The prompt is highly-structured to guide the LLM toward a perfect JSON output.\n",
    "json_user_stories_prompt = f\"\"\"\n",
    "You are a Senior Product Manager creating a product backlog for a new hire onboarding tool.\n",
    "\n",
    "Based on the following context:\n",
    "<context>\n",
    "Problem Statement: {problem_statement}\n",
    "Potential Features: {brainstormed_features}\n",
    "User Personas: {user_personas}\n",
    "</context>\n",
    "\n",
    "Your task is to generate a list of 5 detailed user stories.\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- You MUST output a valid JSON array. Your response must begin with [ and end with ]. Do not include any text or markdown before or after the JSON array.\n",
    "- Each object in the array must represent a single user story.\n",
    "- Each object must have the following keys: 'id' (an integer), 'persona' (a string from the personas), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "# We set a lower temperature to encourage the LLM to stick to the requested format.\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "# Attempt to parse the string output into a Python list.\n",
    "try:\n",
    "    # Use our new standardized cleaning function from utils.py\n",
    "    cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "    \n",
    "    user_stories_json = json.loads(cleaned_json_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    # Pretty-print the first user story to verify its structure\n",
    "    print(\"\\n--- Sample User Story ---\")\n",
    "    print(json.dumps(user_stories_json[0], indent=2))\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    user_stories_json = [] # Assign an empty list to prevent errors in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Explanation:**\n",
    "This is the final and most critical step. We treat the LLM's output as untrusted input and subject it to programmatic validation. This ensures that the artifact we create is reliable and can be consumed by other automated tools in later stages of the SDLC without causing errors. \n",
    "\n",
    "The `validate_and_save_stories` function acts as a gatekeeper. It checks for the correct data types (a list of objects) and ensures that all required fields are present in each object. Only if all checks pass do we proceed to save the file using `save_artifact`. This creates a trustworthy `day1_user_stories.json` file that can be confidently used as an input for other automated processes in our SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All user stories passed validation.\n",
      "✅ Successfully saved artifact to: artifacts/day1_user_stories.json\n"
     ]
    }
   ],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # Loop through each story object in the list.\n",
    "    for i, story in enumerate(stories_data):\n",
    "        # Check for the presence of all required keys.\n",
    "        if not all(key in story for key in required_keys):\n",
    "            print(f\"Validation Failed: Story at index {i} is missing one or more required keys.\")\n",
    "            all_stories_valid = False\n",
    "            continue # Don't bother with further checks for this invalid story\n",
    "        \n",
    "        # Check that the acceptance criteria is a list with at least one item.\n",
    "        ac = story.get('acceptance_criteria')\n",
    "        if not isinstance(ac, list) or not ac:\n",
    "            print(f\"Validation Failed: Story at index {i} ('{story.get('id')}') has invalid or empty acceptance criteria.\")\n",
    "            all_stories_valid = False\n",
    "\n",
    "    # Only save the artifact if all stories in the list are valid.\n",
    "    if all_stories_valid:\n",
    "        print(\"\\nAll user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # Use the helper function to save the file, creating the 'artifacts' directory if needed.\n",
    "        # We use json.dumps with an indent to make the saved file human-readable.\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "    else:\n",
    "        print(\"\\nValidation failed. Artifact not saved.\")\n",
    "\n",
    "# Run the validation function on the data we parsed from the LLM.\n",
    "if 'user_stories_json' in locals() and user_stories_json:\n",
    "    validate_and_save_stories(user_stories_json)\n",
    "else:\n",
    "    print(\"Skipping validation as user_stories_json is empty or could not be parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
