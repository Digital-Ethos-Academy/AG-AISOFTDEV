{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories (Solution)\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Introduction:**\n",
    "This notebook contains the complete solution for Lab 1. It demonstrates how to use an LLM to systematically break down a problem, generate structured requirements, and programmatically validate the output. Each step includes explanations of the code and the reasoning behind the prompts.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Purpose:** This initial block of code prepares our environment for the lab. It adds the project root to the system path to ensure our `utils.py` helper script can be imported, and then initializes the LLM API client.\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Libraries Explained:**\n",
    "- **`os`**, **`sys`**: Standard Python libraries for interacting with the file system and Python's path, ensuring our modules are discoverable.\n",
    "- **`json`**: A standard library for working with JSON data. We use `json.loads` to parse the LLM's text output into a Python dictionary or list, and `json.dumps` to format Python objects into a pretty-printed JSON string for saving.\n",
    "- **`utils`**: Our custom helper script. \n",
    "  - `setup_llm_client()`: Handles reading the `.env` file and initializing the API client.\n",
    "  - `get_completion()`: Simplifies the process of sending a prompt to the LLM and receiving a text response.\n",
    "  - `save_artifact()`: Ensures our project artifacts are stored consistently in the `artifacts` directory.\n",
    "  - `clean_llm_output()`: A new standardized function to remove markdown fences from LLM outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output\n",
    "\n",
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "We define our starting point—a simple, high-level problem statement—as a Python variable. This makes it easy to reuse in multiple prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help our company's new hires get up to speed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Here are the complete solutions for each challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Explanation:**\n",
    "This first challenge is about exploration. We use simple, direct prompts to get the LLM's initial thoughts on the problem. The goal is to generate a broad set of ideas (features and personas) that will serve as the raw material for the more structured tasks to follow. We expect the output to be human-readable markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Brainstorming Features ---\n",
      "- **Welcome Dashboard**\n",
      "  - Personalized welcome message\n",
      "  - Overview of the onboarding process\n",
      "  - Quick links to essential resources\n",
      "\n",
      "- **Task Checklist**\n",
      "  - Step-by-step onboarding tasks\n",
      "  - Progress tracking\n",
      "  - Due dates and reminders\n",
      "\n",
      "- **Document Repository**\n",
      "  - Access to company policies and manuals\n",
      "  - Downloadable forms and templates\n",
      "  - Version control for document updates\n",
      "\n",
      "- **Interactive Training Modules**\n",
      "  - Video tutorials and webinars\n",
      "  - Quizzes and assessments\n",
      "  - Gamified learning elements\n",
      "\n",
      "- **Mentorship Program Integration**\n",
      "  - Automated mentor matching\n",
      "  - Scheduled mentor meetings\n",
      "  - Feedback and evaluation forms\n",
      "\n",
      "- **Company Culture Introduction**\n",
      "  - Videos introducing company values and mission\n",
      "  - Employee testimonials and success stories\n",
      "  - Virtual office tours\n",
      "\n",
      "- **Communication Tools**\n",
      "  - Integrated chat with HR and team members\n",
      "  - FAQ section and helpdesk access\n",
      "  - Scheduled Q&A sessions with leadership\n",
      "\n",
      "- **Feedback Mechanism**\n",
      "  - Anonymous feedback submission\n",
      "  - Surveys on onboarding experience\n",
      "  - Suggestion box for improvements\n",
      "\n",
      "- **Social Integration**\n",
      "  - Employee directory with profiles\n",
      "  - Team introductions and social events calendar\n",
      "  - Integration with internal social networks or forums\n",
      "\n",
      "- **IT and Systems Setup**\n",
      "  - Automated account creation and access provisioning\n",
      "  - Step-by-step guides for software installations\n",
      "  - Troubleshooting and tech support contact\n",
      "\n",
      "- **Compliance and Security Training**\n",
      "  - Mandatory training sessions and certifications\n",
      "  - Security policy acknowledgements\n",
      "  - Incident reporting procedures\n",
      "\n",
      "- **Performance Goals and Expectations**\n",
      "  - Initial goal setting with managers\n",
      "  - Regular check-ins and progress reviews\n",
      "  - Personal development plan templates\n",
      "\n",
      "- **Mobile App Access**\n",
      "  - On-the-go task management\n",
      "  - Push notifications for deadlines and updates\n",
      "  - Offline access to essential resources\n",
      "\n",
      "- **Customization Options**\n",
      "  - Personalized onboarding paths based on role or department\n",
      "  - Language and accessibility options\n",
      "  - Customizable dashboard widgets\n",
      "\n",
      "- **Reporting and Analytics**\n",
      "  - Onboarding completion rates\n",
      "  - Time spent on training modules\n",
      "  - Areas of improvement and bottleneck identification\n",
      "\n",
      "--- Identifying User Personas ---\n",
      "To effectively address the problem statement of helping new hires get up to speed, it's important to identify the key user personas who will interact with the tool. Here are three distinct user personas:\n",
      "\n",
      "1. **New Hire (Entry-Level Employee)**\n",
      "   - **Role:** Recently joined the company in an entry-level position, such as a junior analyst, associate, or intern.\n",
      "   - **Main Goal:** To quickly acclimate to the company culture, understand job responsibilities, and develop the skills necessary to perform their tasks efficiently. They seek a comprehensive onboarding experience that includes access to training materials, company policies, and a clear understanding of their role within the team.\n",
      "\n",
      "2. **Human Resources Manager**\n",
      "   - **Role:** Responsible for onboarding new employees, ensuring they have a smooth transition into the company, and facilitating their initial training.\n",
      "   - **Main Goal:** To streamline the onboarding process, reduce the time it takes for new hires to become productive, and ensure they have access to the necessary resources and information. The HR manager aims to provide a consistent and engaging onboarding experience that aligns with the company’s values and objectives.\n",
      "\n",
      "3. **Direct Supervisor/Team Lead**\n",
      "   - **Role:** Oversees the new hire's day-to-day activities and provides guidance and support as they settle into their role.\n",
      "   - **Main Goal:** To ensure that the new hire is integrating well into the team, understands their specific tasks and goals, and is contributing effectively. The supervisor seeks to track the new hire’s progress, offer feedback, and identify any additional training or support they may need to succeed in their position.\n",
      "\n",
      "Each of these personas interacts with the tool from a different perspective, contributing to a holistic onboarding experience that addresses the needs of the new hire while supporting the goals of HR professionals and direct supervisors.\n"
     ]
    }
   ],
   "source": [
    "# This prompt is direct and open-ended, encouraging the LLM to be creative.\n",
    "features_prompt = f\"\"\"\n",
    "Based on the problem statement: '{problem_statement}', brainstorm a list of potential features for a new hire onboarding tool. \n",
    "Format the output as a simple markdown list.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Brainstorming Features ---\")\n",
    "brainstormed_features = get_completion(features_prompt, client, model_name, api_provider)\n",
    "print(brainstormed_features)\n",
    "\n",
    "# This prompt asks for specific roles to ground the brainstorming in user-centric thinking.\n",
    "personas_prompt = f\"\"\"\n",
    "Based on the problem statement: '{problem_statement}', identify and describe three distinct user personas who would interact with this tool. \n",
    "For each persona, describe their role and main goal.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- Identifying User Personas ---\")\n",
    "user_personas = get_completion(personas_prompt, client, model_name, api_provider)\n",
    "print(user_personas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Explanation:**\n",
    "This challenge represents a significant increase in complexity and value. We are no longer asking for simple text; we are demanding a specific, structured data format (JSON). \n",
    "\n",
    "The prompt is carefully engineered:\n",
    "1.  **Persona:** `You are a Senior Product Manager...` tells the LLM the role it should adopt.\n",
    "2.  **Context:** We provide the previous outputs (`problem_statement`, `brainstormed_features`, `user_personas`) inside `<context>` tags to give the LLM all the necessary information.\n",
    "3.  **Format:** The `OUTPUT REQUIREMENTS` section is extremely explicit. It tells the LLM to *only* output JSON, defines the exact keys for each object, and specifies the format for nested data (like the array of Gherkin strings). This strictness is key to getting reliable, machine-readable output.\n",
    "4.  **Parsing:** The `try...except` block is a crucial step. It attempts to parse the LLM's string output into a Python list of dictionaries. If it succeeds, we know the LLM followed our instructions perfectly. If it fails, we print the raw output to help debug the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating User Stories as JSON ---\n",
      "Successfully parsed LLM output as JSON.\n",
      "\n",
      "--- Sample User Story ---\n",
      "{\n",
      "  \"id\": 1,\n",
      "  \"persona\": \"New Hire (Entry-Level Employee)\",\n",
      "  \"user_story\": \"As a New Hire (Entry-Level Employee), I want a personalized welcome dashboard, so that I can quickly access essential resources and understand the onboarding process.\",\n",
      "  \"acceptance_criteria\": [\n",
      "    \"Given I am a new hire, When I log into the onboarding tool, Then I should see a personalized welcome message.\",\n",
      "    \"Given I am on the welcome dashboard, When I look for resources, Then I should see quick links to essential resources.\",\n",
      "    \"Given I am on the welcome dashboard, When I want to understand the onboarding process, Then I should see an overview of the onboarding process.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# The prompt is highly-structured to guide the LLM toward a perfect JSON output.\n",
    "json_user_stories_prompt = f\"\"\"\n",
    "You are a Senior Product Manager creating a product backlog for a new hire onboarding tool.\n",
    "\n",
    "Based on the following context:\n",
    "<context>\n",
    "Problem Statement: {problem_statement}\n",
    "Potential Features: {brainstormed_features}\n",
    "User Personas: {user_personas}\n",
    "</context>\n",
    "\n",
    "Your task is to generate a list of 5 detailed user stories.\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- You MUST output a valid JSON array. Your response must begin with [ and end with ]. Do not include any text or markdown before or after the JSON array.\n",
    "- Each object in the array must represent a single user story.\n",
    "- Each object must have the following keys: 'id' (an integer), 'persona' (a string from the personas), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "# We set a lower temperature to encourage the LLM to stick to the requested format.\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "# Attempt to parse the string output into a Python list.\n",
    "try:\n",
    "    # Use our new standardized cleaning function from utils.py\n",
    "    cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "    \n",
    "    user_stories_json = json.loads(cleaned_json_str)\n",
    "    print(\"Successfully parsed LLM output as JSON.\")\n",
    "    # Pretty-print the first user story to verify its structure\n",
    "    print(\"\\n--- Sample User Story ---\")\n",
    "    print(json.dumps(user_stories_json[0], indent=2))\n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"LLM Output was:\\n\", json_output_str)\n",
    "    user_stories_json = [] # Assign an empty list to prevent errors in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Explanation:**\n",
    "This is the final and most critical step. We treat the LLM's output as untrusted input and subject it to programmatic validation. This ensures that the artifact we create is reliable and can be consumed by other automated tools in later stages of the SDLC without causing errors. \n",
    "\n",
    "The `validate_and_save_stories` function acts as a gatekeeper. It checks for the correct data types (a list of objects) and ensures that all required fields are present in each object. Only if all checks pass do we proceed to save the file using `save_artifact`. This creates a trustworthy `day1_user_stories.json` file that can be confidently used as an input for other automated processes in our SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All user stories passed validation.\n",
      "✅ Successfully saved artifact to: artifacts/day1_user_stories.json\n"
     ]
    }
   ],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # Loop through each story object in the list.\n",
    "    for i, story in enumerate(stories_data):\n",
    "        # Check for the presence of all required keys.\n",
    "        if not all(key in story for key in required_keys):\n",
    "            print(f\"Validation Failed: Story at index {i} is missing one or more required keys.\")\n",
    "            all_stories_valid = False\n",
    "            continue # Don't bother with further checks for this invalid story\n",
    "        \n",
    "        # Check that the acceptance criteria is a list with at least one item.\n",
    "        ac = story.get('acceptance_criteria')\n",
    "        if not isinstance(ac, list) or not ac:\n",
    "            print(f\"Validation Failed: Story at index {i} ('{story.get('id')}') has invalid or empty acceptance criteria.\")\n",
    "            all_stories_valid = False\n",
    "\n",
    "    # Only save the artifact if all stories in the list are valid.\n",
    "    if all_stories_valid:\n",
    "        print(\"\\nAll user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # Use the helper function to save the file, creating the 'artifacts' directory if needed.\n",
    "        # We use json.dumps with an indent to make the saved file human-readable.\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "    else:\n",
    "        print(\"\\nValidation failed. Artifact not saved.\")\n",
    "\n",
    "# Run the validation function on the data we parsed from the LLM.\n",
    "if 'user_stories_json' in locals() and user_stories_json:\n",
    "    validate_and_save_stories(user_stories_json)\n",
    "else:\n",
    "    print(\"Skipping validation as user_stories_json is empty or could not be parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
