{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1 - Lab 1: AI-Powered Requirements & User Stories (Solution)\n",
    "\n",
    "**Objective:** Use a Large Language Model (LLM) to decompose a vague problem statement into structured features, user personas, and Agile user stories, culminating in a machine-readable JSON artifact.\n",
    "\n",
    "**Introduction:**\n",
    "This notebook contains the complete solution for Lab 1. It demonstrates how to use an LLM to systematically break down a problem, generate structured requirements, and programmatically validate the output. Each step includes explanations of the code and the reasoning behind the prompts.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup\n",
    "\n",
    "**Purpose:** This initial block of code prepares our environment for the lab. It adds the project root to the system path to ensure our `utils.py` helper script can be imported, and then initializes the LLM API client.\n",
    "\n",
    "**Model Selection:**\n",
    "Our `utils.py` script is configured to work with multiple AI providers. You can change the `model_name` parameter in the `setup_llm_client()` function to any of the models listed in the `RECOMMENDED_MODELS` dictionary in `utils.py`. For example, to use a Hugging Face model, you could change the line to: `client, model_name, api_provider = setup_llm_client(model_name=\"meta-llama/Llama-3.3-70B-Instruct\")`\n",
    "\n",
    "**Libraries Explained:**\n",
    "- **`os`**, **`sys`**: Standard Python libraries for interacting with the file system and Python's path, ensuring our modules are discoverable.\n",
    "- **`json`**: A standard library for working with JSON data. We use `json.loads` to parse the LLM's text output into a Python dictionary or list, and `json.dumps` to format Python objects into a pretty-printed JSON string for saving.\n",
    "- **`utils`**: Our custom helper script. \n",
    "  - `setup_llm_client()`: Handles reading the `.env` file and initializing the API client.\n",
    "  - `get_completion()`: Simplifies the process of sending a prompt to the LLM and receiving a text response.\n",
    "  - `save_artifact()`: Ensures our project artifacts are stored consistently in the `artifacts` directory.\n",
    "  - `clean_llm_output()`: A new standardized function to remove markdown fences from LLM outputs.\n",
    "  - `prompt_enhancer()`: An advanced meta-prompt system that takes raw user input and optimizes it using prompt engineering best practices, including role assignment, context grounding, and structural organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'labs/Day_01_.../'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, clean_llm_output, recommended_models_table, prompt_enhancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| Qwen/Qwen-Image | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| Qwen/Qwen-Image-Edit | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\n",
       "| black-forest-labs/FLUX.1-Kontext-dev | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\n",
       "| claude-opus-4-1-20250805 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-opus-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-sonnet-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| codex-mini-latest | openai | ✅ | ❌ | ❌ | ❌ | ❌ | - | - |\n",
       "| dall-e-3 | openai | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| deepseek-ai/DeepSeek-V3.1 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 128,000 | 100,000 |\n",
       "| gemini-1.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 8,192 |\n",
       "| gemini-1.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 2,000,000 | 8,192 |\n",
       "| gemini-2.0-flash-exp | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gemini-2.0-flash-preview-image-generation | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,000 | 8,192 |\n",
       "| gemini-2.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-flash-image-preview | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,768 | 32,768 |\n",
       "| gemini-2.5-flash-lite | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-live-2.5-flash-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gpt-4.1 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,768 |\n",
       "| gpt-4.1-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4.1-nano | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4o | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-4o-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-5-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-mini-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-nano-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-image-1 | openai | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| meta-llama/Llama-3.3-70B-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 8,192 | 4,096 |\n",
       "| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 10,000,000 | 100,000 |\n",
       "| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 32,768 | 8,192 |\n",
       "| o3 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| o4-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| stabilityai/stable-diffusion-3.5-large | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 4,096 | 1,024 |\n",
       "| veo-3.0-fast-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\n",
       "| veo-3.0-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\n",
       "| whisper-1 | openai | ❌ | ❌ | ❌ | ❌ | ✅ | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'| Model | Provider | Text | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\\n|---|---|---|---|---|---|---|---|---|\\n| Qwen/Qwen-Image | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\\n| Qwen/Qwen-Image-Edit | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\\n| black-forest-labs/FLUX.1-Kontext-dev | huggingface | ❌ | ❌ | ❌ | ✅ | ❌ | - | - |\\n| claude-opus-4-1-20250805 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| claude-opus-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| claude-sonnet-4-20250514 | anthropic | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\\n| codex-mini-latest | openai | ✅ | ❌ | ❌ | ❌ | ❌ | - | - |\\n| dall-e-3 | openai | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\\n| deepseek-ai/DeepSeek-V3.1 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 128,000 | 100,000 |\\n| gemini-1.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 8,192 |\\n| gemini-1.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 2,000,000 | 8,192 |\\n| gemini-2.0-flash-exp | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gemini-2.0-flash-preview-image-generation | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,000 | 8,192 |\\n| gemini-2.5-flash | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-2.5-flash-image-preview | google | ❌ | ❌ | ✅ | ❌ | ❌ | 32,768 | 32,768 |\\n| gemini-2.5-flash-lite | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-2.5-pro | google | ✅ | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\\n| gemini-live-2.5-flash-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\\n| gpt-4.1 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,768 |\\n| gpt-4.1-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\\n| gpt-4.1-nano | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\\n| gpt-4o | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\\n| gpt-4o-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\\n| gpt-5-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-5-mini-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-5-nano-2025-08-07 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\\n| gpt-image-1 | openai | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\\n| meta-llama/Llama-3.3-70B-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 8,192 | 4,096 |\\n| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\\n| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 10,000,000 | 100,000 |\\n| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 32,768 | 8,192 |\\n| o3 | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| o4-mini | openai | ✅ | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\\n| stabilityai/stable-diffusion-3.5-large | huggingface | ❌ | ❌ | ✅ | ❌ | ❌ | - | - |\\n| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | ✅ | ❌ | ❌ | ❌ | ❌ | 4,096 | 1,024 |\\n| veo-3.0-fast-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\\n| veo-3.0-generate-preview | google | ❌ | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\\n| whisper-1 | openai | ❌ | ❌ | ❌ | ❌ | ✅ | - | - |'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_models_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'google' with model 'gemini-2.5-pro'\n",
      "✅ LLM Client configured: Using 'huggingface' with model 'deepseek-ai/DeepSeek-V3.1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/agaleana/repos/AG-AISOFTDEV/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM client. You can change the model here.\n",
    "# For example: setup_llm_client(model_name=\"gemini-2.5-flash\")\n",
    "brainstormed_features_client, brainstormed_features_model_name, brainstormed_features_api_provider = setup_llm_client(model_name=\"gemini-2.5-pro\")\n",
    "user_personas_client, user_personas_model_name, user_personas_api_provider = setup_llm_client(model_name=\"deepseek-ai/DeepSeek-V3.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Problem Statement\n",
    "\n",
    "We define our starting point—a simple, high-level problem statement—as a Python variable. This makes it easy to reuse in multiple prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_statement = \"We need a tool to help our company's new hires get up to speed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: The Challenges\n",
    "\n",
    "Here are the complete solutions for each challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): Brainstorming Features\n",
    "\n",
    "**Explanation:**\n",
    "This first challenge demonstrates the power of prompt enhancement. We start with simple, raw prompts for brainstorming features and identifying user personas. However, instead of using these basic prompts directly, we pass them through our `prompt_enhancer` function, which applies advanced prompt engineering techniques to optimize them.\n",
    "\n",
    "The `prompt_enhancer` automatically:\n",
    "- Assigns appropriate expert personas (e.g., \"You are a Senior Product Manager\")\n",
    "- Provides structured context and grounding\n",
    "- Defines clear task instructions with assertive action verbs\n",
    "- Sets explicit output format expectations\n",
    "- Organizes the prompt with clear structural delimiters\n",
    "\n",
    "**Key Efficiency Features:**\n",
    "- We reuse the existing LLM clients that were already initialized, avoiding duplicate setup\n",
    "- Different models can be used for different tasks (e.g., Gemini for features, DeepSeek for personas)\n",
    "- The personas prompt includes the brainstormed features as context for better coherence\n",
    "\n",
    "This enhancement process transforms simple requests into highly optimized prompts that produce more focused, detailed, and useful outputs. The goal is to generate a broad set of high-quality ideas (features and personas) that will serve as the foundation for the more structured tasks to follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CHALLENGE 1: AI-POWERED REQUIREMENTS GENERATION\n",
      "============================================================\n",
      "\n",
      "--- STEP 1: ENHANCING FEATURES PROMPT ---\n",
      "Enhanced prompt preview (first 200 chars): ```xml\n",
      "<persona>\n",
      "You are an expert Product Manager specializing in Human Resources (HR) technology and employee experience platforms. You have extensive experience designing successful onboarding soft...\n",
      "\n",
      "--- STEP 2: GENERATING BRAINSTORMED FEATURES ---\n",
      "Enhanced prompt preview (first 200 chars): ```xml\n",
      "<persona>\n",
      "You are an expert Product Manager specializing in Human Resources (HR) technology and employee experience platforms. You have extensive experience designing successful onboarding soft...\n",
      "\n",
      "--- STEP 2: GENERATING BRAINSTORMED FEATURES ---\n",
      "Alright team, let's gather around the virtual whiteboard. As the Product Manager for this new onboarding initiative, my goal is to architect a solution that not only solves the core administrative headaches but also creates a genuinely welcoming, effective, and memorable experience for every new hire. We want them to feel connected, confident, and productive from day one.\n",
      "\n",
      "I've structured our brainstorming around the four foundational pillars of a world-class onboarding experience. Here is a comprehensive list of features we should consider building.\n",
      "\n",
      "***\n",
      "\n",
      "## Administrative & Logistics\n",
      "\n",
      "This pillar is about creating a frictionless, \"zero-stress\" start. We need to eliminate confusion and administrative burdens so the new hire can focus on what matters.\n",
      "\n",
      "-   **Pre-boarding Portal:** A centralized web portal accessible to the new hire before their start date.\n",
      "-   **Digital Document & E-Signature Hub:** Securely upload required documents (ID, work authorization) and electronically sign all necessary paperwork (offer letter, NDAs, policy acknowledgements).\n",
      "-   **Dynamic Onboarding Checklist:** An interactive, step-by-step checklist that guides the new hire through all pre-start and first-week tasks, with clear deadlines and progress tracking.\n",
      "-   **Automated IT Provisioning Tracker:** A dashboard for the new hire to track the status of their equipment (e.g., \"Laptop Shipped\") and account creations (e.g., \"Email Account Ready\").\n",
      "-   **Hardware & Software Selection:** A simple interface for new hires to select their preferred hardware (e.g., Mac vs. PC) and request any non-standard software they need for their role.\n",
      "-   **Personalized \"First Week\" Agenda:** An automatically generated and integrated calendar for the first week, pre-populated with key meetings like HR orientation, team intros, and manager 1:1s.\n",
      "-   **Guided Benefits Enrollment:** An intuitive, wizard-like experience that simplifies the benefits selection process with clear explanations and comparison tools.\n",
      "\n",
      "## Learning & Development\n",
      "\n",
      "This pillar focuses on accelerating the new hire's path to competency and productivity. The goal is to provide clear, role-specific guidance and learning resources.\n",
      "\n",
      "-   **Collaborative 30-60-90 Day Plan:** A customizable plan with clear goals, milestones, and deliverables for the first three months, shared between the new hire and their manager.\n",
      "-   **Role-Specific Learning Pathways:** Curated learning paths with a mix of content (videos, articles, e-learning modules) tailored to the new hire's specific department and role.\n",
      "-   **In-App System Tutorials:** Interactive, guided walkthroughs of the core software and tools the new hire will be using daily (e.g., CRM, project management tool, internal wikis).\n",
      "-   **Centralized Knowledge Base:** A powerful, AI-driven search engine to find company information, process documentation, and answers to frequently asked questions.\n",
      "-   **Micro-learning Nudges:** Automated, bite-sized learning tips and best practices delivered via email or chat to reinforce training over time.\n",
      "-   **Skill Gap Self-Assessment:** An initial survey to help new hires and their managers identify potential knowledge gaps and automatically recommend relevant training.\n",
      "-   **Job Shadowing Scheduler:** A tool to easily find and request time to shadow key colleagues and understand different aspects of the business.\n",
      "\n",
      "## Cultural Integration\n",
      "\n",
      "This is about connecting the new hire to the company's mission, values, and unique way of working. We want them to understand the \"why\" and feel like they belong.\n",
      "\n",
      "-   **Interactive Company History Timeline:** A visual and engaging presentation of the company's origin story, major milestones, and vision for the future.\n",
      "-   **\"Meet the Leadership\" Video Library:** A collection of short, authentic videos from company leaders sharing insights on culture, values, and strategy.\n",
      "-   **Internal Lingo & Acronym Dictionary:** A searchable glossary of company-specific jargon to help new hires quickly get up to speed in meetings and conversations.\n",
      "-   **Values-in-Action Scenarios:** Interactive quizzes that present real-world business situations and challenge the new hire to apply the company's core values.\n",
      "-   **Digital \"How We Work\" Playbook:** An accessible guide to the company's communication norms, meeting etiquette, decision-making frameworks, and unwritten rules.\n",
      "-   **Virtual Office Tour:** A 360-degree virtual tour of the main office(s) to give remote and hybrid employees a sense of place and connection.\n",
      "\n",
      "## Social Connection\n",
      "\n",
      "This pillar is designed to combat new-hire isolation by intentionally fostering relationships and building a strong professional network from the very beginning.\n",
      "\n",
      "-   **Automated Buddy Program:** An intelligent system that pairs new hires with an experienced employee (their \"Onboarding Buddy\") and provides both with conversation starters, checklists, and recommended activities.\n",
      "-   **Interactive Org Chart & Team Directory:** A rich, visual directory of employees with photos, roles, bios, fun facts, and areas of expertise to make it easy to find and learn about colleagues.\n",
      "-   **Automated \"Coffee Chat\" Lottery:** A feature that automatically schedules short, informal introductory meetings between the new hire and a variety of colleagues across different departments.\n",
      "-   **New Hire Cohort Channel:** A dedicated chat space or group for all employees who started in the same month to ask questions, share experiences, and build a peer support network.\n",
      "-   **Employee Resource Group (ERG) & Club Showcase:** A browsable directory of all internal communities and clubs (e.g., Women in Tech, Running Club), with a simple one-click way to express interest or join.\n",
      "-   **Manager Introduction Prompts:** Automated reminders and suggestions for managers to ensure they introduce their new hire to key stakeholders and team members in the first week.\n",
      "-   **\"Who's Who\" Face-Matching Game:** A simple, gamified tool to help new hires learn the names and faces of their immediate team and key cross-functional partners.\n",
      "\n",
      "--- STEP 3: ENHANCING PERSONAS PROMPT ---\n",
      "Alright team, let's gather around the virtual whiteboard. As the Product Manager for this new onboarding initiative, my goal is to architect a solution that not only solves the core administrative headaches but also creates a genuinely welcoming, effective, and memorable experience for every new hire. We want them to feel connected, confident, and productive from day one.\n",
      "\n",
      "I've structured our brainstorming around the four foundational pillars of a world-class onboarding experience. Here is a comprehensive list of features we should consider building.\n",
      "\n",
      "***\n",
      "\n",
      "## Administrative & Logistics\n",
      "\n",
      "This pillar is about creating a frictionless, \"zero-stress\" start. We need to eliminate confusion and administrative burdens so the new hire can focus on what matters.\n",
      "\n",
      "-   **Pre-boarding Portal:** A centralized web portal accessible to the new hire before their start date.\n",
      "-   **Digital Document & E-Signature Hub:** Securely upload required documents (ID, work authorization) and electronically sign all necessary paperwork (offer letter, NDAs, policy acknowledgements).\n",
      "-   **Dynamic Onboarding Checklist:** An interactive, step-by-step checklist that guides the new hire through all pre-start and first-week tasks, with clear deadlines and progress tracking.\n",
      "-   **Automated IT Provisioning Tracker:** A dashboard for the new hire to track the status of their equipment (e.g., \"Laptop Shipped\") and account creations (e.g., \"Email Account Ready\").\n",
      "-   **Hardware & Software Selection:** A simple interface for new hires to select their preferred hardware (e.g., Mac vs. PC) and request any non-standard software they need for their role.\n",
      "-   **Personalized \"First Week\" Agenda:** An automatically generated and integrated calendar for the first week, pre-populated with key meetings like HR orientation, team intros, and manager 1:1s.\n",
      "-   **Guided Benefits Enrollment:** An intuitive, wizard-like experience that simplifies the benefits selection process with clear explanations and comparison tools.\n",
      "\n",
      "## Learning & Development\n",
      "\n",
      "This pillar focuses on accelerating the new hire's path to competency and productivity. The goal is to provide clear, role-specific guidance and learning resources.\n",
      "\n",
      "-   **Collaborative 30-60-90 Day Plan:** A customizable plan with clear goals, milestones, and deliverables for the first three months, shared between the new hire and their manager.\n",
      "-   **Role-Specific Learning Pathways:** Curated learning paths with a mix of content (videos, articles, e-learning modules) tailored to the new hire's specific department and role.\n",
      "-   **In-App System Tutorials:** Interactive, guided walkthroughs of the core software and tools the new hire will be using daily (e.g., CRM, project management tool, internal wikis).\n",
      "-   **Centralized Knowledge Base:** A powerful, AI-driven search engine to find company information, process documentation, and answers to frequently asked questions.\n",
      "-   **Micro-learning Nudges:** Automated, bite-sized learning tips and best practices delivered via email or chat to reinforce training over time.\n",
      "-   **Skill Gap Self-Assessment:** An initial survey to help new hires and their managers identify potential knowledge gaps and automatically recommend relevant training.\n",
      "-   **Job Shadowing Scheduler:** A tool to easily find and request time to shadow key colleagues and understand different aspects of the business.\n",
      "\n",
      "## Cultural Integration\n",
      "\n",
      "This is about connecting the new hire to the company's mission, values, and unique way of working. We want them to understand the \"why\" and feel like they belong.\n",
      "\n",
      "-   **Interactive Company History Timeline:** A visual and engaging presentation of the company's origin story, major milestones, and vision for the future.\n",
      "-   **\"Meet the Leadership\" Video Library:** A collection of short, authentic videos from company leaders sharing insights on culture, values, and strategy.\n",
      "-   **Internal Lingo & Acronym Dictionary:** A searchable glossary of company-specific jargon to help new hires quickly get up to speed in meetings and conversations.\n",
      "-   **Values-in-Action Scenarios:** Interactive quizzes that present real-world business situations and challenge the new hire to apply the company's core values.\n",
      "-   **Digital \"How We Work\" Playbook:** An accessible guide to the company's communication norms, meeting etiquette, decision-making frameworks, and unwritten rules.\n",
      "-   **Virtual Office Tour:** A 360-degree virtual tour of the main office(s) to give remote and hybrid employees a sense of place and connection.\n",
      "\n",
      "## Social Connection\n",
      "\n",
      "This pillar is designed to combat new-hire isolation by intentionally fostering relationships and building a strong professional network from the very beginning.\n",
      "\n",
      "-   **Automated Buddy Program:** An intelligent system that pairs new hires with an experienced employee (their \"Onboarding Buddy\") and provides both with conversation starters, checklists, and recommended activities.\n",
      "-   **Interactive Org Chart & Team Directory:** A rich, visual directory of employees with photos, roles, bios, fun facts, and areas of expertise to make it easy to find and learn about colleagues.\n",
      "-   **Automated \"Coffee Chat\" Lottery:** A feature that automatically schedules short, informal introductory meetings between the new hire and a variety of colleagues across different departments.\n",
      "-   **New Hire Cohort Channel:** A dedicated chat space or group for all employees who started in the same month to ask questions, share experiences, and build a peer support network.\n",
      "-   **Employee Resource Group (ERG) & Club Showcase:** A browsable directory of all internal communities and clubs (e.g., Women in Tech, Running Club), with a simple one-click way to express interest or join.\n",
      "-   **Manager Introduction Prompts:** Automated reminders and suggestions for managers to ensure they introduce their new hire to key stakeholders and team members in the first week.\n",
      "-   **\"Who's Who\" Face-Matching Game:** A simple, gamified tool to help new hires learn the names and faces of their immediate team and key cross-functional partners.\n",
      "\n",
      "--- STEP 3: ENHANCING PERSONAS PROMPT ---\n",
      "Enhanced prompt preview (first 200 chars): <persona>\n",
      "You are an expert User Experience (UX) Researcher and Product Strategist. You specialize in creating detailed, actionable user personas to guide product development and ensure solutions are ...\n",
      "\n",
      "--- STEP 4: GENERATING USER PERSONAS ---\n",
      "Enhanced prompt preview (first 200 chars): <persona>\n",
      "You are an expert User Experience (UX) Researcher and Product Strategist. You specialize in creating detailed, actionable user personas to guide product development and ensure solutions are ...\n",
      "\n",
      "--- STEP 4: GENERATING USER PERSONAS ---\n",
      "Of course. As a UX Researcher and Product Strategist, I'll analyze the feature set to identify the three most critical and distinct user archetypes for this onboarding tool. The personas are designed to cover the core user groups: the primary beneficiary, the operational facilitator, and the strategic enabler.\n",
      "\n",
      "### **Persona Name: The New Hire (Emma, the Primary User)**\n",
      "*   **Role:** The individual joining the company who needs to complete tasks, learn their role, and integrate into the team.\n",
      "*   **Primary Goal:** To achieve a state of confidence and productivity as quickly and smoothly as possible, overcoming the anxiety and information overload of starting a new job.\n",
      "*   **Key Features They Use:**\n",
      "    *   **Personalized First Week Agenda:** Provides a clear, structured, and manageable plan for their critical first days, directly reducing stress.\n",
      "    *   **Role-Specific Learning Pathways:** Accelerates their competency by delivering the exact knowledge they need in a logical, progressive sequence.\n",
      "    *   **Automated Buddy Program:** Fosters essential social connection by providing a designated, low-pressure point of contact for questions.\n",
      "\n",
      "### **Persona Name: The Hiring Manager (David, the Operational Facilitator)**\n",
      "*   **Role:** The person responsible for ensuring their new team member is effectively integrated and set up for success within their specific role and team.\n",
      "*   **Primary Goal:** To efficiently orchestrate their new hire's ramp-up process without significant manual effort, ensuring they become a productive member of the team.\n",
      "*   **Key Features They Use:**\n",
      "    *   **30-60-90 Day Plans:** A framework to define clear expectations, set measurable goals, and track progress against key milestones for the new hire.\n",
      "    *   **Interactive Org Chart:** Helps them introduce the new hire to key stakeholders and explain team structures and reporting lines within the organization.\n",
      "    *   **Digital Document Hub:** Allows them to request, track, and confirm the completion of critical administrative documents required for their department.\n",
      "\n",
      "### **Persona Name: The HR Onboarding Specialist (Chloe, the Strategic Enabler)**\n",
      "*   **Role:** The central administrator who designs, manages, and measures the effectiveness of the onboarding program for the entire company.\n",
      "*   **Primary Goal:** To deliver a consistent, engaging, and compliant onboarding experience at scale, while gathering data to prove its ROI and continuously improve the process.\n",
      "*   **Key Features They Use:**\n",
      "    *   **Pre-boarding Portal:** Serves as the centralized hub to engage new hires between offer acceptance and Day 1, ensuring all logistical prerequisites are completed.\n",
      "    *   **IT Provisioning Tracker:** Provides visibility into the status of equipment and account setup, allowing them to proactively resolve bottlenecks.\n",
      "    *   **\"How We Work\" Playbook:** A key artifact for standardizing and communicating company-wide cultural norms, practices, and policies to ensure consistent integration.\n",
      "\n",
      "============================================================\n",
      "CHALLENGE 1 COMPLETED SUCCESSFULLY!\n",
      "============================================================\n",
      "Of course. As a UX Researcher and Product Strategist, I'll analyze the feature set to identify the three most critical and distinct user archetypes for this onboarding tool. The personas are designed to cover the core user groups: the primary beneficiary, the operational facilitator, and the strategic enabler.\n",
      "\n",
      "### **Persona Name: The New Hire (Emma, the Primary User)**\n",
      "*   **Role:** The individual joining the company who needs to complete tasks, learn their role, and integrate into the team.\n",
      "*   **Primary Goal:** To achieve a state of confidence and productivity as quickly and smoothly as possible, overcoming the anxiety and information overload of starting a new job.\n",
      "*   **Key Features They Use:**\n",
      "    *   **Personalized First Week Agenda:** Provides a clear, structured, and manageable plan for their critical first days, directly reducing stress.\n",
      "    *   **Role-Specific Learning Pathways:** Accelerates their competency by delivering the exact knowledge they need in a logical, progressive sequence.\n",
      "    *   **Automated Buddy Program:** Fosters essential social connection by providing a designated, low-pressure point of contact for questions.\n",
      "\n",
      "### **Persona Name: The Hiring Manager (David, the Operational Facilitator)**\n",
      "*   **Role:** The person responsible for ensuring their new team member is effectively integrated and set up for success within their specific role and team.\n",
      "*   **Primary Goal:** To efficiently orchestrate their new hire's ramp-up process without significant manual effort, ensuring they become a productive member of the team.\n",
      "*   **Key Features They Use:**\n",
      "    *   **30-60-90 Day Plans:** A framework to define clear expectations, set measurable goals, and track progress against key milestones for the new hire.\n",
      "    *   **Interactive Org Chart:** Helps them introduce the new hire to key stakeholders and explain team structures and reporting lines within the organization.\n",
      "    *   **Digital Document Hub:** Allows them to request, track, and confirm the completion of critical administrative documents required for their department.\n",
      "\n",
      "### **Persona Name: The HR Onboarding Specialist (Chloe, the Strategic Enabler)**\n",
      "*   **Role:** The central administrator who designs, manages, and measures the effectiveness of the onboarding program for the entire company.\n",
      "*   **Primary Goal:** To deliver a consistent, engaging, and compliant onboarding experience at scale, while gathering data to prove its ROI and continuously improve the process.\n",
      "*   **Key Features They Use:**\n",
      "    *   **Pre-boarding Portal:** Serves as the centralized hub to engage new hires between offer acceptance and Day 1, ensuring all logistical prerequisites are completed.\n",
      "    *   **IT Provisioning Tracker:** Provides visibility into the status of equipment and account setup, allowing them to proactively resolve bottlenecks.\n",
      "    *   **\"How We Work\" Playbook:** A key artifact for standardizing and communicating company-wide cultural norms, practices, and policies to ensure consistent integration.\n",
      "\n",
      "============================================================\n",
      "CHALLENGE 1 COMPLETED SUCCESSFULLY!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Challenge 1: Brainstorming Features and User Personas\n",
    "print(\"=\" * 60)\n",
    "print(\"CHALLENGE 1: AI-POWERED REQUIREMENTS GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Enhance Features Prompt\n",
    "print(\"\\n--- STEP 1: ENHANCING FEATURES PROMPT ---\")\n",
    "raw_features_prompt = f\"Based on the problem statement: '{problem_statement}', brainstorm a list of potential features for a new hire onboarding tool. Format the output as a simple markdown list.\"\n",
    "\n",
    "enhanced_features_prompt = prompt_enhancer(\n",
    "    raw_features_prompt,\n",
    "    model_name=brainstormed_features_model_name,\n",
    "    client=brainstormed_features_client,\n",
    "    api_provider=brainstormed_features_api_provider\n",
    ")\n",
    "print(\"Enhanced prompt preview (first 200 chars):\", enhanced_features_prompt[:200] + \"...\")\n",
    "\n",
    "# Step 2: Generate Brainstormed Features\n",
    "print(\"\\n--- STEP 2: GENERATING BRAINSTORMED FEATURES ---\")\n",
    "brainstormed_features = get_completion(\n",
    "    enhanced_features_prompt,\n",
    "    brainstormed_features_client,\n",
    "    brainstormed_features_model_name,\n",
    "    brainstormed_features_api_provider\n",
    ")\n",
    "print(brainstormed_features)\n",
    "\n",
    "# Step 3: Enhance Personas Prompt\n",
    "print(\"\\n--- STEP 3: ENHANCING PERSONAS PROMPT ---\")\n",
    "raw_personas_prompt = f\"Based on the problem statement: '{problem_statement}' and the following brainstormed features: {brainstormed_features}, identify and describe three distinct user personas who would interact with this tool. For each persona, describe their role and main goal.\"\n",
    "\n",
    "enhanced_personas_prompt = prompt_enhancer(\n",
    "    raw_personas_prompt,\n",
    "    model_name=user_personas_model_name,\n",
    "    client=user_personas_client,\n",
    "    api_provider=user_personas_api_provider\n",
    ")\n",
    "print(\"Enhanced prompt preview (first 200 chars):\", enhanced_personas_prompt[:200] + \"...\")\n",
    "\n",
    "# Step 4: Generate User Personas\n",
    "print(\"\\n--- STEP 4: GENERATING USER PERSONAS ---\")\n",
    "user_personas = get_completion(\n",
    "    enhanced_personas_prompt,\n",
    "    user_personas_client,\n",
    "    user_personas_model_name,\n",
    "    user_personas_api_provider\n",
    ")\n",
    "print(user_personas)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CHALLENGE 1 COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): Generating Formal User Stories\n",
    "\n",
    "**Explanation:**\n",
    "This challenge represents a significant increase in complexity and value. We are no longer asking for simple text; we are demanding a specific, structured data format (JSON). \n",
    "\n",
    "The prompt is carefully engineered:\n",
    "1.  **Persona:** `You are a Senior Product Manager...` tells the LLM the role it should adopt.\n",
    "2.  **Context:** We provide the previous outputs (`problem_statement`, `brainstormed_features`, `user_personas`) inside `<context>` tags to give the LLM all the necessary information.\n",
    "3.  **Format:** The `OUTPUT REQUIREMENTS` section is extremely explicit. It tells the LLM to *only* output JSON, defines the exact keys for each object, and specifies the format for nested data (like the array of Gherkin strings). This strictness is key to getting reliable, machine-readable output.\n",
    "4.  **Parsing:** The `try...except` block is a crucial step. It attempts to parse the LLM's string output into a Python list of dictionaries. If it succeeds, we know the LLM followed our instructions perfectly. If it fails, we print the raw output to help debug the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")\n",
    "\n",
    "\n",
    "# The prompt is highly-structured to guide the LLM toward a perfect JSON output.\n",
    "json_user_stories_prompt = f\"\"\"\n",
    "You are a Senior Product Manager creating a product backlog for a new hire onboarding tool.\n",
    "\n",
    "Based on the following context:\n",
    "<context>\n",
    "Problem Statement: {problem_statement}\n",
    "Potential Features: {brainstormed_features}\n",
    "User Personas: {user_personas}\n",
    "</context>\n",
    "\n",
    "Your task is to generate a list of 5 detailed user stories.\n",
    "\n",
    "**OUTPUT REQUIREMENTS**:\n",
    "- You MUST output a valid JSON array. Your response must begin with [ and end with ]. Do not include any text or markdown before or after the JSON array.\n",
    "- Each object in the array must represent a single user story.\n",
    "- Each object must have the following keys: 'id' (an integer), 'persona' (a string from the personas), 'user_story' (a string in the format 'As a [persona], I want [goal], so that [benefit].'), and 'acceptance_criteria' (an array of strings, with each string in Gherkin format 'Given/When/Then').\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Generating User Stories as JSON ---\")\n",
    "# We set a lower temperature to encourage the LLM to stick to the requested format.\n",
    "json_output_str = get_completion(json_user_stories_prompt, client, model_name, api_provider, temperature=0.2)\n",
    "\n",
    "print(f\"Raw LLM response length: {len(json_output_str)} characters\")\n",
    "print(\"First 200 characters of response:\")\n",
    "print(repr(json_output_str[:200]))\n",
    "\n",
    "# Attempt to parse the string output into a Python list.\n",
    "try:\n",
    "    # Use our new standardized cleaning function from utils.py\n",
    "    cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "    print(f\"\\nCleaned JSON length: {len(cleaned_json_str)} characters\")\n",
    "    \n",
    "    user_stories_json = json.loads(cleaned_json_str)\n",
    "    print(\"✅ Successfully parsed LLM output as JSON.\")\n",
    "    print(f\"Number of user stories generated: {len(user_stories_json)}\")\n",
    "    \n",
    "    # Pretty-print the first user story to verify its structure\n",
    "    print(\"\\n--- Sample User Story ---\")\n",
    "    print(json.dumps(user_stories_json[0], indent=2))\n",
    "    \n",
    "except (json.JSONDecodeError, TypeError, IndexError) as e:\n",
    "    print(f\"❌ Error: Failed to parse LLM output as JSON. Error: {e}\")\n",
    "    print(\"\\n--- DEBUGGING INFO ---\")\n",
    "    print(\"Raw LLM Output:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(json_output_str)\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    if 'cleaned_json_str' in locals():\n",
    "        print(\"\\nCleaned JSON:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(cleaned_json_str)\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    user_stories_json = [] # Assign an empty list to prevent errors in the next cell\n",
    "    print(\"\\n⚠️  Set user_stories_json to empty list to prevent downstream errors.\")\n",
    "    print(\"   Please check the API key configuration and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Programmatic Validation and Artifact Creation\n",
    "\n",
    "**Explanation:**\n",
    "This is the final and most critical step. We treat the LLM's output as untrusted input and subject it to programmatic validation. This ensures that the artifact we create is reliable and can be consumed by other automated tools in later stages of the SDLC without causing errors. \n",
    "\n",
    "The `validate_and_save_stories` function acts as a gatekeeper. It checks for the correct data types (a list of objects) and ensures that all required fields are present in each object. Only if all checks pass do we proceed to save the file using `save_artifact`. This creates a trustworthy `day1_user_stories.json` file that can be confidently used as an input for other automated processes in our SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_save_stories(stories_data):\n",
    "    \"\"\"Validates the structure of the user stories data and saves it if valid.\"\"\"\n",
    "    if not isinstance(stories_data, list) or not stories_data:\n",
    "        print(\"Validation Failed: Data is not a non-empty list.\")\n",
    "        return False\n",
    "\n",
    "    required_keys = ['id', 'persona', 'user_story', 'acceptance_criteria']\n",
    "    all_stories_valid = True\n",
    "\n",
    "    # Loop through each story object in the list.\n",
    "    for i, story in enumerate(stories_data):\n",
    "        # Check for the presence of all required keys.\n",
    "        if not all(key in story for key in required_keys):\n",
    "            print(f\"Validation Failed: Story at index {i} is missing one or more required keys.\")\n",
    "            print(f\"   Expected keys: {required_keys}\")\n",
    "            print(f\"   Found keys: {list(story.keys()) if isinstance(story, dict) else 'Not a dictionary'}\")\n",
    "            all_stories_valid = False\n",
    "            continue # Don't bother with further checks for this invalid story\n",
    "        \n",
    "        # Check that the acceptance criteria is a list with at least one item.\n",
    "        ac = story.get('acceptance_criteria')\n",
    "        if not isinstance(ac, list) or not ac:\n",
    "            print(f\"Validation Failed: Story at index {i} (ID: '{story.get('id')}') has invalid or empty acceptance criteria.\")\n",
    "            print(f\"   Expected: list with at least one item\")\n",
    "            print(f\"   Found: {type(ac)} with value {ac}\")\n",
    "            all_stories_valid = False\n",
    "\n",
    "    # Only save the artifact if all stories in the list are valid.\n",
    "    if all_stories_valid:\n",
    "        print(f\"\\n✅ All {len(stories_data)} user stories passed validation.\")\n",
    "        artifact_path = \"artifacts/day1_user_stories.json\"\n",
    "        \n",
    "        # Use the helper function to save the file, creating the 'artifacts' directory if needed.\n",
    "        # We use json.dumps with an indent to make the saved file human-readable.\n",
    "        save_artifact(json.dumps(stories_data, indent=2), artifact_path)\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"\\n❌ Validation failed for one or more stories. Artifact not saved.\")\n",
    "        return False\n",
    "\n",
    "# Note: The actual validation call is now in the next cell with better error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic: Check the current state of user_stories_json\n",
    "print(\"=== DIAGNOSTIC INFO ===\")\n",
    "if 'user_stories_json' in locals():\n",
    "    print(f\"user_stories_json exists: {type(user_stories_json)}\")\n",
    "    print(f\"Length: {len(user_stories_json) if hasattr(user_stories_json, '__len__') else 'N/A'}\")\n",
    "    if user_stories_json:\n",
    "        print(\"Sample content:\", user_stories_json[0] if len(user_stories_json) > 0 else \"Empty list\")\n",
    "    else:\n",
    "        print(\"user_stories_json is empty or falsy\")\n",
    "        print(\"This means JSON parsing likely failed in the previous cell.\")\n",
    "        print(\"Check the raw LLM output above for formatting issues.\")\n",
    "else:\n",
    "    print(\"user_stories_json variable does not exist\")\n",
    "    print(\"This means the previous cell never executed successfully\")\n",
    "\n",
    "# Also check if we have the raw output\n",
    "if 'json_output_str' in locals():\n",
    "    print(f\"\\nRaw LLM output length: {len(json_output_str)} characters\")\n",
    "    print(\"First 200 characters of raw output:\")\n",
    "    print(repr(json_output_str[:200]))\n",
    "else:\n",
    "    print(\"json_output_str not available\")\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the validation function on the data we parsed from the LLM.\n",
    "print(\"=== VALIDATION STEP ===\")\n",
    "\n",
    "if 'user_stories_json' not in locals():\n",
    "    print(\"❌ ERROR: user_stories_json variable not found.\")\n",
    "    print(\"   Make sure to run the previous cell that generates user stories.\")\n",
    "elif not user_stories_json:\n",
    "    print(\"❌ ERROR: user_stories_json is empty or None.\")\n",
    "    print(\"   This usually means JSON parsing failed in the previous step.\")\n",
    "    print(\"   Solutions:\")\n",
    "    print(\"   1. Check that your API keys are correctly configured\")\n",
    "    print(\"   2. Re-run the previous cell to generate user stories\")\n",
    "    print(\"   3. Examine the raw LLM output for formatting issues\")\n",
    "    \n",
    "    # Try to re-parse if we have the raw output\n",
    "    if 'json_output_str' in locals() and json_output_str.strip():\n",
    "        print(\"\\n🔄 Attempting to re-parse the JSON...\")\n",
    "        try:\n",
    "            cleaned_json_str = clean_llm_output(json_output_str, language='json')\n",
    "            user_stories_json = json.loads(cleaned_json_str)\n",
    "            print(\"✅ Re-parsing successful! Proceeding with validation...\")\n",
    "            validate_and_save_stories(user_stories_json)\n",
    "        except (json.JSONDecodeError, TypeError) as e:\n",
    "            print(f\"❌ Re-parsing failed: {e}\")\n",
    "            print(\"Raw output that failed to parse:\")\n",
    "            print(\"-\" * 50)\n",
    "            print(json_output_str)\n",
    "            print(\"-\" * 50)\n",
    "else:\n",
    "    print(f\"✅ Found user_stories_json with {len(user_stories_json)} stories\")\n",
    "    validate_and_save_stories(user_stories_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Congratulations! You have completed the first lab. You started with a vague, one-sentence problem and finished with a structured, validated, machine-readable requirements artifact. This is the critical first step in an AI-assisted software development lifecycle. The `day1_user_stories.json` file you created will be the direct input for our next lab, where we will generate a formal Product Requirements Document (PRD).\n",
    "\n",
    "> **Key Takeaway:** The single most important skill demonstrated in this lab is turning unstructured ideas into structured, machine-readable data (JSON). This transformation is what enables automation and integration with other tools later in the SDLC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create a function. that adds 2 numbers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
