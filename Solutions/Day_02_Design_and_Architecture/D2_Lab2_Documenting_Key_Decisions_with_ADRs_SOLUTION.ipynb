{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2 - Lab 2: Documenting Key Decisions with ADRs (Solution)\n",
    "\n",
    "**Objective:** Use an LLM as a research assistant to compare technical options and synthesize the findings into a formal, version-controlled Architectural Decision Record (ADR).\n",
    "\n",
    "**Introduction:**\n",
    "This solution notebook provides the complete prompts and explanations for the ADR generation lab. It demonstrates how to use an LLM for comparative research and then synthesize that research into a structured, formal document.\n",
    "\n",
    "For definitions of key terms used in this lab, please refer to the [GLOSSARY.md](../../GLOSSARY.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "except IndexError:\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils import setup_llm_client, get_completion, save_artifact, load_artifact\n",
    "\n",
    "client, model_name, api_provider = setup_llm_client(model_name=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: The Challenges - Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 1 (Foundational): The ADR Template\n",
    "\n",
    "**Explanation:**\n",
    "This prompt asks the LLM to generate a standard markdown template for an ADR. The key is to be specific about the sections required (`Title`, `Status`, `Context`, `Decision`, `Consequences`), which guides the LLM to produce a well-structured and reusable template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generating ADR Template ---\n",
      "```markdown\n",
      "# Title: [A short, descriptive title for the decision]\n",
      "\n",
      "**Status:** [Proposed | Accepted | Deprecated | Superseded]\n",
      "\n",
      "## Context\n",
      "- [Describe the problem, the driving forces, and the constraints.]\n",
      "\n",
      "## Decision\n",
      "- [State the chosen solution clearly and concisely.]\n",
      "\n",
      "## Consequences\n",
      "- [List the positive outcomes, negative trade-offs, and any future work required.]\n",
      "```\n",
      "\n",
      "### Usage Notes:\n",
      "- **Title:** Summarize the decision in a way that can be easily referenced.\n",
      "- **Status:** Reflect the current state of the decision. Update this status as the decision evolves through its lifecycle.\n",
      "- **Context:** Provide sufficient background to understand why this decision is necessary. Include information about stakeholders, technical constraints, and any relevant historical context.\n",
      "- **Decision:** Clearly articulate the decision that has been made. Include any relevant technical details or specifications that support the decision.\n",
      "- **Consequences:** Highlight the anticipated impact of the decision. Consider both the benefits and potential downsides. Note any further actions that will be necessary to implement or revisit the decision.\n",
      "✅ Successfully saved artifact to: templates/adr_template.md\n"
     ]
    }
   ],
   "source": [
    "adr_template_prompt = \"\"\"You are a principal engineer who champions clear documentation. Generate a concise, reusable markdown template for an Architectural Decision Record (ADR).\n",
    "\n",
    "The template must include the following sections:\n",
    "- # Title: [A short, descriptive title for the decision]\n",
    "- **Status:** [Proposed | Accepted | Deprecated | Superseded]\n",
    "- ## Context\n",
    "  - [Describe the problem, the driving forces, and the constraints.]\n",
    "- ## Decision\n",
    "  - [State the chosen solution clearly and concisely.]\n",
    "- ## Consequences\n",
    "  - [List the positive outcomes, negative trade-offs, and any future work required.]\"\"\"\n",
    "\n",
    "print(\"--- Generating ADR Template ---\")\n",
    "adr_template_content = get_completion(adr_template_prompt, client, model_name, api_provider)\n",
    "print(adr_template_content)\n",
    "\n",
    "if adr_template_content:\n",
    "    save_artifact(adr_template_content, \"templates/adr_template.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2 (Intermediate): AI-Assisted Research\n",
    "\n",
    "**Explanation:**\n",
    "This prompt leverages the LLM's vast training data to perform a comparative analysis. By instructing it to be an \"unbiased research assistant\" and asking for \"pros and cons for each,\" we guide the model to provide a balanced view rather than a simple recommendation. This produces a more valuable and objective input for our own decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Researching Database Options ---\n",
      "When choosing an approach for implementing a semantic search feature in a new hire onboarding tool, the decision between using PostgreSQL with the `pgvector` extension and a specialized vector database involves evaluating several factors such as operational complexity, cost, query flexibility, and scalability. Below is a balanced comparison of both approaches:\n",
      "\n",
      "### Approach 1: PostgreSQL with `pgvector` Extension\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "1. **Unified System:** \n",
      "   - Using PostgreSQL with `pgvector` allows for managing both traditional relational data and vector embeddings within a single database system, reducing the need for integrating multiple systems.\n",
      "\n",
      "2. **Operational Simplicity:**\n",
      "   - If the team is already using PostgreSQL, extending it with `pgvector` minimizes the learning curve and operational overhead compared to adopting a new database technology.\n",
      "   - PostgreSQL is a well-known and widely adopted database system, which makes it easier to find resources and expertise.\n",
      "\n",
      "3. **Cost-Effective:**\n",
      "   - Utilizing an existing PostgreSQL infrastructure can be more cost-effective than deploying a separate specialized vector database.\n",
      "   - Reduces the need for additional hardware or cloud resources dedicated to a separate database system.\n",
      "\n",
      "4. **Query Flexibility:**\n",
      "   - PostgreSQL's powerful query capabilities, combined with vector similarity search, can offer rich querying possibilities, blending traditional SQL queries with semantic searches.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "1. **Performance Limitations:**\n",
      "   - PostgreSQL with `pgvector` might not offer the same level of performance optimization for vector searches as specialized databases, particularly for very large datasets or high query volumes.\n",
      "\n",
      "2. **Scalability Concerns:**\n",
      "   - As data and query loads grow, the performance of vector operations in PostgreSQL may degrade, requiring careful tuning and potentially more powerful hardware.\n",
      "\n",
      "3. **Feature Set:**\n",
      "   - Lacks some advanced features that specialized vector databases offer, such as automatic indexing, hybrid search capabilities, and native support for various machine learning models.\n",
      "\n",
      "### Approach 2: Specialized Vector Database (e.g., ChromaDB, FAISS, Weaviate)\n",
      "\n",
      "**Pros:**\n",
      "\n",
      "1. **Optimized Performance:**\n",
      "   - Specialized vector databases are designed for fast and efficient vector similarity searches, which can result in better performance for large-scale and high-throughput applications.\n",
      "\n",
      "2. **Scalability:**\n",
      "   - These databases often come with built-in support for scaling horizontally, allowing for easier handling of large datasets and high query volumes.\n",
      "\n",
      "3. **Advanced Features:**\n",
      "   - Offers advanced functionalities such as hybrid search (combining vector and traditional searches), metadata filtering, and integration with machine learning pipelines.\n",
      "\n",
      "4. **Community and Support:**\n",
      "   - Many specialized vector databases have active open-source communities and offer commercial support options, which can be beneficial for troubleshooting and feature requests.\n",
      "\n",
      "**Cons:**\n",
      "\n",
      "1. **Operational Complexity:**\n",
      "   - Introducing a new database system increases the complexity of the tech stack, requiring additional skills and knowledge for setup, maintenance, and integration.\n",
      "\n",
      "2. **Cost Considerations:**\n",
      "   - Deploying and maintaining a separate database system can incur additional costs, especially if commercial support or managed services are used.\n",
      "\n",
      "3. **Integration Overhead:**\n",
      "   - Requires integration with existing systems and workflows, which can introduce complexity and potential data synchronization challenges.\n",
      "\n",
      "4. **Limited Query Flexibility:**\n",
      "   - While optimized for vector searches, these databases may not offer the full range of query capabilities found in traditional relational databases.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "For a small-to-medium sized enterprise application, the choice between these approaches depends on the specific needs and constraints of the project. If operational simplicity and cost are primary concerns, and the dataset is moderate, PostgreSQL with `pgvector` may be a suitable choice. However, if scalability, performance, and advanced search features are critical, investing in a specialized vector database could be more advantageous. The decision should also consider the team's expertise and willingness to manage the added complexity of multiple database systems.\n"
     ]
    }
   ],
   "source": [
    "db_research_prompt = \"\"\"You are an unbiased research assistant. Your task is to provide a balanced technical comparison for a software development team.\n",
    "\n",
    "For the use case of a new hire onboarding tool that needs a semantic search feature, compare and contrast the following two approaches:\n",
    "\n",
    "1.  **Approach 1:** Using PostgreSQL with the `pgvector` extension.\n",
    "2.  **Approach 2:** Using a specialized, dedicated vector database (e.g., ChromaDB, FAISS, Weaviate).\n",
    "\n",
    "Please provide a summary of the pros and cons for each approach. Consider factors like operational complexity, cost, query flexibility, and scalability for a small-to-medium sized enterprise application.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Researching Database Options ---\")\n",
    "db_research_output = get_completion(db_research_prompt, client, model_name, api_provider)\n",
    "print(db_research_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 3 (Advanced): Synthesizing the ADR\n",
    "\n",
    "**Explanation:**\n",
    "This prompt demonstrates a powerful synthesis task. We provide the LLM with two key inputs: unstructured information (the research) and a desired structure (the template). The agent's job is to merge them, creating a polished, formal document. This is a repeatable pattern for turning raw analysis into professional documentation. By assigning the persona of a Staff Engineer, we guide the LLM to adopt a formal and authoritative tone suitable for an official project artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Synthesizing Final ADR ---\n",
      "```markdown\n",
      "# Title: Adoption of PostgreSQL with pgvector Extension for Semantic Search\n",
      "\n",
      "**Status:** Proposed\n",
      "\n",
      "## Context\n",
      "- Our project aims to implement a semantic search feature within a new hire onboarding tool. This feature requires efficient handling of vector embeddings for similarity searches. \n",
      "- We must decide between using PostgreSQL with the `pgvector` extension or a specialized vector database (e.g., ChromaDB, FAISS, Weaviate).\n",
      "- Key considerations include operational complexity, cost, query flexibility, and scalability.\n",
      "- The team is already familiar with PostgreSQL, which is part of our current tech stack, thus minimizing the learning curve and operational overhead.\n",
      "- Cost constraints favor leveraging existing infrastructure without incurring additional expenses for new hardware or cloud services.\n",
      "- The anticipated dataset size and query volume for the onboarding tool are moderate, making PostgreSQL with `pgvector` a potentially viable option.\n",
      "- While performance and scalability are concerns, they may be mitigated through careful system tuning and resource allocation.\n",
      "\n",
      "## Decision\n",
      "- The team has decided to use PostgreSQL with the `pgvector` extension to implement the semantic search feature.\n",
      "- This choice leverages our existing PostgreSQL infrastructure, providing a unified system to manage both relational data and vector embeddings.\n",
      "- It offers a cost-effective solution with minimal operational complexity, allowing us to focus on developing and refining the onboarding tool without the overhead of integrating a new database system.\n",
      "\n",
      "## Consequences\n",
      "- **Positive Outcomes:**\n",
      "  - Utilizes existing PostgreSQL expertise within the team, reducing the need for additional training and resources.\n",
      "  - Offers cost savings by avoiding the deployment of a separate specialized vector database.\n",
      "  - Provides flexible query capabilities, combining traditional SQL queries with semantic searches.\n",
      "\n",
      "- **Negative Trade-offs:**\n",
      "  - Potential performance limitations for vector searches compared to specialized databases, especially as data size and query volume increase.\n",
      "  - Scalability concerns may arise, requiring careful database tuning and potentially more powerful hardware to maintain performance levels.\n",
      "  - Lack of some advanced features available in specialized vector databases, such as automatic indexing and hybrid search capabilities.\n",
      "\n",
      "- **Future Work Required:**\n",
      "  - Continuous monitoring and tuning of PostgreSQL to address performance and scalability issues as the dataset grows.\n",
      "  - Evaluation of the need for advanced features and potential reconsideration of a specialized vector database if requirements evolve.\n",
      "  - Ongoing assessment of the system's performance to ensure it meets user expectations and project goals.\n",
      "```\n",
      "\n",
      "✅ Successfully saved artifact to: artifacts/adr_001_database_choice.md\n"
     ]
    }
   ],
   "source": [
    "adr_template = load_artifact(\"templates/adr_template.md\")\n",
    "\n",
    "synthesis_prompt = f\"\"\"You are a Staff Engineer responsible for documenting key architectural decisions.\n",
    "\n",
    "Your task is to populate the provided ADR template to formally document the decision to **use PostgreSQL with the pgvector extension** for our project.\n",
    "\n",
    "Use the research provided below to fill in the 'Context' and 'Consequences' sections of the template. Be thorough and objective, summarizing the key points from the research.\n",
    "\n",
    "--- ADR TEMPLATE ---\n",
    "{adr_template}\n",
    "--- END TEMPLATE ---\n",
    "\n",
    "--- RESEARCH CONTEXT ---\n",
    "{db_research_output}\n",
    "--- END CONTEXT ---\n",
    "\n",
    "The final ADR should be complete and ready for review.\n",
    "\"\"\"\n",
    "\n",
    "print(\"--- Synthesizing Final ADR ---\")\n",
    "if adr_template and 'db_research_output' in locals() and db_research_output:\n",
    "    final_adr = get_completion(synthesis_prompt, client, model_name, api_provider)\n",
    "    print(final_adr)\n",
    "    save_artifact(final_adr, \"artifacts/adr_001_database_choice.md\")\n",
    "else:\n",
    "    print(\"Skipping ADR synthesis because template or research is missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Conclusion\n",
    "\n",
    "Well done! You have used an LLM to automate a complex but critical part of the architectural process. You leveraged its vast knowledge base for research and then used it again for synthesis, turning raw analysis into a formal, structured document. This `adr_001_database_choice.md` file now serves as a permanent, valuable record for anyone who works on this project in the future.\n",
    "\n",
    "> **Key Takeaway:** The pattern of **Research -> Synthesize -> Format** is a powerful workflow. You can use an LLM to gather unstructured information and then use it again to pour that information into a structured template, creating high-quality, consistent documentation with minimal effort."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
