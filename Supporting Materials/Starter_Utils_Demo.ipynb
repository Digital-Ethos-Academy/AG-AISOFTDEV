{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5505646",
   "metadata": {},
   "source": [
    "\n",
    "# 🧪 Starter Notebook — `utils.py` Quick Demo\n",
    "\n",
    "This notebook helps you **verify your setup** and learn the **core patterns** for using `utils.py` in this course.\n",
    "\n",
    "- Safe to run **as-is** (no external API calls by default).\n",
    "- Clear, **uncomment-to-try** cells for text, vision, image gen/edit, and audio transcription once you have keys.\n",
    "- Uses the **artifact helpers** so everything saves in predictable places under `artifacts/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059160f7",
   "metadata": {},
   "source": [
    "## 1) Import `utils.py` and quick environment check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bfb7e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ utils.py imported OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "import importlib\n",
    "\n",
    "# Add the project's root directory to the Python path to ensure 'utils' can be imported.\n",
    "try:\n",
    "    # Assumes the notebook is in 'Supporting Materials/'\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "except IndexError:\n",
    "    # Fallback for different execution environments\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd()))\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "try:\n",
    "    import utils\n",
    "    importlib.reload(utils)\n",
    "    print(\"✅ utils.py imported OK\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Could not import utils.py. Ensure it's in your project folder. Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142994c6",
   "metadata": {},
   "source": [
    "## 2) Load `.env` and explore recommended models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b5b052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Qwen/Qwen-Image | huggingface | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| Qwen/Qwen-Image-Edit | huggingface | ❌ | ❌ | ✅ | ❌ | - | - |\n",
       "| black-forest-labs/FLUX.1-Kontext-dev | huggingface | ❌ | ❌ | ✅ | ❌ | - | - |\n",
       "| claude-opus-4-1-20250805 | anthropic | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-opus-4-20250514 | anthropic | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| claude-sonnet-4-20250514 | anthropic | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| codex-mini-latest | openai | ❌ | ❌ | ❌ | ❌ | - | - |\n",
       "| dall-e-3 | openai | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| deepseek-ai/DeepSeek-V3.1 | huggingface | ❌ | ❌ | ❌ | ❌ | 128,000 | 100,000 |\n",
       "| gemini-1.5-flash | google | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 8,192 |\n",
       "| gemini-1.5-pro | google | ✅ | ❌ | ❌ | ❌ | 2,000,000 | 8,192 |\n",
       "| gemini-2.0-flash-exp | google | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gemini-2.0-flash-preview-image-generation | google | ❌ | ✅ | ❌ | ❌ | 32,000 | 8,192 |\n",
       "| gemini-2.5-flash | google | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-flash-image-preview | google | ❌ | ✅ | ❌ | ❌ | 32,768 | 32,768 |\n",
       "| gemini-2.5-flash-lite | google | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-2.5-pro | google | ✅ | ❌ | ❌ | ❌ | 1,048,576 | 65,536 |\n",
       "| gemini-live-2.5-flash-preview | google | ❌ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| gpt-4.1 | openai | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,768 |\n",
       "| gpt-4.1-mini | openai | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4.1-nano | openai | ✅ | ❌ | ❌ | ❌ | 1,000,000 | 32,000 |\n",
       "| gpt-4o | openai | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-4o-mini | openai | ✅ | ❌ | ❌ | ❌ | 128,000 | 16,384 |\n",
       "| gpt-5-2025-08-07 | openai | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-mini-2025-08-07 | openai | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-5-nano-2025-08-07 | openai | ✅ | ❌ | ❌ | ❌ | 400,000 | 128,000 |\n",
       "| gpt-image-1 | openai | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| meta-llama/Llama-3.3-70B-Instruct | huggingface | ❌ | ❌ | ❌ | ❌ | 8,192 | 4,096 |\n",
       "| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ❌ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ❌ | ❌ | ❌ | ❌ | 10,000,000 | 100,000 |\n",
       "| mistralai/Mistral-7B-Instruct-v0.3 | huggingface | ❌ | ❌ | ❌ | ❌ | 32,768 | 8,192 |\n",
       "| o3 | openai | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| o4-mini | openai | ✅ | ❌ | ❌ | ❌ | 200,000 | 100,000 |\n",
       "| stabilityai/stable-diffusion-3.5-large | huggingface | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| tokyotech-llm/Llama-3.1-Swallow-8B-Instruct-v0.5 | huggingface | ❌ | ❌ | ❌ | ❌ | 4,096 | 1,024 |\n",
       "| veo-3.0-fast-generate-preview | google | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\n",
       "| veo-3.0-generate-preview | google | ❌ | ❌ | ❌ | ❌ | 1,024 | - |\n",
       "| whisper-1 | openai | ❌ | ❌ | ❌ | ✅ | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filtered examples:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| deepseek-ai/DeepSeek-V3.1 | huggingface | ❌ | ❌ | ❌ | ❌ | 128,000 | 100,000 |\n",
       "| gemini-live-2.5-flash-preview | google | ❌ | ❌ | ❌ | ❌ | 1,048,576 | 8,192 |\n",
       "| meta-llama/Llama-4-Maverick-17B-128E-Instruct | huggingface | ❌ | ❌ | ❌ | ❌ | 1,000,000 | 100,000 |\n",
       "| meta-llama/Llama-4-Scout-17B-16E-Instruct | huggingface | ❌ | ❌ | ❌ | ❌ | 10,000,000 | 100,000 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| Qwen/Qwen-Image | huggingface | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| dall-e-3 | openai | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| gemini-2.0-flash-preview-image-generation | google | ❌ | ✅ | ❌ | ❌ | 32,000 | 8,192 |\n",
       "| gemini-2.5-flash-image-preview | google | ❌ | ✅ | ❌ | ❌ | 32,768 | 32,768 |\n",
       "| gpt-image-1 | openai | ❌ | ✅ | ❌ | ❌ | - | - |\n",
       "| stabilityai/stable-diffusion-3.5-large | huggingface | ❌ | ✅ | ❌ | ❌ | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "| Model | Provider | Vision | Image Gen | Image Edit | Audio Transcription | Context Window | Max Output Tokens |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| whisper-1 | openai | ❌ | ❌ | ❌ | ✅ | - | - |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from utils import load_environment, recommended_models_table\n",
    "load_environment()  # prints a warning if no .env is found\n",
    "_ = recommended_models_table()  # full list\n",
    "print(\"\\nFiltered examples:\")\n",
    "_ = recommended_models_table(task=\"text\", min_context=100_000)\n",
    "_ = recommended_models_table(task=\"image\")\n",
    "_ = recommended_models_table(task=\"audio\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195cd939",
   "metadata": {},
   "source": [
    "## 3) Configure a client (no API call yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a98d520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LLM Client configured: Using 'openai' with model 'gpt-4o'\n",
      "Provider: openai | Model: gpt-4o\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils import setup_llm_client\n",
    "MODEL = \"gpt-4o\"  # change when running locally (e.g., \"gemini-2.5-pro\", \"claude-opus-4-1-20250805\")\n",
    "client, model_name, provider = setup_llm_client(MODEL)\n",
    "print(\"Provider:\", provider, \"| Model:\", model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d78a26a",
   "metadata": {},
   "source": [
    "## 4) Artifact helpers (always offline-safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec120501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import save_artifact, load_artifact\n",
    "save_artifact(\"# Demo artifact\\nThis was written by the starter notebook.\", \"artifacts/notes/starter_demo.md\")\n",
    "print(\"Preview:\", (load_artifact(\"artifacts/notes/starter_demo.md\") or \"\")[:120])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d91b874",
   "metadata": {},
   "source": [
    "## 5) (Optional) PlantUML — requires internet; leave commented if offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import render_plantuml_diagram\n",
    "puml = \"\"\"\n",
    "@startuml\n",
    "actor User\n",
    "User -> API: POST /employees\n",
    "API -> DB: insert record\n",
    "@enduml\n",
    "\"\"\"\n",
    "render_plantuml_diagram(puml, \"artifacts/diagrams/quickcheck.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed6b5b2",
   "metadata": {},
   "source": [
    "## 6) Text completion — uncomment when keys are set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25ae53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import get_completion\n",
    "print(get_completion(\"Give me 3 bullet tips for clean FastAPI code.\", client, model_name, provider, temperature=0.3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409bd32f",
   "metadata": {},
   "source": [
    "## 7) Vision (image + text) — uncomment when ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b92150",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import get_vision_completion\n",
    "url = \"https://picsum.photos/seed/fastapi/640/360\"\n",
    "print(get_vision_completion(\"List 3 accessibility issues you notice.\", url, client, model_name, provider))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de7652b",
   "metadata": {},
   "source": [
    "## 8) Image generation — uncomment for supported models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import get_image_generation_completion\n",
    "file_path, data_url_or_error = get_image_generation_completion(\"A flat icon of a rocket\", client, model_name, provider)\n",
    "print(file_path, \"\\n\", (data_url_or_error or \"\")[:120], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad031f6",
   "metadata": {},
   "source": [
    "## 9) Image editing — uncomment for supported models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff4083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import get_image_edit_completion\n",
    "edited_path, data_url_or_msg = get_image_edit_completion(\n",
    "    \"Add a subtle blue outline.\",\n",
    "    \"artifacts/screens/source.png\",\n",
    "    client, model_name, provider\n",
    ")\n",
    "print(edited_path, \"\\n\", (data_url_or_msg or \"\")[:120], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790cd1f",
   "metadata": {},
   "source": [
    "## 10) Audio transcription — uncomment for Whisper/Google STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e31b3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import transcribe_audio\n",
    "print(transcribe_audio(\"artifacts/audio/sample.wav\", client, model_name, provider, language_code=\"en-US\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445327c",
   "metadata": {},
   "source": [
    "## 11) Clean model output (strip code fences) — always safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e616624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils import clean_llm_output\n",
    "raw = \"\"\"```python\n",
    "print(\"hello\")\n",
    "```\"\"\"\n",
    "print(\"Cleaned:\", clean_llm_output(raw, language=\"python\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
